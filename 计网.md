# 小林Coding-计网篇

# HTTP篇

## TCP/IP网络模型有几层

问这个一般回答四层：应用层，传输层，网络层，网络接口层

OSI参考模型是七层：应用层，表示层，会话层，传输层，网络层，数据链路层，物理层（一般把表示层和会话层去掉，常说5层 ）

传输层不负责将数据从一个设备传输到另一个设备，而是服务好应用即可，传输功能实际是在网络层

![](http://oss.interviewguide.cn/img/202205072300304.png)

分层好处：灵活性好、易于实现和维护

**物理层：**利用传输介质为数据链路层提供物理连接，实现比特流的透明传输。

**数据链路层：**接收来自物理层的位流形式的数据，并封装成帧，传送到上一层。

**网络层：**将网络地址翻译成对应的物理地址，并通过路由选择算法为分组通过通信子网选择最适当的、路径。 

**传输层：**在源端与目的端之间提供可靠的透明数据传输。

**会话层：**负责在网络中的两节点之间建立、维持和终止通信。（**建立、管理和维护会话**）

**表示层：**处理用户信息的表示问题，**数据的编码，压缩和解压缩，数据的加密和解密**。

**应用层：**为应用程序提供服务。

**应用层是工作在操作系统中的用户态，传输层及以下则工作在内核态。**

### OSI七层模型（对应协议）

1. **物理层（Physical Layer）**
   - 负责传输原始比特流。
   - 相关协议/标准：以太网（Ethernet）、光纤（Fiber）、USB、HDMI等。
2. **数据链路层（Data Link Layer）**
   - 负责在相邻的网络设备间传输帧，提供错误检测和修正。
   - 相关协议：以太网（Ethernet）、PPP（Point-to-Point Protocol）、STP（Spanning Tree Protocol）、VLAN等。
3. **网络层（Network Layer）**
   - 负责数据包的路由选择和转发。
   - 相关协议：IP（Internet Protocol）、ICMP（Internet Control Message Protocol）、IGMP（Internet Group Management Protocol）、OSPF（Open Shortest Path First）、BGP（Border Gateway Protocol）等。
4. **传输层（Transport Layer）**
   - 提供端到端的通信服务，确保数据的完整性。
   - 相关协议：TCP（Transmission Control Protocol）、UDP（User Datagram Protocol）、SCTP（Stream Control Transmission Protocol）等。
5. **会话层（Session Layer）**
   - 管理应用程序之间的会话，控制连接的建立和断开。
   - 相关技术：NetBIOS、SSH（Secure Shell）、TLS（Transport Layer Security）等。
6. **表示层（Presentation Layer）**
   - 负责数据格式的转换，加密解密，数据压缩。
   - 相关标准：JPEG、MPEG、ASCII、EBCDIC、加密算法等。
7. **应用层（Application Layer）**
   - 为应用软件提供网络服务。
   - 相关协议和服务：HTTP（Hypertext Transfer Protocol）、FTP（File Transfer Protocol）、SMTP（Simple Mail Transfer Protocol）、DNS（Domain Name System）、Telnet等。

### TCP/IP四层模型

1. **链路层（Link Layer）**
   - 相当于OSI模型的物理层和数据链路层的结合。
   - 相关协议：以太网、PPP等。
2. **网络层（Internet Layer）**
   - 主要协议是IP。
   - 其他协议：ICMP、ARP（Address Resolution Protocol）、RARP（Reverse Address Resolution Protocol）等。
3. **传输层（Transport Layer）**
   - 主要协议：TCP和UDP。
4. **应用层（Application Layer）**
   - 包含了OSI模型的会话层、表示层和应用层的功能。
   - 相关协议和服务：HTTP、FTP、SMTP、DNS、Telnet等。

### 各层数据交换的过程

当数据在网络中从一个主机传输到另一个主机时，数据会通过这四层，并在每一层都进行特定的处理。以下是数据从发送端到接收端的一般流程：

**发送端：**

1. **应用层** - 数据生成
   - 应用层协议（如HTTP, FTP, SMTP等）创建数据。
   - 数据对于不同的协议来说可能意味着HTTP请求/响应、电子邮件等。
2. **传输层** - 数据分割和控制
   - 应用层传来的数据被分割成合适大小的段。
   - TCP添加端口号和序列号，如果使用UDP，则添加端口号和长度信息。
   - 对数据进行错误检测，TCP还会添加控制信息以确保可靠传输。
3. **网络层** - 数据封装和路由
   - 在数据段前面添加IP头，包括源IP地址和目标IP地址。
   - 路由功能决定数据包的路径。
4. **链路层** - 数据帧化和物理传输
   - IP数据包被封装成帧，每一帧包含MAC地址、错误检测和其他控制信息。
   - 数据被发送到物理介质（如以太网、WIFI、光纤）。

**网络中的数据传输：**

- 数据在物理介质中传输，可能通过路由器和交换机等设备，这些设备在网络层和链路层操作，确保数据向正确的方向移动。

**接收端：**

1. **链路层**
   - 接收到的帧被处理，检查MAC地址决定是否为目标设备的数据。
   - 错误检测确保数据的完整性。
2. **网络层**
   - 帧中提取出IP数据包。
   - 检查IP头的目标地址以确认数据包已到达目的地。
   - 如果设备是路由器，会根据IP头中的地址决定如何转发数据包。
3. **传输层**
   - 从IP数据包中提取出传输层的数据段。
   - TCP检查段的顺序和完整性，如果有必要，进行重新排序或请求重传。
   - 端口号用于将数据送到正确的应用程序。
4. **应用层**
   - 完整的数据被送到应用层。
   - 应用程序处理数据，如显示网页、存储电子邮件等。

在这个过程中，每一层都对数据或数据头进行了操作，然后向下传递给下一层。在接收端，这一过程以相反的顺序发生，最终将原始数据准确无误地送到目标应用程序。



### 发送 HTTP 请求用到的协议

1. **HTTP (超文本传输协议)**：HTTP是一个应用层协议，用于发送和接收超文本信息，包括网页、图片、视频等。它规定了请求和响应的格式，包括头部信息和主体内容。HTTP协议中定义了一些方法（如GET、POST、PUT、DELETE等）用于表示对资源的不同操作。
2. **HTTPS (超文本传输安全协议)**：HTTPS是HTTP的安全版，它在HTTP和TCP之间增加了一个安全层（通常是SSL或TLS），用于加密HTTP请求和响应，保护数据的隐私和完整性。
3. **TCP (传输控制协议)**：TCP是一种传输层协议，负责在网络中的两个主机之间提供可靠的、有序的和错误检查的数据流。TCP通过使用握手过程建立连接，使用确认和重传机制保证数据的可靠传输，使用序列号保证数据的有序接收。
4. **IP (互联网协议)**：IP是一种网络层协议，负责将数据包从源主机发送到目标主机。IP协议包含源IP地址和目标IP地址，以确定数据包的发送者和接收者。IP协议不保证数据包的可靠传输，这一任务由TCP协议完成。
5. **DNS (域名系统)**：虽然DNS并不直接参与HTTP请求的发送和接收，但在客户端向服务端发送HTTP请求之前，通常需要通过DNS解析服务端的域名，得到服务端的IP地址。
6. **ARP (地址解析协议)**：如果请求在一个局域网内部进行，还可能涉及到ARP协议。ARP用于将IP地址映射到物理MAC地址，以进行局域网内部的通信。

这些协议在网络栈中各自扮演不同的角色，共同支持了从客户端到服务端的HTTP通信。





## 常用流程

### 输入网址url到网页显示过程

**浏览器（客户端）先解析URL，确定了web服务器和文件名之后根据这些信息生成HTTP请求消息，再通过DNS服务器查询web服务器域名对应的IP地址，得到IP地址后，TCP3次握手建立连接然后给服务器发送http请求，服务器响应http请求，TCP4次挥手关闭连接，浏览器得到html代码并且解析代码请求代码中的资源，最后浏览器对页面进行渲染呈现给用户**。

- **MTU**：一个网络包的最大长度，以太网中一般为**1500**字节。
- **MSS**：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。
- **MTU**是在IP上分的，**MSS**是TCP报文段。

网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将**数字信息转换为电信号**，才能在网线上传输，也就是说，这才是真正的数据发送过程；负责执行这一操作的是**网卡**，要控制网卡还需要靠**网卡驱动程序**。网卡驱动获取网络包之后，会将其**复制**到网卡内的缓存区中，接着会在其**开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列**



#### 浏览器无法显示网页，如何排查

1. 首先确认是服务端的问题还是客户端的问题
   - 确认浏览器是否可以访问其他网站，如果不可以，说明客户端网络自身的问题，然后检查客户端网络配置（连接wifi正不正常，有没有插网线）
   - 如果可以正常其他网页，说明客户端网络是可以正常上网的。
2. 抓包确认 DNS 是否解析出了 IP 地址，如果没有解析出来，说明域名写错了。
3. 抓包确认有没有和服务端建立三次握手，如果能成功建立三次握手，并且发出了 HTTP 请求，但是就是没有显示页面，可以查看服务端返回的响应码：
   - 如果是404错误码，检查输入的url是否正确；
   - 如果是500，说明服务器此时有问题；
   - 如果是200，F12看看前端代码有问题导致浏览器没有渲染出页面。
4. 如果客户端网络是正常的，但是访问速度很慢，导致很久才显示出来。这时候要看客户端的网口流量是否太大的了，导致tcp发生丢包之类的问题。

**总之就是一层一层有没有插网线，网络配置是否正确、DNS有没有解析出 IP地址、TCP有没有三次握手、HTTP返回的响应码是什么。**





#### 没有网络连接，从哪些方面去排除问题

1. **检查物理链路是否有问题**
   - 电脑本身的网卡有没有问题
   - 网线是否已经接上
   - 本机所连接的交换机是否有问题
2. **查看本机IP地址、路由、DNS的设置是否有问题**
   - 检查是否存在 IP 地址冲突的问题，用 `arping 192.168.9.120` 看下是否 ip 是否唯一
   - 检查路由设置，是否对特定的包进行了限制
   - 检查 DNS 是否有问题，用 `ping www.baidu.com` 看是否能够返回 ip 地址
3. **测试网关或路由器的通畅情况。先测网关然后再测路由器，一级一级地测试（确认局域网的通信正常）**
   - 主要就是 ping 了，先 ping 网关的 ip 地址，再 ping 路由器的 ip 地址
4. **测试DNS的通畅情况，可以直接ping网站地址**
   - 直接 ping 目标 ip，看是否能够 ping 通



1. 



###  HTTP 请求的过程

- 由域名→ IP 地址：寻找 IP 地址的过程依次经过了浏览器缓存、系统缓存、hosts 文件、路由器缓存、 递归搜索根域名服务器（DNS解析）。
- 建立 TCP/IP 连接（三次握手具体过程）。
- 由浏览器发送一个 HTTP 请求。
- 经过路由器的转发，通过服务器的防火墙，该 HTTP 请求到达了服务器。
- 服务器处理该 HTTP 请求，返回一个 HTML 文件。
- 浏览器解析该 HTML 文件，并且显示在浏览器端。
- 服务器关闭 TCP 连接（四次挥手具体过程）

1. 域名解析

- **浏览器缓存**：浏览器会检查是否有缓存的DNS记录。
- **系统缓存**：如果浏览器没有缓存，操作系统会检查自身的DNS缓存。
- **hosts文件**：如果系统缓存中也没有，会查找系统的hosts文件。
- **路由器缓存**：如果前面步骤均未命中，请求会发送到本地网络的路由器，它可能有自己的DNS缓存。
- **递归搜索**：如果路由器缓存也未命中，路由器将请求发送至配置的DNS服务器，可能发生递归查询，最终可能查询到根域名服务器，获取域名对应的IP地址。

2. 建立TCP连接（三次握手）

1. **SYN**：客户端发送一个SYN（同步序列编号）标志的TCP段，以告知服务器它希望建立连接。
2. **SYN-ACK**：服务器回应一个SYN-ACK（同步和应答）标志的TCP段，确认收到了客户端的SYN。
3. **ACK**：客户端发送一个ACK（应答）标志的TCP段，作为对服务器SYN-ACK的确认响应。

3. 浏览器发送HTTP请求

- **组装HTTP请求消息**：浏览器构建一个HTTP请求消息，包含请求行（如`GET /index.html HTTP/1.1`）、请求头（如`Host`, `User-Agent`, `Accept`等）和请求体（如果是POST请求）。
- **发送请求**：浏览器通过建立的TCP连接发送请求消息给服务器。

4. 请求传输过程

- **路由器转发**：HTTP请求消息可能通过多个路由器传输。
- **防火墙检查**：到达服务器前，请求可能会经过防火墙的检查，以确保安全性。

5. 服务器处理HTTP请求

- **服务器接收请求**：服务器的HTTP服务（如Apache或Nginx）接收到请求并处理。
- **服务器返回响应**：服务器处理完请求后，返回一个HTTP响应消息，包含状态行、响应头和响应体（通常是HTML内容）。

6. 浏览器解析HTML

- **解析HTML内容**：浏览器接收到HTML文件后，开始解析HTML标记，并构建DOM树。
- **渲染页面**：浏览器根据DOM树和CSS渲染页面，并执行JavaScript代码。

7. 关闭TCP连接（四次挥手）

1. **FIN**：通常由浏览器发起，发送一个FIN（结束）标志的TCP段来关闭连接。
2. **ACK**：服务器确认接收到FIN，发送一个ACK。
3. **FIN**：服务器发送自己的FIN段。
4. **ACK**：客户端发送ACK确认，完成连接终止。



### DNS原理、工作流程

**DNS原理：**

DNS的原理基于将容易记忆的域名（www.example.com`）转换为数字形式的IP地址（`192.0.2.1`），识别每个节点的方法。域名以层次结构组织，允许分布式处理。域名解析是通过一系列递归和迭代查询完成的，涉及不同级别的DNS服务器，包括根服务器、顶级域名服务器（TLD服务器）和权威名称服务器。

**DNS工作流程：**

1. **用户请求：** 用户输入一个域名（如`www.example.com`）进入浏览器。
2. **本地系统查询：** 系统首先检查本地DNS缓存，看是否已经有该域名的解析记录；如果没有，则系统会向配置的DNS递归服务器发出请求。
3. **递归服务器：** 递归DNS服务器查看它的缓存；如果缓存中没有找到，则递归服务器将请求发送到根服务器。
4. **根服务器：** 根服务器回应顶级域（TLD）服务器的地址。对于`www.example.com`，它是`.com`的TLD服务器。
5. **TLD服务器：** 递归服务器随后向`.com` TLD服务器查询`example.com`域的权威名称服务器地址。
6. **权威名称服务器：** 一旦获得权威名称服务器的地址，递归服务器向权威服务器查询`www.example.com`的IP地址。
7. **IP地址回应：** 权威名称服务器回应`www.example.com`的IP地址。
8. **存储记录：** 递归服务器将IP地址存储在其缓存中以备后续查询，并将IP地址回应给用户的设备。
9. **建立连接：** 用户的设备使用这个IP地址与目标服务器建立TCP连接，并开始HTTP会话，加载网站内容。
10. **结果：** 用户的浏览器显示`www.example.com`的网页内容。



Web页面请求

**1、Web的页面请求流程及涉及到的技术**

【浏览器地址栏输入URL回车后涉及到的流程】

**1.1 查找DNS缓存**

​	**浏览器->OS->路由器->LSP（本地通信服务商）**

1. 先从浏览器查找DNS缓存，看浏览器中是否存在目标域名的 IP 地址；
2. 如果不在浏览器缓存，则浏览器将对OS发起系统调用，查询 OS 本地缓存：
3. 如果不在操作系统本地缓存，则浏览器会查询与之相连的路由器缓存：
4. 如果不在路由器缓存，则浏览器会检查LSP缓存：

如果上述四步都查询不到，则发起DNS查询

**1.2 发起DNS查询**

向本地 DNS 发起 DNS 查询：

- 本地 DNS 的缓存中找到，直接返回对应的IP地址
- 找不到，本地 DNS （客户端 TCP/IP 设置中填写的 DNS 服务器地址）从根 DNS 服务器开始迭代查询，直到查询到IP地址，将结果加入缓存，然后返回IP地址）

【解释：DNS 是分布式域名服务器，每台服务器只维护一部分P地址到网络地址的映射，没有任何一台服务器能够维持全部的映射关系】

**1.3 封装数据包**

拿到IP地址后，根据URL中的端口可知端口号【HTTP：80；HTTPS：443】，一般先会先尝试建立HTTP连接；

1. **封装传输层数据包：**将应用层传递下来的实际数据，在传输层添加TCP首部：
2. **封装网络层数据包：**将传输层传下来的数据在网络层添加IP首部：
3. **封装网络接口层数据包：**将网络层传输下来的数据，在数据链路层添加以太网首部，并在传输介质中进行传输。

**1.4 浏览器与目标服务器建立连接**

经过上述DNS和ARP查询流程后，浏览器会收到目标服务器的IP和MAC地址，然后经过三次握手后建立TCP连接：

此时有两个结果：

1. **使用HTTP协议**

   浏览器发送请求到服务器，如果使用的是HTTP协议，则服务器直接返回结果：

2. **使用HTTPS协议**

   如果不是HTTP协议，则服务器会返回一个以3开头的重定向消息，告诉浏览器使用的HTTPS,IP没变，只是端口号变成443；完成四次挥手；

   然后重新建立TCP连接，将端口号修改为443，同时沟通好双方的使用的认证算法、加密和解密算法，在次过程中也会检查对方的CA安全证书，采用SSL加密技术进行传输数据。

**1.5 浏览器发送HTTP/HTTPS请求到web服务器**

主要使用两种请求方式：

1. 浏览器发送get请求，要求目标服务器提供输入的网页；
2. 浏览器发送post请求，表示填写的是表单。

**1.6 服务器处理请求并返回响应**

服务器会从浏览器接受请求并将其传递给请求处理程序并建立响应包；

一般响应包包含：请求的网页以及状态码，压缩类型，如何缓存的页面，设置的cookie：

**1.7 服务器将响应包发送给客户端**

应用层->传输层->网络层->链路层

**1.8  浏览器显示HTML页面**

1. 渲染HTML骨架
2. 检查HTML标记并发送GET请求以获取网页上的其他元素【图像、CSS样式、JS文件等】，该静态文件一般由浏览器缓存，再次访问，不用重新请求：
3. 显示HTML页面







### RPC远程过程调用

客户端可以像调用本地函数一样的调用服务端的函数；本质是提供了一种轻量无感知的跨进程通信的方式。

**RPC调用过程：**

1. 客户端调用函数（函数3个参数：待调用的接口名+函数名，待调用函数的形参和接收结果的指针）
2. 客户端存根收到调用之后将要待调用的接口名+函数名，待调用函数中需要传的参数和执行函数后接收执行结果的指针类型打包序列化成二进制数据
3. 将序列化后的数据通过网络传输到服务端
4. 服务端进行反序列化从客户端传来的数据
5. 根据反序列化后的数据去找到并执行客户端需要调用的函数
6. 将函数执行的结果序列化成二进制数据
7. 客户端反序列化从服务端传来的二进制数据
8. 客户端得到执行结果

**Protobuf的语法：**

message相当于结构体，service像一个接口，里面的数字是按顺序写的，并不是赋值，范围是1-15

```c++
message Test{
    string aaa = 1;
    int32 bbb = 2;
    repeated string ccc = 3;
}
```

RPC的架构：

1. 传输层（TCP传输插件，HTTP传输插件）
2. 协议层（协议插件，序列化插件，解压缩插件）
3. 集群层（服务发现插件，连接管理插件，负载均衡插件，路由插件，容错插件，配置管理插件）
4. 入口层（动态代理插件，链路追踪插件，过滤链插件）

把每个功能都抽象成一个接口，这样便于以后的扩展







Linux 收发网络包的流程

**接收过程：**

1. 网卡收到一个网络包，以DMA的方式把网卡上收到的帧写到内存（Ring Buffer）里，硬中断通知CPU有数据到达。当CPU收到中断请求后，会去调用网络驱动注册的中断处理函数。网卡的中断处理函数并不做过多工作（发出软中断请求，修改CPU的poll_list）然后尽快释放CPU。

2. ksoftirqd进程检测到有软中断请求到达，关闭硬中断后调用驱动的poll开始轮询收包，poll函数将收到的包送到协议栈注册的ip_rcv函数处理。

3. 然后，ip_rcv函数再将包送到udp_rcv函数中（对于tcp包就送到tcp_rcv）处理，最后加入用户的接收队列，唤醒用户进程


**注意：**

- ksoftirqd是专门处理软中断的线程，不只是处理网络软中断，还有定时器软中断等

**发送过程：**

1. 调用 `send(fd, buf, size, op)` 以后，首先根据fd在内核中将对应socket中找出来，因为socket中记录这各种协议栈的函数地址与网络信息。然后构造一个 `struct msghdr` 对象，把用户传入的数据，比如 buffer地址、数据长度啥的，统统都装进去。

2. 在进入到协议栈 inet_sendmsg 以后，内核接着会找到 socket 上的具体协议发送函数。对于 TCP 协议来说，那就是 tcp_sendmsg（同样也是通过 socket 内核对象找到的）。然后内核申请一段内核态的skb（`struct sk_buff`）内存，将这段内存加入发送队列的尾部，最后将用户待发送的数据放进去。

   **注意：**

   - 此时需要判断是否可以发送（窗口大小等），可以才发送，否则就只是拷贝到内核
   - skb中实际上已经包含所有头部的内存，在加入新的头部时，只需要挪动头部指针即可，避免了内存的申请和拷贝，提高效率

3. `tcp_write_xmit()`处理了传输层的拥塞控制、滑动窗口相关的工作。满足窗口要求的时候，拷贝一份将要发送的skb，设置一下 TCP 头，然后将 skb 传到更低的网络层进行处理。

   **注意：在传输层又拷贝了一份即将发送的skb，why？**

   - 因为 skb 后续在调用网络层，最后到达网卡发送完成时，这个 skb 会被释放掉。而TCP是支持丢失重传的，因此在收到对方的ACK之前，这个skb不可删除，网络层发送成功时，删除的只是一个副本。

4. 网络层里主要处理路由项查找、IP 头设置、netfilter 过滤、skb 切分（大于 MTU 的话）等几项工作，处理完这些工作后会交给更下层的邻居子系统来处理。

5. 邻居子系统是位于网络层和数据链路层中间的一个系统，在邻居子系统里主要是查找或者创建邻居项，在创造邻居项的时候，有可能会发出实际的 arp 请求。然后封装一下 MAC 头，将发送过程再传递到更下层的网络设备子系统。

   **注意：邻居项实际上就是arp缓存**

6. 进入网络设备子系统，由于现在网卡有多个发送队列（RingBuffer），因此需要先选择一个队列进行发送

   **注意：**这个过程消耗的是用户进程（内核态）的系统时间，当quota（配额）用完，或其他进程需要CPU，就触发软中断进程继续发送

7. 如果系统态 CPU 发送网络包不够用的时候，会调用 ` __netif_schedule ` 触发一个软中断。该函数会进入到 `__netif_reschedule`，由它来实际发出 `NET_TX_SOFTIRQ` 类型软中断。在软中断中，获取发送队列，然后同样调用网卡驱动程序进行发送

   **注意：软中断开始的数据发送就不会消耗用户进程（内核态）的系统时间了**

8. 调用驱动里的发送函数 igb_xmit_frame。在驱动函数里，将 skb 会挂到 RingBuffer上，skb 的所有数据都映射到 DMA 地址后，数据包将真正从网卡发送出去。

9. 发送完成后，网卡向CPU发送硬中断，通知CPU清理 RingBuffer 中刚刚发送出去的数据（对于TCP来说，删除的只是副本）

   注意：

   - 这里清理指的是清理 skb，解除 DMA 映射等

   - **从硬中断触发的软中断都是 NET_RX_SOFTIRQ**，与接收触发的软中断一致，在软中断中对发送和接收分别处理


**1、发送网络数据的时候都涉及到哪些内存拷贝操作？**

1. 第一次拷贝操作是内核申请完 skb 之后，这时候会**将用户传递进来的 buffer 里的数据内容都拷贝到 skb 中**。如果要发送的数据量比较大的话，这个拷贝操作开销还是不小的。
2. 第二次拷贝操作是从传输层进入网络层的时候，每一个 skb 都会被克隆一个新的副本出来。网络层以及下面的驱动、软中断等组件在发送完成的时候会将这个副本删除。传输层保存着原始的 skb，在当网络对方没有 ack 的时候，还可以重新发送，以**实现 TCP 中要求的可靠传输**。
3. 第三次拷贝不是必须的，只有当 **IP 层发现 skb 大于 MTU 时**才需要进行。会再申请额外的 skb，并将原来的 skb 拷贝为多个小的 skb。



### SCOKET编程

Socket编程用于在不同设备之间进行数据交换。它提供了端到端的通信链接，通过这个链接，应用程序可以交换数据。TCP（传输控制协议）、UDP（用户数据报协议）。

**TCP Socket编程流程**

TCP提供的是一个面向连接、可靠的字节流服务。

**TCP服务器端流程：**

1. **创建Socket：** 使用`socket()`函数创建一个新的socket。

   ```c++
   int sockfd = socket(AF_INET, SOCK_STREAM, 0);
   ```

2. **绑定Socket到地址和端口：** 使用`bind()`函数将socket绑定到服务器的特定IP地址和端口上。

   ```c++
   struct sockaddr_in server_addr;
   server_addr.sin_family = AF_INET;
   server_addr.sin_port = htons(PORT);
   server_addr.sin_addr.s_addr = INADDR_ANY;
   bind(sockfd, (struct sockaddr *)&server_addr, sizeof(server_addr));
   ```

3. **监听连接：** 使用`listen()`函数使socket进入被动监听状态。

   ```c++
   listen(sockfd, BACKLOG);
   ```

4. **接受连接：** 使用`accept()`函数接受一个客户端的连接请求。这个调用通常是阻塞的。

   ```c++
   struct sockaddr_in client_addr;
   socklen_t client_addr_size = sizeof(client_addr);
   int new_socket = accept(sockfd, (struct sockaddr *)&client_addr, &client_addr_size);
   ```

5. **读取和写入数据：** 使用`read()`和`write()`或`recv()`和`send()`函数与客户端交换数据。

   ```c++
   char buffer[1024];
   ssize_t bytes_read = recv(new_socket, buffer, sizeof(buffer), 0);
   send(new_socket, buffer, bytes_read, 0);
   ```

6. **关闭连接：** 使用`close()`函数关闭socket连接。

   ```c++
   close(new_socket);
   close(sockfd);
   ```

**TCP客户端流程：**

1. **创建Socket：** 类似于服务器端，使用`socket()`创建socket。

   ```c++
   int sockfd = socket(AF_INET, SOCK_STREAM, 0);
   ```

2. **指定服务器地址和端口：** 使用服务器的IP地址和端口设置sockaddr_in结构。

   ```c++
   server_addr.sin_family = AF_INET;
   server_addr.sin_port = htons(PORT);
   inet_pton(AF_INET, "SERVER_IP", &server_addr.sin_addr);
   ```

3. **连接到服务器：** 使用`connect()`函数请求连接到服务器。

   ```c++
   connect(sockfd, (struct sockaddr *)&server_addr, sizeof(server_addr));
   ```

4. **读取和写入数据：** 使用`send()`和`recv()`函数与服务器交换数据。

   ```c++
   char buffer[1024];
   strcpy(buffer, "Hello, Server!");
   send(sockfd, buffer, strlen(buffer), 0);
   ssize_t bytes_received = recv(sockfd, buffer, sizeof(buffer), 0);
   ```

5. **关闭Socket：** 使用`close()`函数关闭socket。

   ```c++
   close(sockfd);
   ```



**UDP Socket编程流程**

UDP提供的是一个无连接的数据报服务。

1. ### UDP服务器端流程：

   1. **创建Socket：** 使用`socket()`函数创建一个新的socket。

      ```c++
      int sockfd = socket(AF_INET, SOCK_DGRAM, 0);
      ```

   2. **绑定Socket到地址和端口：** 使用`bind()`函数将socket绑定到服务器的特定IP地址和端口上。

      ```c++
      struct sockaddr_in server_addr;
      memset(&server_addr, 0, sizeof(server_addr));
      server_addr.sin_family = AF_INET;
      server_addr.sin_port = htons(PORT);
      server_addr.sin_addr.s_addr = INADDR_ANY;
      bind(sockfd, (struct sockaddr *)&server_addr, sizeof(server_addr));
      ```

   3. **接收数据：** 使用`recvfrom()`函数从客户端接收数据。这个调用通常是阻塞的。

      ```c++
      struct sockaddr_in client_addr;
      socklen_t client_addr_len = sizeof(client_addr);
      char buffer[1024];
      ssize_t msglen = recvfrom(sockfd, buffer, sizeof(buffer), 0, (struct sockaddr *)&client_addr, &client_addr_len);
      ```

   4. **发送响应：** 使用`sendto()`函数向客户端发送数据。

      ```c++
      sendto(sockfd, buffer, msglen, 0, (struct sockaddr *)&client_addr, client_addr_len);
      ```

   5. **关闭Socket：** 使用`close()`函数关闭socket。

      ```c++
      close(sockfd);
      ```

   ### UDP客户端流程：

   1. **创建Socket：** 类似于服务器端，使用`socket()`创建socket。

      ```c++
      int sockfd = socket(AF_INET, SOCK_DGRAM, 0);
      ```

   2. **指定服务器地址和端口：** 设置sockaddr_in结构体，填入服务器的IP地址和端口。

      ```c++
      struct sockaddr_in server_addr;
      memset(&server_addr, 0, sizeof(server_addr));
      server_addr.sin_family = AF_INET;
      server_addr.sin_port = htons(PORT);
      inet_pton(AF_INET, "SERVER_IP", &server_addr.sin_addr);
      ```

   3. **发送数据：** 使用`sendto()`函数向服务器发送数据。

      ```c++
      char buffer[] = "Hello, Server!";
      sendto(sockfd, buffer, strlen(buffer), 0, (struct sockaddr *)&server_addr, sizeof(server_addr));
      ```

   4. **接收响应：** 使用`recvfrom()`函数接收服务器的响应。

      ```c++
      struct sockaddr_in from_addr;
      socklen_t from_addr_len = sizeof(from_addr);
      ssize_t msglen = recvfrom(sockfd, buffer, sizeof(buffer), 0, (struct sockaddr *)&from_addr, &from_addr_len);
      ```

   5. **关闭Socket：** 使用`close()`函数关闭socket。

      ```c++
      close(sockfd);
      ```

   在使用UDP进行Socket编程时，你不需要像TCP一样进行连接和断开连接的过程，因为UDP是无连接的。







- 服务端和客户端初始化 `socket`，得到文件描述符；
- 服务端调用 `bind`，将绑定在 IP 地址和端口;
- 服务端调用 `listen`，进行监听；
- 服务端调用 `accept`，等待客户端连接；
- 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；
- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；
- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。





字节序是什么(大端、小端)

- 字节序经常被分为两类：

  1. Big-Endian（大端，网络）：高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。

  2. Little-Endian（小端，主机）：低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。

- **高低地址与高低字节：**

  - 在十进制中靠左边的是高位，靠右边的是低位

    - **网络字节序 就是 大端字节序：4个字节的32 bit值以下面的次序传输，首先是0～7bit，其次8～15bit，然后16～23bit，最后是24~31bit**
    - **主机字节序 就是 小端字节序，现代PC大多采用小端字节序**

  - C++提供了相应的函数接口，htonl、htons用于主机序转换到网络序，ntohl、ntohs用于网络序转换到主机序。htons用于主机序转换到网络序，ntohl、ntohs用于网络序转换到主机序。其中h表示host主机，n表示network网络。







**Linux接收网络包**

1.**当有网络包到达时，会通过DMA技术，将网络包写入到指定的内存地址**，也就是写入到Ring Buffer，**接着网卡向CPU发起硬件中断，当CPU收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数。**

2.中断处理函数会先**暂时屏蔽中断**，接着发起**软中断**，恢复刚才屏蔽的中断。软中断是由**内核中的ksoftirqd线程负责处理**，它会从ring buffer中获取一个数据帧，用sk_buff表示，从而作为一个网络包交给网络协议栈逐层处理。

3.网络协议栈会先进入到网络接口层，在这一层会检查报文的合法性，如果不合法则丢弃，合法则会找出该网络包的上层协议的类型，比如是IPv4，还是IPv6，接着再去掉帧头和帧尾，然后交给网络层。到了网络层，则取出IP包，判断网络包下一步的走向，比如是交给上层处理还是转发出去。当确认这个网络包要发送给本机后，就会从IP头里看看上一层协议的类型是TCP，还是UDP，接着去掉IP头，然后交给传输层。传输层取出TCP头或UDP头，根据四元组「源IP、源端口、目的IP、目的端口」 作为标识，找出对应的Socket，并把数据放到Socket的接收缓冲区。最后，应用层程序调用Socket接口，将内核的Socket接收缓冲区的数据拷贝到应用层的缓冲区，然后唤醒用户进程。

硬件中断处理函数干啥：先**暂时屏蔽中断**，表示已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知 CPU 了，这样可以提高效率，避免 CPU 不停的被中断；接着发起**软中断**，恢复刚才屏蔽的中断。

## HTTP相关

### HTTP状态码

一共五类状态码，**1xx表示提示信息**，是一种中间状态，实际用的很少；**2xx表示服务器成功处理了客户端请求**；**3xx表示重定向**，就是需要客户端用新的URL重新发送请求获取资源；**4XX表示客户端发送的报文有误，服务器无法处理**；**5xx**表示请求报文正确，但服务器处理时内部发生了问题，是**服务器端错误**。

常见的有：  [**200** OK]，表示一切正常。如果**非HEAD请求**，服务器返回的响应头会有body数据

​				 	[**204** No Content]，也是表示成功，但是没有body数据

​					 [**301** Moved Permanently]，**永久重定向**，表示请求的资源不存在了，需要新的URL

​					 [**302** Found]，**临时重定向**，说明请求的资源还在，但暂时需要用另一个URL来访问。

​					 [**304** Not Modified]，**缓存重定向**，301和302会自动跳转到新的URL，但是304不跳转用的是缓存

​					 [**404** Not Found]，**表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。**

​					 [**400** Bad Request]，**表示客户端请求的报文有错误，但只是个笼统的错误。**

​					 [**403** Forbidden]，表示**服务器禁止访问资源**，并不是客户端的请求出错。

​					 [**500** Internal Server Error]，**笼统通用的错误码**，服务器发生了什么错误，我们并不知道。

​					 [**501** Not Implemented]，表示**客户端*请求的功能*还不支持**，类似“即将开业，敬请期待”的意思。

​				   「**502** Bad Gateway」通常是服务器作为网关或代理时返回的错误码，**表示服务器自身工作正常，访问后端服务器发生了错误。**

​					 [**503** Service Unavailable]，表示**服务器当前很忙**，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思



**HTTP字段**

**请求行，请求头，请求体；状态行，响应头，响应体**

![](https://img-blog.csdnimg.cn/93efd22b2bbd4a328e0d66a1af2e3a44.png)

这是一个http请求

```c++
POST /chapter17/user.html HTTP/1.1
Accept: image/jpeg, application/x-ms-application, *...
Referer: http://localhost:8088/chapter17/user/register.html?code=100&time=123123
Accept-Language: zh-CN
User-Agent: Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1:Content-Type: application/x-www-form-urlencoded
Host: localhost:8088(www.xxx.com)
Content-Length: 112
Connection: Keep-Alive
Content-Type: text/html; charset=utf-8
name=tom&password=1234&realName=tomson
```

由此看出常见字段有：

**Host字段**，用来指定服务器域名；**Content-length字段**，表示服务器返回数据时数据的长度；**Connection字段**，常用于开启**HTTP长连接机制**，**Content-Type字段**，表示返回数据的数据类型，**Content-Encoding字段**，表示返回的数据用了什么压缩格式。

**HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。HTTP/1.1默认长连接，一般要指定长连接的超时时间，keeplive_timeout一般是60s，60s内没有数据发送就触发回调函数关闭连接**，开启了长连接，一个TCP就可以对应多个HTTP请求。

HTTP是基于TCP传输的，TCP面向字节流的，可能会有**粘包问题**，HTTP 协议**通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界**，这两个方式都是为了**解决“粘包”的问题**



**HTTPS会加密URL么**

会，因为URL的信息都是保存在HTTP Header中的，而**HTTPS是会对HTTP Header(请求行+请求头部)+HTTP Body整个加密的**，所以URL自然是会被加密的。

但是我们**可以在TLS握手过程中看到域名信息**，server name就是域名信息。



### HTTP请求方法(GET/POST区别)

**GET，POST，HEAD，OPTIONS，DELETE等**

GET方法的**参数是写在 ? 后面，用 & 分割**。解析报文的过程是通过获取 TCP 数据，用正则等工具从数据中获取 Header 和 Body，从而提取参数。

1. GET主要用于**获取数据**，POST主要用于**修改数据**

2. GET和POST安不安全的问题，要看安全的定义是什么，如果安全的定义是**请求方法不会破坏服务器上的资源**，那么GET是安全的POST不安全，如果安全的定义是在传输角度，那么他俩都不安全，**因为HTTP在网络上是明文传输的，只要在网络节点上抓包，就能完整地获取数据报文。**(**想要安全传输需要用HTTPS**)

3. **GET是幂等的，POST是不幂等的**。（幂等：多次执行相同的操作，结果都是相同的）。**GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。**POST** 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据就会创建多个资源，所以**不是幂等**的。所以，**浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签**。

4. **GET请求的数据会被浏览器主动缓存，POST不能缓存**。

5. **GET提交的数据最大是2K（ 实际上取决于浏览器），POST理论上没有限制。**

6. get把请求的数据放在url上，而post把数据放在请求体内。任何请求都可以**带 body** 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。

7. HTTP 协议没有 Body 和 URL 的**长度限制**，对 URL 限制的大多是浏览器和服务器的原因。

8. **POST 会将 header 和 body 分开发送**，先发送 header，服务端返回 100 状态码再发送 body。

   

**HTTP缓存**

有些重复的请求，我们就可以把这些重复的请求以及他们对应的响应缓存在本地，这样就不至于每次都要获取服务器的响应了，直接在本地缓存里找就行了。

**强制缓存和协商缓存**

强缓存指的是**只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存**，决定是否使用缓存的**主动性在于浏览器这边**。主要通过**Cache-Control**和**Expires**这两个HTTP响应头部(Response Header)字段实现的。**Cache-Control的优先级高于 Expires** 

**协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存**，遇到**304**的时候就是协商缓存了。协商缓存这两个字段**都需要配合强制缓存中 Cache-control 字段来使用**，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求

`Cache-control: private`，私有缓存；`Cache-control: public`，共有缓存

**如何保证最新缓存**：Cache-Control字段中max-age指令出现在请求报文，并且**缓存资源的缓存时间小于该指令指定的时间**，那么就能接受该缓存。



5. 





## HTTP和HTTPS

### HTTP和HTTPS区别

HTTPS主要是**解决了HTTP不安全的问题**，HTTPS**在TCP和HTTP网络层之间加入了(SSL)TLS安全协议**。

HTTP经过TCP三次握手后就可以建立连接进行报文传输，而**HTTPS在TCP三次握手后还要进行(SSL)TLS握手过程，才可以进行加密报文传输**。

HTTP默认端口是**80**，HTTPS默认端口是**443**。

**HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的**。



### HTTPS 的工作过程

1、 客户端发送自己支持的加密规则给服务器，代表告诉服务器要进行连接了；

2、 服务器从中选出一套加密算法和 hash 算法以及自己的身份信息（地址等）以证书的形式发送给浏览器，证书中包含服务器信息，加密公钥，证书的办法机构；

3、客户端收到网站的证书之后要做下面的事情：

- 验证证书的合法性；

- 如果验证通过证书，浏览器会生成一串随机数，并用证书中的公钥进行加密；

- 用约定好的 hash 算法计算握手消息，然后用生成的密钥进行加密，然后一起发送给服务器。

4、服务器接收到客户端传送来的信息，要做下面的事情：

- 4.1 用私钥解析出密码，用密码解析握手消息，验证 hash 值是否和浏览器发来的一致；
- 4.2 使用密钥加密消息；

5、如果计算法 hash 值一致，握手成功。



### HTTPS 的TLS、RSA 握手过程

`RSA` 是最简单的密钥交换算法

**TLS握手过程**

每一个「框」都是一个记录（*record*），记录是 TLS 收发数据的基本单位，类似于 TCP 里的 segment。多个记录可以组合成一个 TCP 包发送，所以**通常经过「四个消息」就可以完成 TLS 握手，也就是需要 2个 RTT 的时延**，然后就可以在安全的通信环境里发送 HTTP 报文，实现 HTTPS 协议。



**RSA握手过程**

**1、第一次握手**

**共包含一条信息：「Client Hello」**

- 客户端首先会发一个「**Client Hello**」消息，字面意思我们也能理解到，这是跟服务器「打招呼」。
- 消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的**随机数（*Client Random*）**，这个随机数会被服务端保留，它是生成对称加密密钥的材料之一。

**2、第二次握手**

**共包含三条信息：「Server Hello」、「Server Certificate」、「Server Hello Done」**

- 当服务端收到客户端的「Client Hello」消息后，会确认 TLS 版本号是否支持，和从密码套件列表中选择一个密码套件，以及生成**随机数（*Server Random*）**。
- 接着，返回「**Server Hello**」消息，消息里面有服务器确认的 TLS 版本号，也给出了随机数（Server Random），然后从客户端的密码套件列表选择了一个合适的密码套件。
- 然后，服务端为了证明自己的身份，会发送「**Server Certificate**」给客户端，这个消息里含有数字证书。
- 随后，服务端发了「**Server Hello Done**」消息，目的是告诉客户端，我已经把该给你的东西都给你了，本次打招呼完毕。

**3、客户端验证证书**

**CA 签发证书**的过程，如上图左边部分：

- 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；
- 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；
- 最后将 Certificate Signature 添加在文件证书上，形成数字证书；

**客户端校验服务端的数字证书**的过程，如上图右边部分：

- 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；
- 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；
- 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。

这里还涉及到证书链，需要从根证书开始逐级验证。

**3、第三次握手**

**共包含三条信息：「Change Cipher Key Exchange」、「Change Cipher Spec」、「Encrypted Handshake Message（Finishd）」**

- 客户端验证完证书后，认为可信则继续往下走。接着，客户端就会生成一个新的**随机数 (*pre-master*)**，用服务器的 RSA 公钥加密该随机数，通过「**Change Cipher Key Exchange**」消息传给服务端。
- 服务端收到后，用 RSA 私钥解密，得到客户端发来的随机数 (pre-master)。
- 双方根据已经得到的三个随机数（***Client Random***、***Server Random***、***pre-master***），生成**会话密钥（Master Secret）**，它是对称密钥，用于对后续的 HTTP 请求/响应的数据加解密。
- 生成完会话密钥后，然后客户端发一个「**Change Cipher Spec**」，告诉服务端开始使用加密方式发送消息。
- 然后，客户端再发一个「**Encrypted Handshake Message（Finishd）**」消息，把之前所有发送的数据做个摘要，再用会话密钥（master secret）加密一下，让服务器做个验证，验证加密通信是否可用和之前握手信息是否有被中途篡改过。

**4、第四次握手**

服务器也是同样的操作，发「**Change Cipher Spec**」和「**Encrypted Handshake Message**」消息，如果双方都验证加密和解密没问题，那么握手正式完成。

最后，就用「会话密钥」加解密 HTTP 请求和响应了。

RSA 算法的缺陷

**使用 RSA 密钥协商算法的最大问题是不支持前向保密**。

因为客户端传递随机数（用于生成对称加密密钥的条件之一）给服务端时使用的是公钥加密的，服务端收到到后，会用私钥解密得到随机数。所以一旦服务端的私钥泄漏了，过去被第三方截获的所有 TLS 通讯密文都会被破解。



### HTTPS建立连接(SSL/TLS加密协议)

SSL/TLS是用于保护网络通信安全的加密协议，通过混合加密的手段保证了信息的安全性。

1. **ClientHello**，客户端向服务器发起加密通信请求，发送信息包括**客户端支持的TLS协议版本**，**客户端产生的随机数**，**客户端支持的密码套件列表**(这里是用RSA算法的TLS握手举例，所以套件列表里就有RSA加密算法)。
2. **ServerHello**，服务器收到请求，向客户端发出响应，响应内容包括**确认TLS协议版本**，如果服务器不支持则关闭通信，**服务器产生的随机数**，**确认的密码套件列表**，**服务器的数字证书**。
3. **客户端回应**，**先通过CA公钥确认服务器的数字证书的真实性**，没问题的话客户端就会从数字证书中**取出服务器的公钥，加密客户端产生的一个随机数**，将这个**随机数**，**加密通信算法改变通知**（以后都用会话密钥通信了），**客户端握手结束通知**（这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验）发给服务器。
4. **服务器最后回应**，**服务器得到三个随机数，通过协商的加密算法，计算出本次通信的会话密钥**，然后给客户端发送信息：**加密通信算法改变通知**，**服务器握手结束通知**（这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验）。

⚠️**使用 RSA 密钥协商算法的最大问题是不支持前向保密**。如果服务器的私钥泄露了就GG了。

⚠️**有的时候刷新页面不需要重新TLS连接**：TCP连接有的时候会被浏览器和服务端维持一段时间，TCP不需要重新建立，TLS自然也会用之前的。



#### 混合加密、摘要算法和数字签名

**混合加密**

HTTPS采用**对称加密**和**非对称加密**结合的**混合加密**方式，在**通信建立前**采用**非对称加密**交换密钥，后续在**通信过程中采用对称加密交换密钥**。

- **非对称加密**使用两个密钥：公钥和私钥，**公钥可以任意分发而私钥保密**，解决了密钥交换问题但速度慢。
- **对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。

**摘要算法和数字签名**

**摘要算法**其实就是用**哈希函数**把内容计算成一个hash值，这个**hash值是唯一的**，且无法通过hash值推导出内容。**先对内容计算一个hash值，hash值连通内容一起传输给对方，对方收到后先对内容计算一个hash值，然后两个hash值进行比较，相同的话内容就没有被篡改，通过这种方式保证了传输过程中报文的完整性。**

⚠️摘要算法能保证内容不被篡改，但是不能保证[内容+hash值]不被替换(也就是被冒充了)，因为缺少了对客户端收到的消息是否来源于服务端的证明

**非对称加密算法**可以解决。一个**公钥**(公开给所有人)一个私钥(本人管理，不可泄露的)，这两个密钥是**双向加密**的，用公钥(私钥)加密，可以用私钥(公钥)解密。但是有不同的意义：

**公钥加密，私钥解密**是为了保证内容传输的安全，公钥加密的内容只有持有私钥的人才能解密；

**私钥加密，公钥解密**是为了保证消息不会被冒充，私钥不可泄露，如果用公钥成功解密了，那么这个消息一定来自于持有私钥的人，所以就不会被冒充了

非对称加密计算比较耗时，一般多用于**通过私钥加密，公钥解密的方式，来确认消息的身份**，也就是**数字签名算法**，不过不是对内容加密而是对hash值加密

**数字证书**

**什么是数字签名**

为了避免数据在传输过程中被替换，比如黑客修改了你的报文内容，但是你并不知道，所以我们让发送端做一个数字签名，把数据的摘要消息进行一个加密，比如 MD5，得到一个签名，和数据一起发送。然后接收端把数据摘要进行 MD5 加密，如果和签名一样，则说明数据确实是真的。

对称加密中，双方使用公钥进行解密。虽然数字签名可以保证数据不被替换，但是数据是由公钥加密的，如果公钥也被替换，则仍然可以伪造数据，因为用户不知道对方提供的公钥其实是假的。所以为了保证发送方的公钥是真的，CA 证书机构会负责颁发一个证书，里面的公钥保证是真的，用户请求服务器时，服务器将证书发给用户，这个证书是经由系统内置证书的备案的。

**数字证书签发和验证流程：**

CA(数字证书认证机构)会先将持有者的公钥和一些信息打包在一起，通过hash计算一个hash值，CA用自己的私钥对这个hash值加密，生成数字签名，这些东西放在证书上就成了数字证书。

客户端验证服务端的数字证书先通过同样的hash算法获取证书的hash值h1，通过CA的公钥解密数字签名得到hash值h2，h1和h2相同，证书就是可靠的。

⚠️但事实上，证书的验证过程中**还存在一个证书信任链的问题**，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的。**这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。**







**HTTPS一定安全可靠吗**

**一定**，如果假基站把消息转到了中间服务器，中间服务器再与真正服务器连接这并不是HTTPS的问题，中间服务器给客户端发自己数字证书的时候，客户端能看出来这个证书非法，会提醒用户，但你仍然”继续浏览此网站“，代表你信任他了这不是HTTPS问题是你的问题。

**HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全**。



**为什么抓包能截取HTTPS数据**

本质上是利用了中间人。抓包工具能够抓包的关键是**客户端会往系统受信任的根证书列表中导入抓包工具生成的证书，而这个证书会被浏览器信任，也就是抓包工具给自己创建了一个认证中心 CA，客户端拿着中间人签发的证书去中间人自己的 CA 去认证，当然认为这个证书是有效的。**

**如何避免被中间人抓包**

我们要保证自己电脑的安全，不要被病毒乘虚而入，而且也不要点击任何证书非法的网站，这样 HTTPS 数据就不会被中间人截取到了。

还可以通过**HTTPS双向认证**，一般HTTPS是单项认证，只有客户端验证服务器身份，没有服务器验证客户端身份











### 对称加密与非对称加密区别

**对称密钥加密**是指加密和解密使用同一个密钥的方式，这种方式存在的最大问题就是密钥发送问题，即如何安全地将密钥发给对方。

- 优点：运算速度快
- 缺点：无法安全地将密钥传输给通信

**非对称加密**是指使用一对非对称密钥，即公钥和私钥，公钥可以随意发布，但私钥只有自己知道。发送密文的一方使用对方的公钥进行加密处理，对方接收到加密信息后，使用自己的私钥进行解密。

由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性；但是和对称加密比起来，它非常的慢，所以我们还是要用对称加密来传送消息，但对称加密所使用的密钥我们可以通过非对称加密的方式发送出去。

- 优点：可以更安全地将公开密钥传输给通信发送方；
- 缺点：运算速度慢



### SSL保证数据传输安全

- （1）客户端向服务器端发起SSL连接请求； 
- （2） 服务器把公钥发送给客户端，并且服务器端保存着唯一的私钥 
- （3）客户端用公钥对双方通信的对称秘钥进行加密，并发送给服务器端 （4）服务器利用自己唯一的私钥对客户端发来的对称秘钥进行解密， 
- （5）进行数据传输，服务器和客户端双方用公有的相同的对称秘钥对数据进行加密解密，可以保证在数据收发过程中的安全，即是第三方获得数据包，也无法对其进行加密，解密和篡改。

因为数字签名、摘要是证书防伪非常关键的武器。 “摘要”就是对传输的内容，通过hash算法计算出一段固定长度的串。然后，通过发送方的私钥对这段摘要进行加密，加密后得到的结果就是“数字签名”

SSL/TLS协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。

**补充**：SSL/TLS的四次握手，目前网上的主流答案都在重复阮一峰老师的博客，属于TLS 1.0版本的答案，使用RSA密钥交换算法。但是现在TLS 1.2已经成为主流，使用ECDHE算法，如果面试可以说出这个版本的答案，应该会更好。

**如何保证公钥不被篡改**

将公钥放在数字证书中。只要证书是可信的，公钥就是可信的。 公钥加密计算量太大，如何减少耗用的时间？ 每一次对话（session），客户端和服务器端都生成一个"对话密钥"（session key），用它来加密信息。由于"对话密钥"是对称加密，所以运算速度非常快，而服务器公钥只用于加密"对话密钥"本身，这样就减少了加密运算的消耗时间。 

- （1） 客户端向服务器端索要并验证公钥。 
- （2） 双方协商生成"对话密钥"。 
- （3） 双方采用"对话密钥"进行加密通信。上面过程的前两步，又称为"握手阶段"（handshake）





### HTTPS 的应用数据如何保证完整性

- TLS 在实现上分为**握手协议**和**记录协议**两层：

  - TLS 握手协议就是我们前面说的 TLS 四次握手的过程，负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）；
  - TLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议；

- TLS 记录协议主要负责消息（HTTP 数据）的压缩，加密及数据的认证，具体过程如下：

  - 首先，消息被分割成多个较短的片段,然后分别对每个片段进行压缩。
  - 接下来，经过压缩的片段会被**加上消息认证码（MAC 值，这个是通过哈希算法生成的），这是为了保证完整性，并进行数据的认证**。通过附加消息认证码的 MAC 值，可以识别出篡改。与此同时，为了防止重放攻击，在计算消息认证码时，还加上了片段的编码。
  - 再接下来，经过压缩的片段再加上消息认证码会一起通过对称密码进行加密。
  - 最后，上述经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。

  记录协议完成后，最终的报文数据将传递到传输控制协议 (TCP) 层进行传输。

**HTTPS 握手会影响性能吗**

- 由裸数据传输的 HTTP 协议转成加密数据传输的 HTTPS 协议，给应用数据套了个「保护伞」，提高安全性的同时也带来了性能消耗
- 因为 HTTPS 相比 HTTP 协议多一个 TLS 协议握手过程，**目的是为了通过非对称加密握手协商或者交换出对称加密密钥**，这个过程最长可以花费掉 2 RTT，接着后续传输的应用数据都得使用对称加密密钥来加密/解密



### HTTPS解决了什么、优化

通过**混合加密**的方式实现了信息的机密性，**解决了信息泄露的问题**

通过**摘要算法**的方式**确保报文的完整性**（摘要算法为数据生成独一无二的指纹，指纹用于校验数据的完整性，**解决了内容被篡改的风险**）

通过**数字签名**的方式保证消息来源的可靠性

将**服务器公钥放到数字证书中**，**解决了伪装的问题**



**HTTPS优化**

**HTTPS主要性能消耗在TLS四次握手的过程，最长可以花费掉两个RTT**

**硬件升级方法**：**HTTPS 协议是计算密集型，而不是 I/O 密集型**，**一个好的 CPU**，可以提高计算性能，因为 HTTPS 连接过程中就有大量需要计算密钥的过程，所以这样可以加速 TLS 握手过程

**软件优化**：1.软件升级；2.**协议优化，就是对密钥交换过程优化**：**RSA 密钥交换算法的 TLS 握手过程，不仅慢，而且安全性也不高**。**尽量选用 ECDHE 密钥交换**算法替换 RSA 算法，因为该算法由于支持「False Start」，客户端可以在 TLS 协议的第 3 次握手后，第 4 次握手前，发送加密的应用数据，以此将 **TLS 握手的消息往返由 2 RTT 减少到 1 RTT，而且安全性也高，具备前向安全性**。或者直接把TLS1.2升级成TLS1.3，**TLS1.3 把 Hello 和公钥交换这两个消息合并成了一个消息，于是这样就减少到只需 1 RTT 就能完成 TLS 握手**。

**证书优化**：**证书传输优化：对于服务器的证书应该选择椭圆曲线（ECDSA）证书，而不是 RSA 证书，因为在相同安全强度下， ECC   密钥长度比 RSA   短的多；服务器应该开启 OCSP Stapling 功能，由服务器预先获得 OCSP 的响应，并把响应结果缓存起来，这样 TLS 握手的时候就不用再访问 CA 服务器，减少了网络通信的开销，提高了证书验证的效率**

这个重要**会话复用**：**缓存TLS握手协商的对称加密密钥，下次HTTPS连接直接复用这个密钥。**

**Ticket和Session**

- 第一种叫 **Session ID**；**客户端和服务器首次 TLS 握手连接后，双方会在内存缓存会话密钥，并用唯一的 Session ID 来标识**，Session ID 和会话密钥相当于 key-value 的关系；它有两个缺点：
  - 服务器必须保持每一个客户端的会话密钥，随着客户端的增多，**服务器的内存压力也会越大**
  - 现在网站服务一般是由多台服务器通过负载均衡提供服务的，**客户端再次连接不一定会命中上次访问过的服务器**，于是还要走完整的 TLS 握手过程；
- 第二种叫 **Session Ticket**，**服务器不再缓存每个客户端的会话密钥，而是把缓存的工作交给了客户端**，类似于 HTTP 的 Cookie；客户端与服务器首次建立连接时，服务器会加密「会话密钥」作为 Ticket 发给客户端，交给客户端缓存该 Ticket。客户端再次连接服务器时，客户端会发送 Ticket，服务器解密后就可以获取上一次的会话密钥，然后验证有效期，如果没问题，就可以恢复会话了，开始加密通信。





**为什么抓包工具能截取 HTTPS 数据**

- 很多抓包工具 之所以可以明文看到 HTTPS 数据，工作原理与中间人一致的。对于 HTTPS 连接来说，中间人要满足以下两点，才能实现真正的明文代理:
  1. 中间人，作为客户端与真实服务端建立连接这一步不会有问题，因为服务端不会校验客户端的身份；
  2. 中间人，作为服务端与真实客户端建立连接，这里会有客户端信任服务端的问题，也就是服务端必须有对应域名的私钥；
- 中间人要拿到私钥只能通过如下方式：去网站服务端拿到私钥；去CA处拿域名签发私钥；自己签发证书，且要被浏览器信任；抓包工具只能使用第三种方式取得中间人的身份。
- 使用抓包工具进行 HTTPS 抓包的时候，需要在客户端安装 Fiddler 的根证书，这里实际上起认证中心（CA）的作用。
- 抓包工具能够抓包的关键是客户端会往系统受信任的根证书列表中导入抓包工具生成的证书，而这个证书会被浏览器信任，也就是抓包工具给自己创建了一个认证中心 CA，客户端拿着中间人签发的证书去中间人自己的 CA 去认证，当然认为这个证书是有效的。

**如何避免被中间人抓取数据**

- 可以通过 **HTTPS 双向认证**来避免这种问题
- 如果用了双向认证方式，不仅客户端会验证服务端的身份，而且服务端也会验证客户端的身份。服务端一旦验证到请求自己的客户端为不可信任的，服务端就拒绝继续通信，客户端如果发现服务端为不可信任的，那么也中止通信











**HTTPS 中 TLS 和 TCP 能否同时握手**

需要下面这两个条件同时满足才可以：

- **客户端和服务端都开启了 TCP Fast Open 功能，且 TLS 版本是 1.3；**
- **客户端和服务端已经完成过一次通信。**

如果 HTTPS 的 TLS 版本是 1.3，那么 TLS 过程只需要 1-RTT。

**因此如果「TCP Fast Open + TLSv1.3」情况下，在第二次以后的通信过程中，TLS 和 TCP 的握手过程是可以同时进行的。**

**如果基于 TCP Fast Open 场景下的 TLSv1.3 0-RTT 会话恢复过程，不仅 TLS 和 TCP 的握手过程是可以同时进行的，而且 HTTP 请求也可以在这期间内一同完成。**



**ECDHE加密算法**

- DH 算法：核心数学思想是**离散对数**，离散对数是在对数运算的基础上加了模运算

  ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E7%A6%BB%E6%95%A3%E5%AF%B9%E6%95%B0.png)

  底数 a 和模数 p 是离散对数的公共参数，b 是真数，i 是对数。知道了对数，就可以计算出真数。但反过来，知道真数却很难推算出对数。**当模数 p 是一个很大的质数，即使知道底数 a 和真数 b ，在现有的计算机的计算水平是几乎无法算出离散对数**

- DH 算法是如何密钥交换的：

  - 需要先确定模数和底数作为算法的参数，这两个参数是公开的，用 P 和 G 来代称
  - 然后各自生成一个随机整数作为**私钥**，双方的私钥要各自严格保管，不能泄漏，小红的私钥用 a 代称，小明的私钥用 b 代称
  - 于是就可以计算出**公钥**：
    - 小红的公钥记作 A，A = G ^ a ( mod P )；
    - 小明的公钥记作 B，B = G ^ b ( mod P )；
    - 从真数（A 和 B）反向计算对数 a 和 b 是非常困难的，至少在现有计算机的计算能力是无法破解的
  - 双方交换各自 DH 公钥后，小红手上共有 5 个数：P、G、a、A、B，小明手上也同样共有 5 个数：P、G、b、B、A。然后小红执行运算： B ^ a ( mod P )，其结果为 K，因为离散对数的幂运算有交换律，所以小明执行运算： A ^ b ( mod P )，得到的结果也是 K。这个 K 就是小红和小明之间用的**对称加密密钥**，可以作为会话密钥使用。

- DHE 算法：

  -  **static DH 算法不具备前向安全性**，static DH 算法里有一方的私钥是静态的，密钥协商的过程有些数据是公开的，黑客就可以依据这些数据暴力破解出服务器的私钥，然后就可以计算出会话密钥了，于是之前截获的加密数据会被破解
  -  既然固定一方的私钥有被破解的风险，那么干脆就让双方的私钥在每次密钥交换通信时，都是随机生成的、临时的，这个方式也就是 DHE 算法，E 全称是 ephemeral（临时性的）
  -  即使有个牛逼的黑客破解了某一次通信过程的私钥，其他通信过程的私钥仍然是安全的，因为**每个通信过程的私钥都是没有任何关系的，都是独立的，这样就保证了「前向安全」**
  -  DHE 算法由于计算性能不佳，因为需要做大量的乘法，为了提升 DHE 算法的性能，所以就出现了现在广泛用于密钥交换算法 —— **ECDHE 算法**

- 使用 ECDHE 密钥交换算法的过程：

  - 双方事先确定好使用哪种椭圆曲线，和曲线上的基点 G，这两个参数都是公开的；
  - 双方各自随机生成一个随机数作为**私钥d**，并与基点 G相乘得到**公钥Q**（Q = dG），此时小红的公私钥为 Q1 和 d1，小明的公私钥为 Q2 和 d2；
  - 双方交换各自的公钥，最后小红计算点（x1，y1） = d1Q2，小明计算点（x2，y2） = d2Q1，由于椭圆曲线上是可以满足乘法交换和结合律，所以 d1Q2 = d1d2G = d2d1G = d2Q1 ，因此**双方的 x 坐标是一样的，所以它是共享密钥，也就是会话密钥**。

  这个过程中，双方的私钥都是随机、临时生成的，都是不公开的，即使根据公开的信息（椭圆曲线、公钥、基点 G）也是很难计算出椭圆曲线上的离散对数（私钥）

- **最终的会话密钥，就是用「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料生成的**

- RSA 和 ECDHE 握手过程的区别：

  - RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法「支持」前向保密；

  - 使用了 RSA 密钥协商算法，TLS 完成四次握手后，才能进行应用数据传输，而对于 ECDHE 算法，客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据，节省了一个消息的往返时间；

  - 使用 ECDHE， **在 TLS 第 2 次握手中，会出现服务器端发出的「Server Key Exchange」消息，而 RSA 握手过程没有该消息**；



## HTTP版本

### HTTP/1.1

HTTP/1.1最突出的**优点**是：**简单**：报文格式易于理解；灵活和易于扩展：HTTP协议里的各种内容都不是固定死的，允许开发人员自定义和扩充；**应用广泛和跨平台**。

**缺点**：**双刃剑-无状态**：服务器不记忆HTTP的状态，所以不需要额外的资源，能减轻服务器负担；而因为无状态，所以完成有关联性的操作就比较麻烦。解决无状态的问题方法：**Cookie**技术，就是服务器第一次响应的时候**下发一个Cookie记录信息给客户端**，后续客户端再请求的时候带着Cookie，服务器就知道是谁了。

**双刃剑-明文传输**：好处是方便阅读，坏处是容易被盗号。

**严重的缺点：不安全**，明文传输，所以可能信息泄露；不验证通信双方的身份，所以可能遇到伪装；无法证明报文的完整性，报文有可能遭篡改。

### HTTP1.1优化

HTTP1.1每次都会互相发送相同的首部，在有重复的HTTP请求的时候**尽量避免发送HTTP请求，用HTTP缓存技术**，**Cache-Control字段中的max-age指令可以保证缓存是最新的**，指令出现在请求报文，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存。max-age 指令出现在响应报文，表示缓存资源在缓存服务器中保存的时间。

**减少HTTP请求次数**：**减少重定向次数，合并请求，延迟发送请求**

**减少HTTP响应数据的大小**：对响应的资源进行**压缩**，这样就可以减少响应的数据大小，从而提高网络传输的效率

### HTTP1.1、1.0区别

**HTTP1.1使用长连接，HTTP1.0使用短连接**；HTTP1.1支持**管道网络传输**，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去

**缺点**：**请求头或者响应头不压缩就发送**，这样首部信息越多延迟越大；**每次都会互相发送相同的首部**；**服务器是按请求顺序响应的**，如果服务器响应慢则客户端就会一直请求不到数据，造成**队头阻塞**；**没有请求优先级控制**；**请求只能从客户端开始，服务器只能被动响应**。

### HTTP/2改进

**1. 头部压缩；2. 二进制格式；3. 并发传输； 4. 服务器可以主动推送资源**

HTTP/2会**压缩Heade**r，如果同时发送多个请求，他们Header一样，协议会**消除重复的部分**。就是客户端和服务器同时维护了一个头信息表，所有字段都存在表里，每次发送索引号就行。

HTTP/2**报文都是二进制格式，增加了数据传输效率**。

**并发传输**，多个**Stream**复用在一条TCP连接上，解决了队头HTTP1.1的队头阻塞。**针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应**。

⚠️HTTP2可以做到一个TCP连接中多个HTTP请求一起发送，就是因为这个stream。

客户端和服务器**双方都可以建立 Stream**， Stream ID也是有区别的，客户端建立的Stream必须是奇数号，而服务器建立的Stream必须是偶数号。

**缺点**：HTTP2有自己的队头阻塞，因为HTTP2是基于TCP协议传输的，TCP是面向字节流协议，TCP层必须保证收到的字节数据是完整且连续的，当前一个字节数据没有到达时，后到达的字节数据只能存在内核缓冲区中，只有等这一个字节数据到达了，HTTP/2应用层才能从内核中拿到数据，这就是HTTP/2的队头阻塞。

**虽然可以主动推送资源但是依然是在客户端发起请求之后才新增的**。

### HTTP/3改进（QUIC协议）

HTTP1.1解决了请求队头阻塞没有解决响应队头阻塞，这是HTTP层的队头阻塞；HTTP2解决了HTTP的队头阻塞，但是基于TCP传输的会有TCP层的队头阻塞。

所以HTTP3把下层协议改成了UDP。而且**基于UDP的QUIC协议还可以实现类似TCP的可靠传输，三个特点**：**无队头阻塞，更快的连接建立，连接迁移**

- ***无队头阻塞*：**

  QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。

  QUIC 有自己的一套机制可以保证传输的可靠性的。**当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题**。**QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口**。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。

  所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。

- ***更快的连接建立*：**

  对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。

  HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。

  但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商。甚至，在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。

- ***连接迁移***

  基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。

  那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接**。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

  而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID**来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

**QUIC 是一个在 UDP 之上的伪 TCP + TLS + HTTP/2 的多路复用的协议。**









## HTTP长连接和短连接

**短连接：**

在 HTTP/1.0 中默认使用短连接。客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个 HTML 或其他类型的 Web 页中包含有其他的 Web 资源（图像文件、CSS 文件等），每遇到这样一个 Web 资源，浏览器就会重新建立一个 HTTP 会话。

**长连接：**

而 HTTP/1.1 ，默认使用长连接，用以保持连接特性。使用长连接的 HTTP 协议，会在响应头加入这行代码：

```
Connection:keep-alive
```

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。

Keep-Alive 不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如：Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。

**使用场景**

**长连接**：

1. 需要实时交互的应用，如在线游戏、即时通讯、实时数据同步等。
2. 需要长时间维持连接的应用，如数据库连接，大文件传输等。

**短连接**：

1. 不需要频繁交互，只偶尔进行数据传输的应用。
2. 对连接的安全性要求较高的应用，如银行系统。因为短连接在每次连接后都会断开，从而降低被恶意利用的风险。

**HTTP 如何实现长连接，在什么时候会超时**

通过在头部（请求和响应头）设置 Connection: keep-alive，HTTP1.0协议支持，但是默认关闭，从HTTP1.1协议以后，连接默认都是长连接

1、HTTP 一般会有 httpd 守护进程，里面可以设置 keep-alive timeout，当 tcp 链接闲置超过这个时间就会关闭，也可以在 HTTP 的 header 里面设置超时时间

2、TCP 的 keep-alive 包含三个参数，支持在系统内核的 net.ipv4 里面设置：当 TCP 链接之后，闲置了 tcp_keepalive_time，则会发生侦测包，如果没有收到对方的 ACK，那么会每隔 tcp_keepalive_intvl 再发一次，直到发送了 tcp_keepalive_probes，就会丢弃该链接。

（1）tcp_keepalive_intvl = 15
（2）tcp_keepalive_probes = 5
（3）tcp_keepalive_time = 1800

实际上 HTTP 没有长短链接，只有 TCP 有，TCP 长连接可以复用一个 TCP 链接来发起多次 HTTP 请求，这样可以减少资源消耗，比如一次请求 HTML，可能还需要请求后续的 JS/CSS/图片等



### HTTP长连接和TCP长连接

这两个东西不是一个东西，一个是HTTP的长连接机制，一个是TCP的保活机制

**HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。HTTP/1.1默认长连接，一般要指定长连接的超时时间，keeplive_timeout一般是60s，60s内没有数据发送就触发回调函数关闭连接**

保护机制详细内容在**建立连接后客户端宕机**



TCP 最大连接数限制

**如何标识一个TCP连接**

在确定最大连接数之前，先来看看系统如何标识一个tcp连接。系统用一个4四元组来唯一标识一个TCP连接：{local ip, local port,remote ip,remote port}。

**client最大tcp连接数**

client每次发起tcp连接请求时，除非绑定端口，通常会让系统选取一个空闲的本地端口（local port），该端口是独占的，不能和其他tcp连接共享。tcp端口的数据类型是unsigned short，因此本地端口个数最大只有65536，端口0有特殊含义，不能使用，这样可用端口最多只有65535，所以在全部作为client端的情况下，最大tcp连接数为65535，这些连接可以连到不同的server ip。

**server最大tcp连接数**

server通常固定在某个本地端口上监听，等待client的连接请求。不考虑地址重用（unix的SO_REUSEADDR选项）的情况下，即使server端有多个ip，本地监听端口也是独占的，因此server端tcp连接4元组中只有remote ip（也就是client ip）和remote port（客户端port）是可变的，因此最大tcp连接为客户端ip数×客户端port数，对IPV4，不考虑ip地址分类等因素，最大tcp连接数约为2的32次方（ip数）×2的16次方（port数），也就是server端单机最大tcp连接数约为2的48次方。

**实际的tcp连接数**

上面给出的是理论上的单机最大连接数，在实际环境中，受到机器资源、操作系统等的限制，特别是sever端，其最大并发tcp连接数远不能达到理论上限。在unix/linux下限制连接数的主要因素是内存和允许的文件描述符个数（每个tcp连接都要占用一定内存，每个socket就是一个文件描述符），另外1024以下的端口通常为保留端口。在默认2.6内核配置下，经过试验，每个socket占用内存在15~20k之间。



## Cookie与Session

**Cookie**技术，就是服务器第一次响应的时候**下发一个Cookie记录信息给客户端**，后续客户端再请求的时候带着Cookie，服务器就知道是谁了。

**主要是保存状态信息**

**Cookie作用**：

- 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
- 个性化设置（如用户自定义设置、主题等）
- 浏览器行为跟踪（如跟踪分析用户行为等）

**Session**：

除了可以**将用户信息通过Cookie存储在用户浏览器中**，也可以**利用Session存储在服务器端**，存储在服务器端的信息更加安全。

Session可以存储在服务器上的文件、数据库或者内存中。也可以将Session存储在Redis这种内存型数据库中，效率会更高。

session的工作原理是客户端登录完成之后，服务器会创建对应的session，session创建完之后，**会把session的id发送给客户端**，客户端再存储到浏览器中。这样客户端每次访问服务器时，都会带着session id，服务器拿到session id之后，**在内存找到与之对应的session这样就可以正常工作了**。

⚠️补充：Session ID一般都是放在Cookie中传给对方的，所以Cookie就是运载Session的一种方式，而且Session ID只是一个单纯的ID没有任何用户密码信息，所以即使被知道了Session ID也没用，也不能盗取密码。

**怎么选择应用场景**：

- Cookie只能存储**ASCII码字符串**，而Session则可以存储**任何类型的数据**，因此在考虑数据复杂性时首选Session；
- **Cookie存储在浏览器中，容易被恶意查看。**如果非要将一些隐私数据存在Cookie中，可以将Cookie值进行加密，然后在服务器进行解密；
- 对于大型网站，如果用户所有的信息都存储在Session中，那么开销是非常大的，因此**不建议将所有的用户信息都存储到Session中**。

**关闭浏览器Session就失效了：**

这是**不对**的，对Session来说，除非程序通知服务器删除一个session，否则服务器会一直保留。之所以会有失效这种错觉是因为session机制大部分通过会话cookie来保存session id，关闭浏览器后这个session id就失效了，再次连接服务器时也就无法找到原来的session。如果cookie被保存在硬盘上，那还是能打开原来的session。

cookie和session的区别

Cookie和Session都是在服务器和客户端之间**保存状态信息的技术**

**存储位置**：Cookie保存在**客户端**（也就是用户的浏览器），而Session保存在**服务器端。**

**存储容量**：由于Cookie保存在客户端，所以它的大小受到限制，通常每个网站最多只能存储20个Cookie，每个Cookie的大小限制为4KB。而Session是保存在服务器端的，理论上它没有大小限制，但是过多的数据存储在Session中会增加服务器的负担。

**数据类型**：Cookie只支持保存文本数据，需要通过编码和解码来存储和读取复杂数据；而Session可以存储任何类型的数据，如对象或数据结构等。

**安全性**：由于Cookie保存在客户端，因此相比于Session来说，其安全性相对较低。如果敏感信息在Cookie中被窃取或篡改，可能会导致安全问题。而Session保存在服务器端，只返回给客户端一个识别标识（通常是Session ID），敏感信息不会在网络上传输，所以更加安全。

**如何解决分布式 session 的问题**

在互联网公司为了可以支撑更大的流量，后端往往需要**多台服务器**共同来支撑前端用户请求，那如果用户在 A 服务器登录了，第二次请求跑到服务 B 就会出现登录失效问题。

分布式 Session 一般会有以下几种解决方案：

1. 客户端存储：直接将信息存储在 cookie 中，cookie是存储在客户端上的一小段数据，客户端通过 http 协议和服务器进行 cookie 交互，通常用来存储一些不敏感信息
2. Nginx ip_hash 策略：服务端使用 Nginx 代理，每个请求按访问 IP 的 hash 分配，这样来自同一 IP 固定访问一个后台服务器，避免了在服务器 A 创建 Session，第二次分发到服务器 B 的现象。
3. Session 复制：任何一个服务器上的 Session 发生改变（增删改），该节点会把这个 Session 的所有内容序列化，然后广播给所有其它节点。
4. 共享 Session：服务端无状态话，将用户的 Session 等信息使用缓存中间件（如Redis）来统一管理，保障分发到每一个服务器的响应结果都一致。

**建议采用共享 Session 的方案。**



**cookie 和 session 是如何配合的**

1. 用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 Session 
2. 请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器
3. 浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名。
4. 当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端
5. 服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分系统也是根据此原理来验证用户登录状态。



# TCP篇

**TCP头格式有哪些**

**TCP头部和UDP首部**

![](https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230534096.png)

- **序列号**：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「**数据字节数**」的大小。**用来解决网络包乱序问题。**

- **确认应答号**：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**用来解决丢包的问题。**

- **控制位：**

  - *ACK*：该位为 `1` 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 `SYN` 包之外该位必须设置为 `1` 。
  - *RST*：该位为 `1` 时，表示 TCP 连接中出现异常必须强制断开连接。
  - *SYN*：该位为 `1` 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
  - *FIN*：该位为 `1` 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位为 1 的 TCP 段

  

  **发送的 TCP 报文：**

  - **公式一：序列号 = 上一次发送的序列号 + len（数据长度）。特殊情况，如果上一次发送的报文是 SYN 报文或者 FIN 报文，则改为 上一次发送的序列号 + 1。**
  - **公式二：确认号 = 上一次收到的报文中的序列号 + len（数据长度）。特殊情况，如果收到的是 SYN 报文或者 FIN 报文，则改为上一次收到的报文中的序列号 + 1。**

  **序列号是解决网络包乱序问题，确认号是用来解决丢包的问题**

![](https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230439961.png)

**TCP是面向连接的，可靠的，基于字节流的传输层通信协议**

![](https://cdn.xiaolincoding.com//mysql/other/format,png-20230309230436594.png)

理论上是这么些，但是实际上达不到会有别的因素限制。

⚠️**TCP连接数量限制主要看浏览器设置，Chrome最多是允许同一个Host建立6个TCP连接。**

TCP协议全称为Transmission Control Protocol，中文叫做传输控制协议。它是一种面向连接的、可靠的、基于字节流的传输层通信协议。TCP协议在Internet协议族中被广泛使用，是网络通信中最常见的协议之一。

**TCP常见参数**

1. `tcp_tw_reuse`：默认情况下，TCP 会将处于 TIME-WAIT 状态的连接端口保持 2MSL（Maximum Segment Lifetime）时间（通常为几分钟）。启用 `tcp_tw_reuse` 参数可以允许复用这些端口，从而减少端口资源的消耗。
2. `tcp_tw_recycle`：启用 `tcp_tw_recycle` 参数可以开启 TCP TIME-WAIT 快速回收机制。这种机制可以重新使用 TIME-WAIT 状态的连接端口，并快速回收它们，以便更有效地利用端口资源。
3. `tcp_fin_timeout`：TCP 连接关闭后，会进入 TIME-WAIT 状态，此时会等待一段时间以确保连接的可靠关闭。`tcp_fin_timeout` 参数指定了连接保持在 TIME-WAIT 状态的超时时间，通常以秒为单位。
4. `tcp_keepalive_time`：TCP keep-alive 机制用于检测空闲连接或闲置会话。`tcp_keepalive_time` 参数定义了发送 TCP keep-alive 探测报文的时间间隔。如果连接在一段时间内没有活动，则会发送探测报文以确定连接是否仍然有效。
5. `tcp_keepalive_probes`：当 TCP keep-alive 探测报文未收到响应时，将进行多次重试。`tcp_keepalive_probes` 参数指定了重试的次数。
6. `tcp_keepalive_intvl`：在发送 TCP keep-alive 探测报文的重试过程中，定义了重试的间隔时间。`tcp_keepalive_intvl` 参数指定了重试的间隔时间。
7. `tcp_syncookies`：启用 `tcp_syncookies` 参数可以提供一种防止 SYN 攻击的机制。当系统 SYN 队列满时，会使用 SYN cookies 替代传统的 SYN 队列，以减轻服务器负担。
8. `tcp_max_syn_backlog`：`tcp_max_syn_backlog` 参数设置了 SYN 队列的最大长度，即等待进行三次握手的连接的最大数量。
9. `tcp_max_tw_buckets`：`tcp_max_tw_buckets` 参数定义了系统中允许的最大 TIME-WAIT 桶（用于存储处于 TIME-WAIT 状态的连接信息）的数量。如果 TIME-WAIT 桶已满，新的连接将被丢弃。
10. `tcp_max_orphans`：`tcp_max_orphans` 参数指定了系统允许的最大孤立连接（即没有与之关联的进程）的数量。孤立连接可能是由于网络中断或意外终止导致的。
11. `tcp_rmem`：`tcp_rmem` 参数用于设置 TCP 接收缓冲区的大小。它包含了三个值，分别是最小值、默认值和最大值。这些值决定了应用程序接收数据时的缓冲区大小。
12. `tcp_wmem`：`tcp_wmem` 参数用于设置 TCP 发送缓冲区的大小。类似于 `tcp_rmem`，它也包含了最小值、默认值和最大值。
13. `tcp_mem`：`tcp_mem` 参数设置了系统级别的 TCP 缓冲区大小限制。它包含了三个值，分别是低压缩阈值、高压缩阈值和最大压缩比。这些值可以影响 TCP 缓冲区的调整和分配。
14. `tcp_syn_retries`：在建立 TCP 连接时，SYN 报文未收到响应时的重试次数。`tcp_syn_retries` 参数指定了重试的次数。
15. `tcp_synack_retries`：在建立 TCP 连接时，SYN-ACK 报文未收到响应时的重试次数。`tcp_synack_retries` 参数指定了重试的次数。
16. `tcp_retries1`：在建立 TCP 连接时，除了 SYN 和 SYN-ACK 报文外的其他报文未收到响应时的重试次数。`tcp_retries1` 参数指定了重试的次数。
17. `tcp_retries2`：在关闭 TCP 连接时，FIN 报文未收到响应时的重试次数。`tcp_retries2` 参数指定了重试的次数。





## TCP概念

TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

- **面向连接**：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；
- **可靠的**：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；
- **字节流**：用户消息通过 TCP 协议传输时，消息可能会被操作系统分组成多个的 TCP 报文，如果接收方的程序如果不知道消息的边界是无法读出一个有效的用户消息的。并且 TCP 报文是有序的，当前一个TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对重复的 TCP 报文会自动丢弃

什么是 TCP 连接

- 简单来说就是，**用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接**，建立一个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识
  - **Socket**：由 IP 地址和端口号组成
  - **序列号**：用来解决乱序问题等
  - **窗口大小**：用来做流量控制(流量控制是作用于接收者的)

如何唯一确定一个 TCP 连接

- TCP 四元组可以唯一的确定一个连接，四元组包括如下：源地址、源端口、目的地址、目的端口
- 源地址和目的地址的字段（32位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。源端口和目的端口的字段（16位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程



UDP 头部没有首部长度字段，而 TCP 有

- 原因是 TCP 有**可变长**的「选项」字段，而 UDP 头部长度则是**不会变化**的，无需多一个字段去记录 UDP 的首部长度。

UDP 头部有包长度字段，而 TCP 无

- TCP 是如何计算负载数据长度：TCP数据总长度 = IP 总长度 - IP 首部长度 -TCP 首部长度 ；其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。
- UDP 也是基于 IP 层的呀，那 UDP 的数据长度也可以通过这个公式计算；这么一问，确实感觉 UDP 「包长度」是冗余的。估计是**因为为了网络设备硬件设计和处理方便，首部长度需要是 `4`字节的整数倍**

udp 调用 connect 有什么用

1. 让应用程序可以接收到底层的**错误信息**，因为 connect 是将 UDP 套接字与服务端的端口和 IP 地址建立映射关系，有了这个映射关系操作系统内核就可以将 ICMP 的不可达信息与 UDP 套接字进行关联，从而进一步将这个错误信息通知给应用程序。而不适用 connect 的话，OS 是无法通过 ICMP 信息找到应用程序的，自然就没有办法通知到应用了。
2. UDP 需要调用 connect 之后才能使用 `send()` 和 `recv()` ，否则只能使用 `sendto()` 和 `recvfrom()` 。
3. 客户端通过 connect 绑定服务端的地址和端口，对 UDP 有一定程度的**性能提升**。如果不使用 connect 的话，客户端每次发送报文都需要频繁连接断开套接字（**连接套接字→发送报文→断开套接字→连接套接字→发送报文→断开套接字 →………**），而使用 connect 后只需要连接断开一次套接字即可（**连接套接字→发送报文→发送报文→……→最后断开套接字**），连接套接字是需要一定开销的，比如需要查找路由表信息。所以，UDP 客户端程序通过 connect 可以获得一定的性能提升。



## TCP和UDP的区别

1. TCP是面向连接的，UDP是无连接的，就是发送之前不需要建立连接
2. TCP是一对一的，UDP可以一对一，一对多，多对多
3. TCP可靠，通过TCP传输的数据无差错，不丢失不重复；UDP不可靠，是尽最大努力交付，不保证可靠交付数据（可以基于UDP的QUIC实现可靠传输）
4. TCP是面向字节流的，没有边界，但是保证顺序和可靠；UDP是面向报文的，一个包一个包传输，有边界，但是可能会乱序和丢包
5. TCP有拥塞控制和流量控制机制，UDP没有，所以网络拥堵了也不会影响UDP传输速率，因此视频会议用UDP
6. TCP首部开销大，至少20个字节；UDP首部开销小，只有8个字节
7. **TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片**，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。**UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片**，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。
8. TCP**提供全双工通信**。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；



## TCP/IP五层模型协议

1. **物理层**

- 作用：负责媒体、信号和二进制传输。

  协议：通常与具体协议无关，因为它关注的是低级数据传输。

  硬件设备：包括网线（如以太网线缆）、光纤、网卡、集线器等。

2. **数据链路层**

- 作用：链路层主要负责通过网络介质在网络设备间传输原始比特流。它处理与物理网络硬件接口的交互，包括控制操作系统如何访问网络介质、帧传输、MAC地址寻址以及错误检测和修正。
- 硬件设备：网桥、交换机。

| **协议** | **名称**         | **作用**                                                     |
| -------- | ---------------- | ------------------------------------------------------------ |
| ARP      | 地址解析协议     | 根据IP地址获取物理地址                                       |
| RARP     | 反向地址转换协议 | 根据物理地址获取IP地址                                       |
| PPP      | 点对点协议       | 用来通过拨号或专线方式建立点对点连接发送数据，使其成为各种主机、网桥和路由器之间简单连接的一种共通的解决方案 |

3. **网络层**

- **作用**：网络层负责在多个网络之间转发数据包。这层的主要任务是选择路由来传输数据，以及处理数据包的分段和重组。

- 硬件设备：路由器。

- 协议：IP、ICMP、IGMP。 

- **IP**

  原理: IP 是负责将数据包从一个点发送到另一个点的核心网络层协议。IP 提供不可靠、无连接的数据传输服务，不保证数据包的成功到达，且不需要事先建立连接。

  **ICMP** （ping)

  原理: ICMP 用于网络中的诊断和错误报告。当某个网络设备无法将数据包路由至目的地时，它可以发送一个 ICMP 错误消息到数据包的来源。常见的 ICMP 消息包括回显请求和回显回复（用于ping命令）以及目的不可达消息。

  **IGMP**

  原理: IGMP 用于管理多播组成员资格。多播是一种网络传输机制，允许一个数据包被送至多个目的地。

4. **传输层**

- 作用：传输层负责为运行在不同主机上的应用程序之间提供端到端的通信。它主要管理数据包的传输，确保数据能够按顺序、可靠地传递。
- 协议：TCP、UDP

- **TCP** 

  原理: TCP 是一种面向连接的协议，它提供可靠的、顺序的和基于字节流的通信。

  **TCP的工作过程：**

  建立连接: 通过三次握手过程建立客户端和服务器之间的连接。

  数据传输: 数据以字节流的形式发送，TCP保证数据的顺序和可靠性，如果发生丢包，TCP会要求重传。

  终止连接: 通过四次挥手过程终止客户端和服务器之间的连接。

  TCP 用于那些需要准确数据传输的应用，如网页浏览、文件传输、电子邮件发送等。

- **UDP** 

  原理: UDP 是一种无连接的协议，它提供了一种最小化的、面向事务的传输服务。

  **UDP的工作过程：**

  发送数据包: 数据以独立的包的形式发送，每个数据包（称为数据报）都是单独发送的。

  不保证传输: UDP不保证数据包的顺序、可靠性或数据完整性。如果数据包丢失，UDP不会重新发送。

  无连接状态: UDP不需要像TCP那样在通信之前建立连接，也不需要维护连接状态，从而减少了开销和延迟。

- UDP 用于那些可以容忍一定数据丢失，但要求低延迟和高性能的应用，如在线游戏、语音和视频通话、实时视频会议等。

**5. 应用层**

- **作用**：负责提供应用程序间的通信。
- 协议：HTTP、FTP、SMTP、DNS、Telnet、SSH。

- **HTTP** 

  原理: HTTP 是基于请求/响应模型的无状态协议。客户端发送一个请求到服务器，请求可以是获取一个网页的内容，提交表单数据等。服务器处理请求并返回响应，响应包含了请求的资源，如HTML页面、图片、文件等。HTTP通常运行在TCP协议之上，使用80端口。

- **FTP**

  原理: FTP 是用于在网络上进行文件传输的协议。它允许用户执行文件上传和下载操作。FTP会建立两个TCP连接：一个是控制连接（通常使用21端口），用于传输控制信息（如认证、命令等），另一个是数据连接，用于实际的文件传输。用户必须通过认证（用户名和密码）才能访问FTP服务器。

- **SMTP**

  原理: SMTP 是一个用于发送邮件的协议。它负责将邮件从发送者的邮件服务器传输到接收者的邮件服务器。SMTP 只负责邮件的发送而不负责邮件的接收，邮件接收通常使用POP3或IMAP协议。SMTP 通常在25端口运行。

- **DNS**

  原理: DNS 将容易记忆的域名转换成IP地址，使得用户可以通过域名访问网站而不需要记忆复杂的数字地址。当用户输入一个域名时，DNS服务器会进行解析，返回对应的IP地址。

- **Telnet**

  原理: Telnet 是一种客户端-服务器协议，主要用于远程控制。通过Telnet，用户可以在本地计算机上登录并在远程计算机上执行命令。它是一种不安全的协议，因为所有传输的数据（包括密码）都是未加密的，现在已经被更安全的SSH所取代。

- **SSH** 

  原理: SSH 与Telnet类似，提供远程登录和执行命令的功能，但它在传输数据时使用加密，保证了通信的安全。SSH不仅加密了登录会话，还提供了对数据完整性的校验和可能的压缩，使得它成为远程管理服务器的首选协议。SSH 默认运行在22端口。



### TCP和UDP对应于应用层哪些协议  

|                            TCP                             |                             UDP                              |
| :--------------------------------------------------------: | :----------------------------------------------------------: |
|         **FTP**：定义了文件传输协议，使用21端口。          |         **DNS**：用于域名解析服务，用的是53号端口。          |
|      **Telnet**：它是一种用于远程登陆的端口，23端口。      |         **SNMP**：简单网络管理协议，使用161号端口。          |
| **SMTP**：定义了简单邮件传送协议，服务器开放的是25号端口。 | **TFTP**(Trival File Transfer Protocal)：简单文件传输协议，端口69。 |
|        **POP3**：它是和SMTP对应，POP3用于接收邮件。        |                                                              |



## TCP三次握手

- 三次握手的目的是建立连接，可靠地初始化连接双方的序列号和确认号以及交换TCP窗口大小信息。

1. **第一次握手（SYN）**
   - **客户端**发送一个SYN标志位为1的TCP段给服务器以开始一个新的连接，这时客户端选择一个初始序列号（seq=x）。客户端进入**SYN_SENT**状态，表示正在等待对方的SYN-ACK确认。
2. **第二次握手（SYN-ACK）**
   - **服务器**接收到SYN段后，如果同意建立连接，则发送一个SYN标志位和ACK标志位都为1的TCP段作为响应。该段中的确认号被设置为客户端序列号加1（ack=x+1），同时服务器也选择自己的一个初始序列号（seq=y）。服务器进入**SYN_RECEIVED**状态，此时服务器已经准备好接受客户端的ACK。
3. **第三次握手（ACK）**
   - **客户端**接收到服务器的SYN-ACK段后，发送一个ACK标志位为1的TCP段，序列号被设置为初始序列号加1（seq=x+1），确认号被设置为服务器的序列号加1（ack=y+1）。一旦发送完这个ACK段，客户端进入**ESTABLISHED**状态，表示客户端到服务器的连接已经打开，可以开始数据传输。
   - **服务器**收到这个ACK段之后，也进入**ESTABLISHED**状态，此时服务器到客户端的连接也打开了，双方可以开始数据通信。





**一开始客户端是Closed的状态，服务器是Listen的状态，开始进行三次握手：客户端先给服务器发送一个SYN报文，报文中SYN标志位为1**（SYN=1的报文段不能携带数据，但要消耗掉一个序列号），**初始化序列号为x，客户端变成SYN_SEND状态；客户端收到报文后，以自己的SYN报文作为应答，这个报文中ACK和SYN标志位都是1，初始化序列号seq = y，确认号ack = x + 1，服务器变成SYN_RCVD状态；客户端收到报文后，再发送一个ACK报文**（ACK报文段可以携带数据），**ACK标志位为1，序列号为x + 1，确认号为y + 1，此时客户端状态变为ESTABLISHED状态，服务器收到ACK报文后也变成ESTABLISHED状态，连接成功。**

⚠️**TCP第三次握手可以携带数据**





### 为什么是三次

**三次才能保证客户端和服务器都具有发送和接收的能力**

**三次握手才可以阻止历史连接去初始化连接**：**在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费。**就是服务器收到报文我就建立连接，旧报文阻塞了发了个新报文，但是旧报文先到了，由于这个报文是旧报文，服务器发送完数据后客户端比对了会再发送一个RST，服务器收到之后就断开了。这样建立了各旧的连接服务器还发送了数据，浪费资源。

**三次握手才能同步初始序列号**，**三次握手可以避免资源浪费**，两次就握手了的话，客户端报文阻塞的话就会重新发很多，每来一个报文就建立一个连接，白白浪费资源。

三次就能握手了就不要四次了。

### 为什么每次初始化序列号不一样

**为了防止历史报文被下一个相同四元组的连接接收（主要方面）**

就是我建立连接后，发送一个数据假如被阻塞了，然后服务器断电重启之后，在收到客户端的数据包的时候就会发送RST报文，就断开连接了，然后又建立了一个相同的新的连接，恰好旧的被阻塞的数据又发过来了，就可以被接收了，但这是旧的数据就会造成数据错乱。

初始序列号 ISN 是如何随机产生的

三次握手的一个重要功能是客户端和服务端交换ISN(Initial Sequence Number), 以便让对方知道接下来接收数据的时候如何按序列号组装数据。

如果ISN是固定的，攻击者很容易猜出后续的确认号，因此 ISN 是动态生成的。

- 起始 `ISN` 是基于时钟的，每 4 微秒 + 1，转一圈要 4.55 个小时
- ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。
  - `M` 是一个计时器，这个计时器每隔 4 微秒加 1。
  - `F` 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值



### 第1/2/3次握手丢失了怎么办

第1次握手丢失了，**只有客户端会重传报文**，因为客户端迟迟没有收到服务器的SYN-ACK报文，他就重传自己的SYN报文；重传次数由**tcp_syn_retries**控制，默认是5；RTO翻倍增长

第2次握手丢失了，**客户端和服务器都会重传报文**，不仅客户端迟迟没收到SYN-ACK报文，服务器也没有收到客户端发来的ACK确认报文，所以服务器也会重传他的SYN-ACK报文；服务器重传SYN-ACK次数由**tcp_synack_retries**控制，默认5

第3次握手丢失了，**只有服务端会重发SYN-ACK报文**。

小补充⚠️：在建立 TCP 连接时，如果第三次握手的 ACK，服务端无法收到，则服务端就会短暂处于 `SYN_RECV` 状态，而客户端会处于 `ESTABLISHED` 状态。由于服务端一直收不到 TCP 第三次握手的 ACK，则会一直重传 SYN、ACK 包，直到重传次数超过 `tcp_synack_retries` 值（默认值 5 次）后，服务端就会断开 TCP 连接。

**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**





## TCP四次挥手

四次挥手的目的是可靠地终止两个方向上的数据传输。

1. **FIN**：

   - 当一个端点完成数据发送任务后，它需要发送一个FIN（终止）标志位被置为1的TCP段，来关闭连接的这一方向。
   - 这个端点之后就进入FIN_WAIT_1状态。

2. **ACK**：

   - 另一端收到这个FIN后，发送一个ACK段作为响应，并将确认号设置为收到的序列号加1。
   - 发送完ACK后，该端进入CLOSE_WAIT状态。发送FIN的端点收到ACK后，进入FIN_WAIT_2状态。

3. **FIN**：

   - 关闭连接的第二个方向开始时，之前处于CLOSE_WAIT状态的端点发送一个带有FIN标志的段。
   - 发送FIN后，该端进入LAST_ACK状态。

4. **ACK**：

   - 原始发送FIN的端点收到这个FIN后，发送一个ACK段作为响应。

   - 发送ACK后，该端进入TIME_WAIT状态，在经过一段时间（这段时间是为了确保最后一个ACK段能到达对方）后关闭连接。

   - 接收到这个ACK的端点关闭连接。

     

**谁主动关闭谁就发送一个FIN标志位为1的报文**

- 客户端打算关闭连接，此时**会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文**，也即 `FIN` 报文，之后**客户端进入 `FIN_WAIT_1` 状态**。
- 服务端收到该报文后，就**向客户端发送 `ACK` 应答报文**，接着**服务端进入 `CLOSE_WAIT` 状态**。**客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态**。
- **等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。**
- **客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文**，之后**进入 `TIME_WAIT` 状态**，**服务器收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态**，至此服务端已经完成连接的关闭。**客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。**

⚠️**主动关闭连接的，才有 TIME_WAIT 状态**

⚠️**CLOSE_WAIT状态，服务端可能传输数据**

⚠️当被动关闭方（服务端）在 TCP 挥手过程中，「**没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。**

### 为什么是四次

主要就是因为关闭连接时，客户端向服务器发送一个FIN报文表示自己不发送数据了，但还能接收数据，服务器接收到报文后回复一个ACK，但此时服务器可能还要处理数据和发送数据，所以等任务结束后再发送一个FIN表示可以关闭连接了，由于服务器的ACK和FIN要分开发送，所以是四次。

### 可以挥手三次吗

如果客户端请求关闭连接时，服务器并没有数据需要发送，其实三次挥手应该也是可以的。但一般情况下，客户端猝不及防地请求断开连接，服务器还是有数据需要传输的，所以四次挥手更加地稳妥。



什么情况会出现三次挥手

当被动关闭方（上图的服务端）在 TCP 挥手过程中，「没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。

-   当被动关闭方在 TCP 挥手过程中，如果「没有数据要发送」，同时「没有开启 TCP_QUICKACK（默认情况就是没有开启，没有开启 TCP_QUICKACK，等于就是在使用 TCP 延迟确认机制）」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。出现三次挥手现象是因为 TCP 延迟确认机制导致的。





### 第1/2/3/4次挥手丢失了怎么办

第1次挥手丢失了，客户端就会重发自己的FIN报文；重传次数由`tcp_orphan_retries`控制

第2次挥手丢失了，⚠️ACK报文是不会重传的，所以也是客户端重传自己的FIN报文

⚠️第3次挥手丢失了，就是服务器给客户端发送FIN丢失了，这个时候客户端处于FIN_WAIT_2状态，由于是调用close函数关闭，FIN_WAIT_2状态是有时长限制的，如果tcp_fin_timeout 时间内还是没能收到服务端的第三次挥手（FIN 报文），那么客户端就会断开连接。**也就是说第3次挥手丢失了，服务器会重传FIN报文，同时客户端也有倒计时。**

第4次挥手丢失了，由于也是丢失了ACK报文，所以是服务器重传他的FIN，而且此时客户端是TIME_WAIT状态，开启时长为 2MSL 的定时器，如果途中再次收到第三次挥手（FIN 报文）后，就会重置定时器，当等待 2MSL 时长后，客户端就会断开连接。



-   





### 四次挥手收到乱序的FIN

第三次挥手会发送数据，但是由于网络堵塞，FIN比数据先到，这个FIN就是乱序的FIN了，**在FIN_WAIT_2状态下收到乱序的FIN报文，它就会被加入到乱序队列，主动发起关闭的一方也不会进入TIME_WAIT状态**，等再次收到前面被网络延迟的数据包的时候，就到乱序队列里找，如果能找到保持顺序的报文同时这个报文还有FIN标志，才会进入到TIME_WAIT状态。





## 为什么要TIME_WAIT状态

两个原因：**防止历史连接中的数据，被后面相同四元组的连接错误的接收；保证被动关闭连接的一方，能被正确的关闭；**

序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据，所以设计了一个TIME_WAIT状态，2MSL的时长足以**让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的**

**如果没有TIME_WAIT**，客户端发一个ACK就关闭了，但如果这个ACK丢了，服务器就会重传，但是客户端已经关闭了，所以会回一个RST，RST不是优雅的关闭连接，所以加一个TIME_WAIT可以确保服务器能收到ACK，从而正确的关闭连接。

或者说**如果过短**，也是第四次丢了，过短开启了tcp_reuse复用了time_wait状态的连接，然后复用后的客户端再发送的SYN就是乱序SYN了，处于last ack状态的服务器就会触发challengeACK，客户端收到后就会回RST也是不优雅的。

**TIME_WAIT(默认60S)过多危害：**

一个是占用系统资源，一个是占用端口资源

- **如果客户端（发起连接方）的 TIME_WAIT 状态过多**，占满了所有端口资源，那么就无法对「目的 IP+ 目的 PORT」都一样的服务器发起连接了，但是被使用的端口，还是可以继续对另外一个服务器发起连接的
- **如果服务端（发起连接方）的 TIME_WAIT 状态过多**，并不会导致端口资源受限，因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接

**有很多 TIME-WAIT 状态如何解决**

服务器可以设置 SO_REUSEADDR 套接字选项来通知内核，如果端口被占用，但 TCP 连接位于 TIME_WAIT 状态时可以重用端口。如果你的服务器程序停止后想立即重启，而新的套接字依旧希望使用同一端口，此时 SO_REUSEADDR 选项就可以避免 TIME-WAIT 状态。

也可以采用长连接的方式减少 TCP 的连接与断开，在长连接的业务中往往不需要考虑 TIME-WAIT 状态，但其实在长连接的业务中并发量一般不会太高。

**优化TIME_WAIT：**

- 打开 **net.ipv4.tcp_tw_reuse** 和 **net.ipv4.tcp_timestamps** 选项；
  - 可以**复用处于 TIME_WAIT 的 socket 为新的连接所用**。有一点需要注意的是，⚠️**tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用**
  - **另一种解释**：net.ipv4.tcp_tw_reuse，如果开启该选项的话，客户端（连接发起方） 在调用 connect() 函数时，**如果内核选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态，如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了**。所以该选项只适用于连接发起方。
  - 由于引入了时间戳，在前面提到的 `2MSL` 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃
  - 这个参数是为了解决，TCP连接的TIME_WAIT过多，端口资源都被耗尽时，就无法与IP地址相同端口号相同的服务器连接
- net.ipv4.tcp_max_tw_buckets
  - 这个值默认为 18000，**当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置**，这个方法比较暴力
- 程序中使用 SO_LINGER ，应用强制使用 RST 关闭
  - 通过设置 socket 选项，来设置调用 close 关闭连接行为。如果`l_onoff`为非 0， 且`l_linger`值为 0，那么调用`close`后，会立该发送一个`RST`标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了`TIME_WAIT`状态，直接关闭。
  - 但这为跨越`TIME_WAIT`状态提供了一个可能，不过是一个非常危险的行为，不值得提倡
- **如果服务端要避免过多的 TIME_WAIT 状态的连接，就永远不要主动断开连接，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT**

⚠️补充：tcp_tw_resue默认是关闭的，因为开启是有风险的：

- 对于**RST报文的时间戳即使过期了，只要RST报文的序列号在对方的接收窗口内，也是能被接受的**。**因此快速复用TIME_WAIT状态的端口，导致新连接可能被回绕序列号的RST报文断开了，而如果不跳过TIME_WAIT状态，而是停留2MSL时长，那么这个RST报文就不会出现在下一个新的连接**。
- 或者说**如果过短**，也是第四次丢了，过短开启了tcp_reuse复用了time_wait状态的连接，然后复用后的客户端再发送的SYN就是乱序SYN了，处于last ack状态的服务器就会触发**challengeACK**（确认号与服务端上一次发送 ACK 报文一样的 ACK 报文），客户端收到后就会回RST也是不优雅的。



### 为什么TIME_WAIT是2MSL

`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

**Linux下，1MSL=30S，所以2MSL=60S。**

**1、保证客户端发送的最后一个ACK报文段能够到达服务端**

**2、防止“已失效的连接请求报文段”出现在本连接中**。

**TIME_WAIT 等待 2 倍的 MSL，**比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以**一来一回需要等待 2 倍的时间**。

- `2MSL` 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**

- **2MSL时长** 这其实是相当于**至少允许报文丢失一次**。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对；



### 服务器出现大量TIME_WAIT状态、close_wait状态

**服务器出现大量TIME_WAIT状态**

1. **HTTP没有使用长连接**，当服务端出现大量的 TIME_WAIT 状态连接的时候，**可以排查下是否客户端和服务端都开启了 HTTP Keep-Alive**，因为任意一方没有开启 HTTP Keep-Alive，都会导致服务端在处理完一个 HTTP 请求后，就主动关闭连接，此时服务端上就会出现大量的 TIME_WAIT 状态的连接。
2. **HTTP长连接超时**，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。大量出现就是因为客户端很长一段时间都没有发送数据。
3. **HTTP长连接请求数量达到上限**，如果达到这个**keepalive_requests 参数设置的最大值**时，则 nginx 会主动关闭这个长连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。

**服务端出现大量close_wait状态**

1. close_wait状态是在TCP四次挥手的时候收到FIN但是没有发送自己的FIN时出现的，服务器出现大量close_wait状态的原因有两种：

   - 服务器内部业务处理占用了过多时间，都没能处理完业务；或者还有数据需要发送；或者服务器的业务逻辑有问题，没有执行close()方法
   - 服务器的父进程派生出子进程，子进程继承了socket，收到FIN的时候子进程处理但父进程没有处理该信号，导致socket的引用不为0无法回收

   处理方法：

   - 停止应用程序
   - 修改程序里的bug

**netstat发现close-wait过多，原因是什么**

不存在丢包，也不存在忙于读写的情况，netstat发现close-wait过多，原因是什么？

- close_wait 按照正常操作的话应该很短暂的一个状态，接收到客户端的fin包并且回复客户端ack之后，会继续发送fin包告知客户端关闭连接之后迁移到Last_ACK状态。close_wait过多只能说明没有迁移到Last_ACK，也就是服务端是否发送fin包，只有发送fin包才会发生迁移，所以**问题定位在是否发送fin包**。fin包的底层实现其实就是调用socket的close方法，这里的问题出在**没有执行close方法。说明服务端socket忙于读写。**
- close_wait过多的解决方案：
  - 使用完socket调用close方法；
  - socket读控制，当读取的长度为0时（读到结尾），立即close；

  - 如果read返回-1，出现错误，检查error返回码，有三种情况：INTR（被中断，可以继续读取），WOULDBLOCK（表示当前socket_fd文件描述符是非阻塞的，但是现在被阻塞了），AGAIN（表示现在没有数据稍后重新读取）。如果不是AGAIN，立即close

  - 可以设置TCP的连接时长keep_alive_time还有tcp监控连接的频率以及连接没有活动多长时间被迫断开连接







## TCP 可靠传输

### 如何保证可靠传输

1. **数据包校验**：TCP报文头有校验和，用于校验报文是否损坏。若校验出包有错，则丢弃报文段并且不给出响应，这时 TCP 发送数据端超时后会重发数据；
2. **确认和重传机制**：接收方收到报文就会确认，发送方发送一段时间后没有收到确认就会重传。
3. **丢弃重复数据**：对于重复数据，能够丢弃重复数据；
4. **应答机制**：当 TCP 收到发自 TCP 连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒；
5. **超时重发**：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；
6. **流量控制**：当接收方来不及处理发送方的数据，能通过滑动窗口，提示发送方降低发送的速率，防止包丢失。
7. **拥塞控制**：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失。

**停止等待协议**

停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组；在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。主要包括以下几种情况：无差错情况、出现差错情况（超时重传）、确认丢失和确认迟到。

**ARQ 协议**

**自动重传请求 ARQ 协议**

停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求 ARQ。

**连续 ARQ 协议**

连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。



### 重传机制

**超时重传机制**：**接收方收到报文就会回复确认报文，发送方一段时间后没有收到确认报文就会重传自己的报文。发送方的报文丢失了也会重传自己的报文，本质原因还是由于没有接收到接受方发送的确认报文**

`RTT` 指的是**数据发送时刻到接收到确认的时刻的差值**，也就是包的往返时间。**超时重传时间 RTO 的值应该略大于报文往返 RTT 的值**。

**快速重传机制**：**不以时间为驱动，而是以数据驱动重传**。快速重传的工作方式是当**收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。**但是不能解决重传几个的问题，如果2,3都丢了，但收到1之后ack发的都是2，就不确定重传2还是3。

**SACK机制**：**选择性确认**，需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**，比如说收到1但是丢了2后续收到了3，4就知道重传2了。

**D-SACK机制**：主要是告诉发送方，有哪些数据发过去了，这样可以判断是发送方的报文丢了还是接收方的ACK丢了

⚠️**TCP报文头有校验和，用于校验报文是否损坏，从而可以保证TCP可靠传输**

⚠️**TCP只保证传输层的消息可靠性，并不保证应用层的消息可靠性。如果我们还想保证应用层的消息可靠性，就需要应用层自己去实现逻辑做保证。**

### 滑动窗口

TCP每发送一个数据都得应答一次，如果数据包往返的时间越长，通信的效率就越低，所以引入了窗口，窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。

**窗口大小**：TCP头部字段里的Window就是窗口大小，**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**发送窗口中的可用窗口就是还能发多少个数据，如果可用窗口为0就证明发不了数据。

### 流量控制

**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**

**TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。**

**如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。**窗口关闭后，接收方处理完数据会向发送方通告一个窗口非0的ACK报文，如果这个报文丢了麻烦就大了，发送方一直在等接收方非0窗口通知，接收方一直在等发送方发送的数据，为解决这个问题，TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。如果持续计时器超时，** **就会发送窗口探测 ( Window probe ) 报文，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。**

流量控制

TCP流量控制通过滑动窗口实现，有发送方窗口和接收方窗口，接收方每次都会告诉发送方自己的窗口大小，然后发送方根据接收窗口和自身的拥塞窗口中的最小值来确定当前的发送窗口大小。

### 拥塞控制

流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。但计算机网络处在一个共享的环境，有可能因为其他主机之间通信使得网络拥堵。**在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大....**

**=====>正式开始**

**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**为了调节发送方能发送的数据的量，定义了一个**拥塞窗口**的概念，它会根据**网络的拥塞程度动态变化的**。其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**

- **慢启动**：刚建立完连接后，一点一点提高发送数据包的数量就是慢启动。规则：**当发送方每收到一个ACK，拥塞窗口cwnd的大小就会加1。**一开始是1，收到ACK以后变成2，再收到2个ACK变成4，再收到4个ACK变成8.......指数增长，涨到什么时候呢？**有一个叫慢启动门限 `ssthresh` （slow start threshold）状态变量。当 `cwnd` < `ssthresh` 时，使用慢启动算法；当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」**

- **拥塞避免算法**：一般来说ssthresh是65535字节，进入拥塞避免算法后规则就是：**每当收到一个ACK时，cwnd增加1/cwnd。**就变成了线性增长，收到8个每个增加1/8就是增加1个，收到9个每个增加1/9就是增加1个。就这样一直增长之后网络就开始慢慢变拥塞了，就可能会出现丢包，触发 重传机制后就会进入**拥塞发生算法**。

- **拥塞发生算法**：**超时重传的时候，ssthresh变成cwnd/2，cwnd再变成cwnd的初始值**(用`ss -nli`命令查看每一个 TCP 连接的cwnd初始化值)，然后重新开始慢启动，因为cwnd<ssthresh了；**快速重传的时候，cwnd变成cwnd/2，ssthresh再变成cwnd，然后再进入快速恢复阶段**

- **快速恢复**：

  - 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；（之所以cwnd变成原来一半是为了ssthresh，真正cwnd要再ssthresh+3）

  - 重传丢失的数据包；

  - 如果再收到重复的ACK，那么cwnd增加 1；

  - 如果收到新数据的 ACK 后，把cwnd设置为第一步中的ssthresh的值，原因是该ACK确认了新的数据，说明从duplicated ACK时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即**再次进入拥塞避免状态**；


![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

流量控制和拥塞控制的窗口区别

**流量控制窗口**用于**控制发送方发送数据的速率**，以确保接收方不会被压倒。流量控制是为了**确保发送方不会使接收方不堪重负而导致数据丢失或缓冲区溢出**。

**拥塞控制窗口**用于**控制发送方的发送速率**，以避免网络拥塞。

两个窗口都是通过调整大小来控制发送方的行为，但流量控制窗口是基于接收方的缓冲区空间，而拥塞控制窗口是基于网络的拥塞状态。

### 流量控制和拥塞控制的区别

- 流量控制属于**通信双方协商**；拥塞控制涉及通信链路全局。
- 流量控制需要通信双方各维护一个发送窗、一个接收窗，对任意一方，接收窗大小由自身决定，发送窗大小由接收方响应的TCP报文段中窗口值确定；
- 拥塞控制的拥塞窗口大小变化由试探性发送一定数据量数据探查网络状况后而自适应调整。
- 实际最终发送窗口 = min{流控发送窗口，拥塞窗口}。

### 为什么快速重传要收到3次重复ACK

1. 当发送方连续收到3个重复ACK报文时，这表明接收方已经接收到了后续的数据包，只是某个数据包丢失了。这可能是由于网络发生了拥塞，所以触发快速重传，减少拥塞对网络性能的影响。
2. 收到2次可能只是网络延迟了或者乱序了，不一定要重传。







### RST为什么不好

TCP中的`RST`（Reset）标志用于突然终止连接，它不是一个优雅的关闭连接的方法。

**当一个TCP段中设置了RST标志，接收该段的端系统立即终止连接，并且丢弃该连接上待处理的任何数据。**

`RST`带来的危害：

1. **数据丢失**：因为RST导致连接立即关闭，所有在传输队列中等待发送或确认的数据都会被丢弃，这可能会导致数据不一致或丢失。
2. **服务拒绝**：在某些攻击（如TCP Reset Attack）中，攻击者可以伪造RST包来中断正常的TCP连接，从而导致服务中断。
3. **导致迷惑和错误**：接收RST的应用程序可能会感到困惑，因为它没有期望连接会突然关闭。这可能导致应用程序错误或系统崩溃。
4. **优雅关闭的好处丢失**：在优雅关闭连接时，双方都有机会发送和确认剩余的数据。但是，使用RST关闭连接时，这个过程会被短路，可能导致数据丢失。

**收到 RST 包就一定会断开连接吗**

不会，看下这个seq是否在合法**接收窗口**范围内。**如果不在范围内，这个RST包就会被丢弃。**防止黑客伪造RST包，进行RST攻击。



**什么情况会出现 RST 包**

1.连接请求到达时，目的端口不存在。

2.向一个已经关闭的连接发送数据。

3.向一个已经崩溃的对端发送数据。

4.请求超时。 接收端在接收数据超时时，会发送RST包。

5.关闭 socket 时，直接丢弃接收缓冲区未读取的数据，并给对方发一个RST。

6.TCP收到了一个根本不存在的连接上的报文。

7.处理半打开连接时。一方关闭了连接，另一方却由于网络故障等原因没有收到结束报文，还维持着原来的连接，这种状态就叫做半打开连接。此时另一方往处于半打开状态的连接写数据的话，对方就会回应RST。



**close 和 shutdown 的区别**

`shutdown(fd, SHUT_RDWR)` 和 `close(fd)` 的差别：

- close 会关闭连接，并释放所有连接对应的资源，而 shutdown 并不会释放掉套接字和所有的资源。
- close 存在引用计数的概念，并不一定导致该套接字不可用；shutdown 则不管引用计数，直接使得该套接字不可用，如果有别的进程企图使用该套接字，将会受到影响。
- close 的引用计数导致不一定会发出 FIN 结束报文，而 shutdown 则总是会发出 FIN 结束报文，这在我们打算关闭连接通知对端的时候，是非常重要的。

**往已经close 的 TCP 连接里面写数据，会收到RST，产生 SIGPIPE信号 ，默认 SIGPIPE信号 的忽略行为就是退出程序，因此需要优雅关闭 TCP 连接需要忽略这个信号。**







**TCP正常挥手后处于TIME_WAIT的连接又收到相同四元组的SYN**

此时例子是服务端主动关闭

如果双方开启了时间戳机制：

- 如果客户端的SYN的「序列号」比服务端「期望下一个收到的序列号」要**大**，**并且**SYN的「时间戳」比服务端「最后收到的报文的时间戳」要**大**。那么就会重用该四元组连接，跳过2MSL而转变为SYN_RECV状态，接着就能进行建立连接过程。
- 如果客户端的SYN的「序列号」比服务端「期望下一个收到的序列号」要**小**，**或者**SYN的「时间戳」比服务端「最后收到的报文的时间戳」要**小**。那么就会**再回复一个第四次挥手的ACK报文，客户端收到后，发现并不是自己期望收到确认号，就回RST报文给服务端**。

**总结**：如果 SYN 报文的「序列号+时间戳」**都是合法**的话，就会重新建立连接；如果 SYN 报文的「序列号+时间戳」**其中一个不合法**的话，就会回RST。

没开启就只比较序列号是否正常

![](https://cdn.xiaolincoding.com//mysql/other/39d0d04adf72fe3d37623acff9ae2507.png)

在 TIME_WAIT 状态，收到 RST 会断开连接吗？

- 如果 `net.ipv4.tcp_rfc1337` 参数为 0，则提前结束TIME_WAIT状态，释放连接。
- 如果 `net.ipv4.tcp_rfc1337` 参数为 1，则会丢掉该RST报文。



## UDP如何实现可靠传输

**UDP 是一种无连接的、不保证数据完整性的传输协议，但有时我们仍需要使用 UDP 来实现可靠的数据传输。这就需要在应用层实现一些 TCP 提供的功能。下面是一些可以考虑的策略：**

1. **确认和重传**：发送方可以为每个发送的数据包分配一个序列号，接收方在接收到数据包后返回一个包含相应序列号的确认（ACK）。如果发送方在一定时间内没有收到确认，它可以重发数据包。
2. **超时重传**：设置一个合适的超时时间，如果在这个时间内没有收到对方的响应，那么就重传数据包。这个时间可能需要根据网络的具体状况进行动态调整。
3. **校验和**：为了检测数据包在传输过程中是否被破坏，可以在每个数据包中添加校验和。接收方可以使用这个校验和来验证数据包的完整性。
4. **滑动窗口**：为了有效地利用网络带宽，发送方可以一次发送多个数据包，而不是等待每个数据包的确认。接收方可以使用一个窗口来接收这些数据包，窗口的大小可以根据网络的拥塞状况进行动态调整。
5. **顺序处理**：由于网络的原因，数据包可能会乱序到达接收方。因此，接收方需要有机制来重新组织这些数据包，确保它们按照正确的顺序被处理。
6. **流量控制和拥塞控制**：发送方需要根据接收方的处理能力和网络的拥塞状况来调整发送速率。

要注意的是，这些策略会增加编程的复杂性，并可能导致性能下降。在许多情况下，使用 TCP 可能是更好的选择，除非有特殊的需求（如实时性要求、多播、广播等）使得 UDP 更为合适。

### QUIC协议

QUIC（快速UDP互联网连接）是一个基于UDP构建的多路复用传输协议，由Google设计并开源实现。它的主要目的是解决TCP在某些场景下的性能瓶颈，如连接建立时的延迟和头阻塞问题。为了在UDP上实现可靠性，QUIC协议引入了以下关键特性：

1. 流控制和拥塞控制

与TCP类似，QUIC实现了流控制和拥塞控制机制。它使用了类似于TCP的算法（如Cubic或BBR）来调整发送速率，以及控制数据流以防止接收方缓冲区溢出。

2. 数据包级别的确认和重传

QUIC协议对每个数据包都赋予一个唯一的编号（即序列号）。接收方会对这些数据包发送确认响应。如果发送方未收到特定数据包的确认，它将重新发送该数据包。

3. 快速握手

QUIC使用0-RTT（零往返时间）和1-RTT握手来建立连接，这比传统的TCP三次握手要快。0-RTT允许在第一个数据包发送时就可以开始数据传输，如果客户端和服务器之前已经建立过连接。

4. 多路复用

QUIC允许多个独立的流在同一个连接中并行传输。这样可以避免一个慢连接阻塞其他连接的情况，从而解决了TCP的头阻塞问题。

5. 加密传输

QUIC的所有传输都是加密的，这基于TLS 1.3。加密不仅限于数据内容，还包括几乎所有的头部信息，从而提供了比TCP+TLS更好的隐私保护。





## 半、全连接队列

**半连接队列：**半连接队列也成SYN队列，就是服务端收到客户端的SYN报文后，内核会把这些连接存储到半连接队列，并向客户端响应SYN-ACK报文

**全连接队列**：服务端收到第三次握手的ACK时候，内核会把半连接队列的连接移除，重新创建新的完全的连接，将其加入到全连接队列也就是accept队列，等待进程调用accept取出连接。如果队列满了就有可能会出现丢包现象。

半连接队列是个**hash表**，全连接队列是个**链表**，全连接队列都是建立好的连接，需要的时候从队头取走就行，但半连接队列都是不完整的连接，如果是链表要是找对应的IP那就得遍历，所以设计成hash表快速查找

Linux内核中会维护两个队列：

- 半连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态；
- 全连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态；

```c
int listen (int socketfd, int backlog)
```

- 参数一 socketfd 为 socketfd 文件描述符
- 参数二 backlog，这参数在历史版本有一定的变化

* backlog 是 accept 队列。但是上限值是内核参数 somaxconn 的大小，也就说 accpet 队列长度 = min(backlog, somaxconn).

**客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。**

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/socket%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png)







**如何增大 TCP 全连接队列呢？**

- **TCP 全连接队列的最大值取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)**
- `somaxconn` 是 Linux 内核的参数，默认值是 128，可以通过 `/proc/sys/net/core/somaxconn` 来设置其值；
- `backlog` 是 `listen(int sockfd, int backlog)` 函数中的 backlog 大小，Nginx 默认值是 511，可以通过修改配置文件设置其长度；

**半连接队列和全连接队列满了的话，后续就会把SYN报文丢弃**







Linux 查看 TCP 状态

TCP 的连接状态查看，在 Linux 可以通过 `netstat -napt` 命令查看。

TCP 如何 Socket 编程

- 服务端和客户端初始化 `socket`，得到文件描述符；
- 服务端调用 `bind`，将 socket 绑定在指定的 IP 地址和端口;
- 服务端调用 `listen`，进行监听；
- 服务端调用 `accept`，等待客户端连接；
- 客户端调用 `connect`，向服务端的地址和端口发起连接请求；
- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；
- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

这里需要注意的是，服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。

所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。

成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。



accept 发生在三次握手的哪一步

**客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。**

- 客户端的协议栈向服务端发送了 SYN 包，并告诉服务端当前发送序列号 client_isn，客户端进入 SYN_SENT 状态；
- 服务端的协议栈收到这个包之后，和客户端进行 ACK 应答，应答的值为 client_isn+1，表示对 SYN 包 client_isn 的确认，同时服务端也发送一个 SYN 包，告诉客户端当前我的发送序列号为 server_isn，服务端进入 SYN_RCVD 状态；
- 客户端协议栈收到 ACK 之后，使得应用程序从 `connect` 调用返回，表示客户端到服务端的单向连接建立成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务端的 SYN 包进行应答，应答数据为 server_isn+1；
- ACK 应答包到达服务端后，服务端的 TCP 连接进入 ESTABLISHED 状态，同时服务端协议栈使得 `accept` 阻塞调用返回，这个时候服务端到客户端的单向连接也建立成功。至此，客户端与服务端两个方向的连接都建立成功。



### 没有accept/listen能TCP连接吗

**都可以**

**accpet 系统调用并不参与 TCP 三次握手过程，它只是负责从 TCP 全连接队列取出一个已经建立连接的 socket**，用户层通过 accpet 系统调用拿到了已经建立连接的 socket，就可以对该 socket 进行读写操作了。

客户端是可以自己连自己的形成连接（**TCP自连接**），也可以两个客户端同时向对方发出请求建立连接（**TCP同时打开**），这两个情况都有个共同点，就是**没有服务端参与，也就是没有 listen，就能 TCP 建立连接。**

⚠️⚠️⚠️⚠️⚠️另一个相似问题**服务端如果只bind了IP地址和端口，而没有调用listen的话，然后客户端对服务端发起了连接建立，服务端会回RST报文。**



**没有listen，为什么还能建立连接**

我们知道执行 listen 方法时，会创建半连接队列和全连接队列。

三次握手的过程中会在这两个队列中暂存连接信息。

所以形成连接，前提是你得有个地方存放着，方便握手的时候能根据 IP + 端口等信息找到对应的 socket。



**客户端有半连接队列吗**

**显然没有**，因为客户端没有执行listen，因为半连接队列和全连接队列都是在执行 listen 方法时，内核自动创建的。

但内核还有个全局 hash 表，可以用于存放 sock 连接的信息。

这个全局 hash 表其实还细分为 ehash，bhash和listen_hash等，但因为过于细节，大家理解成有一个全局 hash 就够了，

**在 TCP 自连接的情况中，客户端在 connect 方法时，最后会将自己的连接信息放入到这个全局 hash 表中，然后将信息发出，消息在经过回环地址重新回到 TCP 传输层的时候，就会根据 IP + 端口信息，再一次从这个全局 hash 中取出信息。于是握手包一来一回，最后成功建立连接**。

TCP 同时打开的情况也类似，只不过从一个客户端变成了两个客户端而已。





### 连接后服务器进程崩溃，客户端出现什么情况

**TCP 的连接信息是由内核维护的**，所以当服务端的**进程崩溃后，内核需要回收该进程的所有 TCP 连接资源**，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也**都是在内核完成**，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。

- **客户端情况：**首先要看有没有开启keepalive，如果开启了的话就可以探测出服务器崩溃了，客户端也会关闭掉 
- 如果没有开启keepalive但是有数据传输，由于服务器崩溃了，所以内核会回复RST，客户端也会关闭掉 

- 如果没有开启keeoalive也没有数据传输，那就一直耗着资源





### **连接后客户端宕机（保活机制）**

发生这种情况的时候，如果服务端**一直不会发送数据给客户端**，那么服务端是永远无法感知到客户端宕机这个事件的，也就是服务端的 TCP 连接将一直处于 `ESTABLISH` 状态，占用着系统资源。

因此有一个**保活机制**：定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，**每隔一个时间间隔，发送一个探测报文**，该探测报文包含的数据非常少，**如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。**

⚠️注意，应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 `SO_KEEPALIVE` 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。

- 如果开启了 TCP 保活，需要考虑以下几种情况：
  - 第一种，**对端程序是正常工作的**。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
  - 第二种，**对端程序崩溃并重启**。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但**由于没有该连接的有效信息**，**会产生一个 RST 报文**，这样很快就会发现 TCP 连接已经被重置。
  - 第三种，**对端程序崩溃**，**或对端由于其他原因导致报文不可达**。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**
- (这个就是WebServer项目中的定时器由来吧)可以自己在应用层实现一个心跳机制：比如，web服务软件一般都会提供 `keepalive_timeout` 参数，用来指定HTTP长连接的超时时间。如果设置了 HTTP 长连接的超时时间是60秒，web服务软件就会**启动一个定时器**，如果客户端在完成一个HTTP请求后，在60秒内都没有再发起新的请求，**定时器的时间一到，就会触发回调函数来释放该连接。**

**建立连接后客户端宕机了，服务器不知道(说明没触发保活机制发送RST报文，也就是它还是establish状态)，然后客户端又偷偷上线了发送SYN报文建立连接：**

1. **如果SYN报文里的端口号与历史连接不同**，那么就是通过三次握手建立新的连接，而旧的连接，如果服务器通过旧连接发了数据，由于连接是失效的所以内核会回复RST报文，服务器收到后就释放连接了；如果服务器一直没发数据，就触发了保活机制，检测到旧连接不在了服务器就会释放掉连接
2. **如果SYN报文里的端口号与历史连接相同**，处于Established状态的服务端，如果收到了客户端的SYN报文（⚠️注意此时的SYN报文其实是乱序的，因为SYN报文的初始化序列号其实是一个随机数），**会回复一个携带了正确序列号和确认号的ACK报文，这个ACK被称之为Challenge ACK**，接着，客户端收到这个Challenge ACK，发现确认号（ack num）并不是自己期望收到的，于是就会回RST报文，服务端收到后，就会释放掉该连接。

**有数据传输时**建立连接后宕机了然后迅速重启，由于有数据传输，宕机后服务器一直收不到客户端的ACK所以就会重传自己的SYN-ACK，重启后客户端收到了SYN-ACK，**不管客户端有没有进程绑定报文中的端口，内核都会发送RST**，即使有绑定也因为内核里协议栈找不到该TCP的socket结构体所以还是会回复RST。如果一直没重启，超时重传一定次数后就GG断开连接



**保活计时器的作用？**

除时间等待计时器外，TCP 还有一个保活计时器（keepalive timer）。设想这样的场景：客户已主动与服务器建立了 TCP 连接。但后来客户端的主机突然发生故障。显然，服务器以后就不能再收到客户端发来的数据。因此，应当有措施使服务器不要再白白等待下去。这就需要使用保活计时器了。

服务器每收到一次客户的数据，就重新设置保活计时器，时间的设置通常是两个小时。若两个小时都没有收到客户端的数据，服务端就发送一个探测报文段，以后则每隔 75 秒钟发送一次。若连续发送 10个 探测报文段后仍然无客户端的响应，服务端就认为客户端出了故障，接着就关闭这个连接。

**机器端口号上限是多少，可修改**

65536.因为TCP的报文头部中源端口号和目的端口号的长度是16位，也就是可以表示2^16=65536个不同端口号，因此TCP可供识别的端口号最多只有65536个。但是由于0到1023是知名服务端口，所以实际上还要少1024个端口号。

而对于服务器来说，可以开的端口号与65536无关，其实是受限于Linux可以打开的文件数量，并且可以通过MaxUserPort来进行配置。



**网站证书是绿色的是怎么意思**

绿色证书表示网站启用了HTTPS加密连接，并且经过了受信任的证书颁发机构的验证，是一种安全的标识。

**访问服务器较慢，一般有什么问题**

1. **网络延迟**：网络延迟是指从发送请求到接收响应所需的时间。它可能由网络连接质量不佳、网络拥塞、网络设备故障等因素引起。如果网络延迟高，会导致请求和响应之间的交互变慢，影响服务器访问速度。
2. **服务器负载过高**：服务器负载指服务器正在处理的请求数量。当服务器负载过高时，可能会超出其处理能力，导致响应时间增加。高负载可能由于大量并发请求、资源不足、处理复杂任务等原因引起。
3. **数据库查询性能**：如果访问涉及数据库查询，数据库的查询性能可能会影响服务器访问速度。慢速的数据库查询可以导致延迟，特别是在查询复杂数据结构或没有正确索引的大型数据集时。
4. **服务器配置不当**：服务器的硬件、操作系统和网络配置可能对性能产生影响。例如，服务器资源不足、网络带宽限制、过时的操作系统或未优化的网络设置等都可能导致访问速度较慢。
5. **程序或代码问题**：应用程序或代码本身可能存在效率低下的问题。例如，慢速的算法、不合理的并发设计、资源泄漏或阻塞等都可能导致服务器访问速度下降。















IP 层会分片，为什么 TCP 层还要 MSS 

- **`MTU`：一个网络包的最大长度**，以太网中一般为 `1500` 字节；
- **`MSS`**：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 **TCP 数据的最大长度**；

- 如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，当 IP 层有一个超过 `MTU` 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。这看起来井然有序，但这存在隐患的，**那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传**。因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。因此，可以得知由 IP 层进行分片传输，是非常没有效率的
- 为了达到最佳的传输效能 TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了；经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率



客户端用 close ，连接断开的流程

- 客户端调用 `close`，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态；
- 服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 `EOF` 到接收缓冲区中，应用程序可以通过 `read` 调用来感知这个 FIN 包。这个 `EOF` 会被**放在已排队等候的其他已接收的数据之后**，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态；
- 接着，当处理完数据后，自然就会读到 `EOF`，于是也调用 `close` 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态；
- 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；
- 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；
- 客户端经过 `2MSL` 时间之后，也进入 CLOSE 状态；



为什么UDP的数据包不能超过512字节

为了保证通用性，这个MTU一般取下限即 576 字节

鉴于 Internet 上的标准 MTU 值为 576 字节（[IPv4 标准](https://www.rfc-editor.org/rfc/rfc791)规定，每个主机必须能够重新组装 576 字节或更少的数据包），所以建议在进行 Internet 的 UDP 编程时，最好将 UDP 的数据长度控件在 548 字节（MTU(576) - IPHeader(20) - UDPHeader(8)）以内。

典型的 IPv4 头部是 20 字节，而 UDP 头部是 8 字节。然而，可以包括 IP 选项，该选项可以将 IP头部的大小增加到多达 60 字节。

此外，有时中间节点需要将数据报封装在另一种协议（如IPsec（用于VPN等））中，以便将数据包路由到其目的地。

因此，如果不知道特定网络路径上的 MTU，最好为可能没有预料到的其他头部信息留出合理的余量。512字节的 UDP 有效载荷通常被认为可以做到这一点，尽管即使这样也没有为最大尺寸的 IP报头留下足够的空间。

**UDP 数据包的最大安全负载应该是 508 字节**（MTU(576) - IPHeader(60) - UDPHeader(8)），因为 IP 头部最大时为 60 字节。512 也是一个综合考虑的结果。















TCP的一些扩展

- **为什么需要端口号**

在计算机网络中，端口号是用来帮助操作系统识别正在进行的特定网络服务或应用的一种标识。**每个网络请求都与一个特定的端口号相关联，这使得操作系统能够知道它应该将网络数据发送到哪个应用或服务。**

通俗地说，你可以将计算机想象成一个大楼，IP 地址就是这个大楼的地址，而端口号则类似于大楼内的房间号。大楼地址可以帮助你找到这个大楼，但是要找到大楼内的一个特定房间（即一个特定的应用或服务），你还需要一个房间号，这就是端口号的作用。

- **tcp怎么确定每次传多少**

根据拥塞窗口和流量窗口的最小值来确定每次发送多少

- **假如接收窗口和发送窗口最小值有10K 我会把这10k全部发走吗**

不一定，一般会分段，一个重要的原因是，虽然TCP是一种可靠的协议，但是网络传输过程中仍然可能发生数据丢失。如果一次性发送大量的数据，当其中的一部分数据丢失时，需要重传的数据量就会很大，这会导致网络效率降低。通过将数据分段，当数据丢失时，只需要重传丢失的那一段，而不是全部的数据，这可以提高网络的效率。

- **tcp包很大 到ip层要分两个包发 那我这两个ip包都要包含tcp头部吗**

如果一个TCP包过大，以至于在IP层需要进行分片（fragmentation），那么**这些分片的每一个都将包含原始IP头部的复制。这是因为每一个分片都可能需要独立地在网络上进行路由。但请注意，TCP头部信息只包含在第一个分片中，后续分片不会包含TCP头部。**

TCP的Fast Open

TCP Fast Open 功能减少 TCP 连接建立的时延

- 在第一次建立连接的时候，服务端在第二次握手产生一个 `Cookie` （已加密）并通过 SYN、ACK 包一起发给客户端，于是客户端就会缓存这个 `Cookie`，所以第一次发起 HTTP Get 请求的时候，还是需要 2 个 RTT 的时延；
- 在下次请求的时候，客户端在 SYN 包带上 `Cookie` 发给服务端，就提前可以跳过三次握手的过程，因为 `Cookie` 中维护了一些信息，服务端可以从 `Cookie` 获取 TCP 相关的信息，这时发起的 HTTP GET 请求就只需要 1 个 RTT 的时延；

就算第三次握手加上了请求数据也是2个RTT

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-Wireshark/45.jpg)

可以通过设置 `net.ipv4.tcp_fastopen` 内核参数，来打开 Fast Open 功能。

net.ipv4.tcp_fastopen 各个值的意义:

- 0 关闭
- 1 作为客户端使用 Fast Open 功能
- 2 作为服务端使用 Fast Open 功能
- 3 无论作为客户端还是服务器，都可以使用 Fast Open 功能

TCP延迟确认和Nagle算法

Nagle算法做了一些策略来避免过多的小数据报文发送，这可提高传输效率，

- 使用Nagle算法，该算法的思路是延时处理，只有满足下面两个条件中的任意一个条件，才能可以发送数据：

  - 条件一：要等到窗口大小 >= `MSS`并且 数据大小 >= `MSS`；
  - 条件二：收到之前发送数据的`ack`回包；

  只要上面两个条件都不满足，发送方一直在囤积数据，直到满足上面的发送条件。**简单来讲就是上一个分组得到确认才会发送下一个分组；收集多个小分组，在一个确认到来时一起发送**

- **Nagle算法一定会有一个小报文，也就是在最开始的时候。**

Nagle算法会导致粘包问题

没有携带数据的 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报文。所以出现了**延迟确认机制**

TCP 延迟确认的策略：

- **当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方**
- **当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送**
- **如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK**

⚠️不能同时使用这两个方法，要不发送方关闭 Nagle 算法，要不接收方关闭 TCP 延迟确认

TCP三次握手优化

**客户端优化**：当客户端发起 SYN 包时，可以通过 `tcp_syn_retries` 控制其重传的次数。

**服务端优化**：

- SYN半连接队列满了就通过`tcp_max_syn_backlog、somaxconn、backlog` 参数来调整 SYN 半连接队列的大小。
- 服务端回复 SYN+ACK 的重传次数由 `tcp_synack_retries` 参数控制。如果遭受 SYN 攻击，应把 `tcp_syncookies` 参数设置为 1，表示仅在 SYN 队列满后开启 syncookie 功能，可以保证正常的连接成功建立。
- 如果进程来不及取出连接导致accept队列满了，accept 队列溢出，系统默认丢弃 ACK，如果可以把 `tcp_abort_on_overflow` 设置为 1 ，表示用 RST 通知客户端连接建立失败。如果 accpet 队列溢出严重，可以通过 listen 函数的 `backlog` 参数和 `somaxconn` 系统参数提高队列大小，accept 队列长度取决于 min(backlog, somaxconn)。
- TCP Fast Open 功能可以绕过三次握手，使得 HTTP 请求减少了 1 个 RTT 的时间，Linux 下可以通过 `tcp_fastopen` 开启该功能，同时必须保证服务端和客户端同时支持。

TCP四次挥手优化

调用了 close 函数意味着完全断开连接，**完全断开不仅指无法传输数据，而且也不能发送数据。 此时，调用了 close 函数的一方的连接叫做「孤儿连接」，如果你用 netstat -p 命令，会发现连接对应的进程名为空。**

close函数关闭连接不优雅，所以要用优雅的shutdown函数，可以控制只关闭一个方向的连接

**主动方优化**：

主动发起 FIN 报文断开连接的一方，如果迟迟没收到对方的 ACK 回复，则会重传 FIN 报文，重传的次数由 `tcp_orphan_retries` 参数决定。

当主动方收到 ACK 报文后，连接就进入 FIN_WAIT2 状态，根据关闭的方式不同，优化的方式也不同：

- 如果这是 close 函数关闭的连接，那么它就是孤儿连接。如果 `tcp_fin_timeout` 秒内没有收到对方的 FIN 报文，连接就直接关闭。同时，为了应对孤儿连接占用太多的资源，`tcp_max_orphans` 定义了最大孤儿连接的数量，超过时连接就会直接释放。
- 反之是 shutdown 函数关闭的连接，则不受此参数限制；

当主动方接收到 FIN 报文，并返回 ACK 后，主动方的连接进入 TIME_WAIT 状态。这一状态会持续 1 分钟，为了防止 TIME_WAIT 状态占用太多的资源，`tcp_max_tw_buckets` 定义了最大数量，超过时连接也会直接释放。

当 TIME_WAIT 状态过多时，还可以通过设置 `tcp_tw_reuse` 和 `tcp_timestamps` 为 1 ，将 TIME_WAIT 状态的端口复用于作为客户端的新连接，注意该参数只适用于客户端。

**被动方优化**：

被动关闭的连接方应对非常简单，它在回复 ACK 后就进入了 CLOSE_WAIT 状态，等待进程调用 close 函数关闭连接。因此，出现大量 CLOSE_WAIT 状态的连接时，应当从应用程序中找问题。

当被动方发送 FIN 报文后，连接就进入 LAST_ACK 状态，在未等到 ACK 时，会在 `tcp_orphan_retries` 参数的控制下重发 FIN 报文。

TCP数据传输的优化

TCP 可靠性是通过 ACK 确认报文实现的，又依赖滑动窗口提升了发送速度也兼顾了接收方的处理能力。

可是，默认的滑动窗口最大值只有 64 KB，不满足当今的高速网络的要求，要想提升发送速度必须提升滑动窗口的上限，在 Linux 下是通过设置 `tcp_window_scaling` 为 1 做到的，此时最大值可高达 1GB。

滑动窗口定义了网络中飞行报文的最大字节数，当它超过带宽时延积时，网络过载，就会发生丢包。而当它小于带宽时延积时，就无法充分利用网络带宽。因此，滑动窗口的设置，必须参考带宽时延积。

内核缓冲区决定了滑动窗口的上限，缓冲区可分为：发送缓冲区 tcp_wmem 和接收缓冲区 tcp_rmem。

Linux 会对缓冲区动态调节，我们应该把缓冲区的上限设置为带宽时延积。发送缓冲区的调节功能是自动打开的，而接收缓冲区需要把 tcp_moderate_rcvbuf 设置为 1 来开启。其中，调节的依据是 TCP 内存范围 tcp_mem。

但需要注意的是，如果程序中的 socket 设置 SO_SNDBUF 和 SO_RCVBUF，则会关闭缓冲区的动态整功能，所以不建议在程序设置它俩，而是交给内核自动调整比较好。

有效配置这些参数后，既能够最大程度地保持并发性，也能让资源充裕时连接传输速度达到最大值。



1. **粘包（Packet Stick）**：在TCP/IP网络中，"粘包"是指发送方发送的若干包数据到达接收方时，被接收方当作一个包进行接收。原因有很多，例如发送方的数据发送得过快，接收方处理不过来，导致多个数据包接收时被连在一起。或者由于TCP的Nagle算法，小数据包会被合并到一起发送，到达接收方时就形成了"粘包"。
2. 

**根据快手面试得：假如有多个包，前面一个包发送过去了，接下来有一个包由于某些原因没有发送过去，导致后面的包黏在一起，这就是粘包**









## TCP粘包、拆包

**TCP粘包**

TCP粘包发生在数据接收方。由于TCP是一个基于流的协议，数据的发送和接收是没有明确界限的。在高负载系统中，为了效率考虑，多个数据包可能会连续发送，它们之间没有边界，导致接收方在读取这些数据的时候，可能会一次性读取到多个数据包的信息，这就是所谓的“粘包”。

**TCP 黏包是怎么产生的（本质）**

原因既可能由发送方造成，也可能由接收方造成。
**发送方引起的粘包**是由TCP协议本身造成的：

- 1、TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一包数据。若连续几次发送的数据都很少，通常TCP会根据优化算法把这些数据合成一包后一次发送出去，这样接收方就收到了粘包数据。注意：tcp一次传输数据应该最大有1460字节。
- 2、TCP协议规定有MSS，如果数据包过长就会被分开传输。这样接收方就收到了粘包数据。

**接收方引起的粘包**是由于接收方用户进程不及时接收数据，从而导致粘包现象。

- 这是因为接收方先把收到的数据放在系统接收缓冲区，用户进程从该缓冲区取数据，若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据。



**粘包发生的场景**:

- 发送方连续快速发送多个小的数据包，而TCP为了网络效率会将这些小的数据包合并为一个大的数据包发送出去。
- 接收方没有及时读取接收到的数据包，导致接收缓冲区中积累了多个数据包。



**TCP拆包**

TCP拆包是指发送方发送了一个大的数据包，但是因为该数据包超出了TCP协议的最大报文段长度（MSS）或网络的最大传输单元（MTU），所以这个大的数据包在传输过程中被分割为多个小的数据包。这样，接收方就需要对这些分割后的小包进行重组，才能得到完整的原始数据。

**拆包发生的场景**:

- 单个数据包超过了MSS或MTU的限制，必须分割才能发送。
- 路径MTU发现，即在路径中的某个节点不能处理当前大小的包，它会被拆分以适应这个节点的MTU。



#### 粘包解决策略

为了解决粘包和拆包问题，通常在应用层实现某种形式的消息定界。以下是一些常用的策略：

1. **定长包**: 发送固定长度的数据包。如果数据不足，可以填充空字节。
2. **包尾加分隔符**: 在数据包的尾部加入特定的字符作为分隔符，如使用`\n`或者其他不会在正常数据中出现的字符。
3. **包头加长度**: 在数据包的头部加入长度字段，用来说明数据包的长度。
4. **更复杂的应用层协议**: 如使用HTTP、WebSocket等协议，这些协议自带有效的数据开始和结束的标记，从而能够明确区分数据边界。

如何解决粘包？

粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。

- **固定长度的消息**：每个用户消息都是固定长度的，比如规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息

- **特殊字符作为边界**：两个用户消息之间插入一个特殊的字符串，这样接收方在接收数据时，读到了这个特殊字符，就把认为已经读完一个完整的消息；HTTP 是一个非常好的例子，GET请求每行通过/r/n区分

- **自定义消息结构，比如protobuf**。由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大

  我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。

  ```c++
  struct { 
      u_int32_t message_length; 
      char message_data[]; 
  } message;
  ```

  比如这个消息结构体，首先 4 个字节大小的变量来表示数据长度，真正的数据则在后面。

  当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。

1. **使用序列化工具**：protobuf在编码后的数据中加入一些元数据，用来表示消息的长度和类型等信息。仅使用 protobuf 是不能直接解决粘包问题的。protobuf 本身只是一个数据序列化和反序列化的工具。但你可以结合 protobuf 和上述提到的方法来解决粘包问题。**例如**，你可以先使用 protobuf 将数据序列化，再发送一个包含数据长度的固定长度头部，接着发送 protobuf 编码后的数据。

**具体步骤：**

1. 使用 protobuf 对你的消息进行序列化。
2. 获取序列化后的数据长度。
3. 发送一个固定长度的头部（比如4个字节）来表示后续数据的长度。
4. 发送 protobuf 序列化后的数据。

接收方接收到数据后：

1. 先读取固定长度的头部，解析出后续数据的长度。
2. 根据解析出的长度，读取对应长度的数据。
3. 使用 protobuf 对收到的数据进行反序列化，得到原始的消息。



**1、UDP是面向报文的协议**

当用户消息通过 UDP 协议传输时，**操作系统不会对消息进行拆分**，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是**每个 UDP 报文就是一个用户消息的边界**，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。

操作系统在收到 UDP 报文后，会将其插入到队列里，**队列里的每一个元素就是一个 UDP 报文**，这样当用户调用 recvfrom() 系统调用读数据的时候，就会从队列里取出一个数据，然后从内核里拷贝给用户缓冲区。

**2、TCP是面向字节流的协议**

**TCP 是面向字节流的协议**：TCP 是流式传输，没有边界，但保证顺序和可靠，不能认为一个用户消息对应一个 TCP 报文；用户消息通过 TCP 传输时，消息可能会被操作系统分组成多个的 TCP 报文，如果接收方的程序如果不知道消息的边界，是无法读出一个有效的用户消息的；

因为一个用户信息可能会被操作系统拆分成多个TCP报文，如果不知道边界就不能有效读取信息，不像UDP一个报文就对应一个用户消息，所以UDP是面向报文的TCP是面向字节流的。

**当两个消息的某部分被分到同一个报文时就是粘包问题**，粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。



如何理解UDP面向报文

- 当用户消息通过 UDP 协议传输时，**操作系统不会对消息进行拆分**，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是**每个 UDP 报文就是一个用户消息的边界**，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息
- 操作系统在收到 UDP 报文后，会将其插入到队列里，**队列里的每一个元素就是一个 UDP 报文**，这样当用户调用 recvfrom() 系统调用读数据的时候，就会从队列里取出一个数据，然后从内核里拷贝给用户缓冲区

- 

拔掉网线后，原本的TCP连接还存在吗？

**拔掉网线这个动作并不会影响TCP连接的状态**。**连接在不在还是要看有没有数据传输**

**拔掉网线，有数据传输**：

1. 在超时重传过程中又把网线插回去了，就无事发生
2. 超时重传过程中也只没插网线，连接就会断开，断开了再插回去，如果客户端向服务器发数据，服务器内核就会回RST

⚠️超时重传次数由tcp_retries2控制，默认15次，但并不一定是15次，而是**内核会根据 tcp_retries2 设置的值，计算出一个 timeout**（*如果 tcp_retries2 =15，那么计算得到的 timeout = 924600 ms*），**如果重传间隔超过这个 timeout，则认为超过了阈值，就会停止重传，然后就会断开 TCP 连接**。

**拔掉网线，没有数据传输**：

- 如果双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。
- 如果双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。

TCP的一些缺陷

**TCP建立连接的延迟**：如果是HTTPS+TCP的话就得先TCP三次握手再TLS四次握手

⚠️针对 HTTPS 来说，TLS 是在应用层实现的握手，而 TCP 是在内核实现的握手，这两个握手过程是无法结合在一起的，总是得先完成 TCP 握手，才能进行 TLS 握手。

**TCP存在队头阻塞**：TCP是面向字节流协议，**TCP层必须保证收到的字节数据是完整且有序的**，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据。⚠️HTTP2的队头阻塞就是TCP层造成的。

**网络迁移需要建立新的TCP连接**，基于TCP的HTTP协议是靠四元组来确定连接的，如果网络切换了，比如说从WiFi切换到了流量，就意味着IP地址变换了，就得重新建立连接。

TCP和UDP绑定相同端口相关

**TCP和UDP可以同时绑定相同端口**，(⚠️不要说同时监听，监听是TCP才有的动作)，端口是为了区分不同的应用程序，收到数据后在**IP包头协议号字段**知道给TCP还是UDP处理，TCP/UDP得到数据后再通过端口号确定给哪个应用程序，所以完全可以绑定相同端口。

**多个 TCP 服务进程可以绑定同一个端口吗？** **如果绑定的IP地址和端口都相同就不行**，bind()的时候就会报Address in use的错误。扩展，重启TCP服务进程后，总是碰到Address in use错误，导致TCP服务进程不能快速重启，总是要过一会才重启成功，他的原因和这个类似，就是**因为四次挥手过程中主动关闭方有个TIME_WAIT，在这个状态下的连接的IP和PORT号仍然被认为是有效的，由于不能绑定相同的IP+PORT，所以会报错**，⚠️可以通过端口复用SO_REUSEADDR来解决，它也可以解决绑定不同的IP地址+端口号

**客户端的端口可以重复使用吗**？**TCP连接是通过四元组确认的，并不会因为端口号相同而有影响，所以只要其他的改了，相同的端口号也没问题**







## RTO，RTT和超时重传

- **超时重传**：发送端发送报文后若长时间未收到确认的报文则需要重发该报文。可能有以下几种情况：
  - 发送的数据没能到达接收端，所以对方没有响应。
  - 接收端接收到数据，但是ACK报文在返回过程中丢失。
  - 接收端拒绝或丢弃数据。
- **RTO**：从上一次发送数据，因为长期没有收到ACK响应，到下一次重发之间的时间。就是重传间隔。
  - 通常每次重传RTO是前一次重传间隔的两倍，计量单位通常是RTT。例：1RTT，2RTT，4RTT，8RTT......
  - 重传次数到达上限之后停止重传。
- **RTT**：数据从发送到接收到对方响应之间的时间间隔，即数据报在网络中一个往返用时。大小不稳定



## SYN攻击

SYN攻击简单来说就是把TCP半连接队列弄满，后续的SYN报文就会被丢弃，从而引起网络拥塞甚至系统瘫痪。具体来讲就是客户端伪造大量不存在的IP地址并向服务器不断发送SYN包，由于IP不存在，服务器会不断重发直至超时，这些伪造的SYN包将长时间占用半连接队列。

避免 SYN 攻击方式，可以有以下四种方法：

- **调大 netdev_max_backlog**：当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包
- **增大 TCP 半连接队列**：需要同时增大下面这三个参数：
  - 增大 net.ipv4.tcp_max_syn_backlog
  - 增大 listen() 函数中的 backlog
  - 增大 net.core.somaxconn
- **开启 tcp_syncookies**：**开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接**：
  - 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不会丢弃，而是根据算法，计算出一个 `cookie` 值；
  - 将 cookie 值放到第二次握手报文的「序列号」里，然后服务端回第二次握手给客户端；
  - 服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，将该连接对象放入到「 Accept 队列」
- **减少 SYN+ACK 重传次数**，以加快处于 SYN_REVC 状态的 TCP 连接断开。



### DDOS攻击

客户端向服务端发送请求链接数据包，服务端向客户端发送确认数据包，**客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认** 。

没有彻底根治的办法，除非不使用TCP 

DDos 预防：（1）限制同时打开SYN半连接的数目，（2）缩短SYN半连接的Time out时间，（3）关闭不必要的服务

### SQL注入攻击

攻击者在HTTP请求中注入恶意的SQL代码，服务器使用参数构建数据库SQL命令时，恶意SQL被一起构造，并在数据库中执行。 用户登录，输入用户名 lianggzone，密码 ‘ or ‘1’=’1 ，如果此时使用参数构造的方式，就会出现 select * from user where name = ‘lianggzone’ and password = ‘’ or ‘1’=‘1’ 不管用户名和密码是什么内容，使查询出来的用户列表不为空。如何防范SQL注入攻击使用预编译的PrepareStatement是必须的，但是一般我们会从两个方面同时入手。 

Web端 1）有效性检验。 2）限制字符串输入的长度。 服务端 1）不用拼接SQL字符串。 2）使用预编译的PrepareStatement。 3）有效性检验。(为什么服务端还要做有效性检验？第一准则，外部都是不可信的，防止攻击者绕过Web端请求) 4）过滤SQL需要的参数中的特殊字符。比如单引号、双引号



CSRF攻击

跨站点请求伪造，指攻击者通过跨站请求，以合法的用户的身份进行非法操作。可以这么理解CSRF攻击：攻击者盗用你的身份，以你的名义向第三方网站发送恶意请求。CRSF能做的事情包括利用你的身份发邮件，发短信，进行交易转账，甚至盗取账号信息。

如何防范CSRF攻击

**安全框架**，例如Spring Security。 **token机制**。在HTTP请求中进行token验证，如果请求中没有token或者token内容不正确，则认为CSRF攻击而拒绝该请求。 **验证码**。通常情况下，验证码能够很好的遏制CSRF攻击，但是很多情况下，出于用户体验考虑，验证码只能作为一种辅助手段，而不是最主要的解决方案。 **referer识别**。在HTTP Header中有一个字段Referer，它记录了HTTP请求的来源地址。如果Referer是其他网站，就有可能是CSRF攻击，则拒绝该请求。但是，服务器并非都能取到Referer。很多用户出于隐私保护的考虑，限制了Referer的发送。在某些情况下，浏览器也不会发送Referer，例如HTTPS跳转到HTTP。 1）验证请求来源地址； 2）关键操作添加验证码； 3）在请求地址添加 token 并验证。











服务端只bind()没有listen()

**服务端如果只 bind 了 IP 地址和端口，而没有调用 listen 的话，然后客户端对服务端发起了连接建立，服务端会回 RST 报文。**

扩展：**不用listen能建立TCP连接么**，**是可以的，客户端是可以自己连自己的形成连接（TCP自连接），也可以两个客户端同时向对方发出请求建立连接（TCP同时打开），这两个情况都有个共同点，就是没有服务端参与，也就是没有listen，就能建立连接**

连接信息通常是存在listen时创建的半连接队列和全连接队列中，但是**在 TCP 自连接的情况中，客户端在 connect 方法时，最后会将自己的连接信息放入到这个全局 hash 表中，然后将信息发出，消息在经过回环地址重新回到 TCP 传输层的时候，就会根据 IP + 端口信息，再一次从这个全局 hash 中取出信息。于是握手包一来一回，最后成功建立连接**。

客户端连接一个不存在的IP地址会发生什么

分两种情况

- 第一种情况，目标IP地址和客户端IP地址**在同一个局域网（网络IP相同）**：

  客户端无法发出SYN报文，主要**卡在网络接口层**。网络接口层**发送ARP广播请求时，由于目标地址不存在，所以没有设备应答其ARP请求。所有无法拿到目标设备的MAC头，所以SYN报文无法发送出去**。

- 第二种情况，目标IP地址和客户端IP地址**不在同一个局域网（网络IP不同）**：

  当不在同一个局域网时，客户端会通过**路由控制表查看和目标IP有着相同网络号的路由器（若有多个，则选择匹配最大的路由器），然后在网络接口层发送ARP请求，询问IP地址（路由器IP）是谁的，路由器发现是自己的后，告诉客户端自己的MAC地址，就发出去了**。客户端将SYN报文发送给路由器，然后路由器继续转发，由于目标IP地址是不存在的，**报文最后消失在网络中，客户端不会收到对SYN报文的应答**。然后**触发超时重传，重传SYN报文，直到达到重传次数，释放连接**。
  
  

客户端连接一个存在的IP地址但是端口不存在的TCP发生什么

客户端连接的目标IP是存在的，那么**SYN报文能正确到达目标设备**。目标收到SYN后，发现端口号不存在（未监听），目标设备会回复一个RST报文，客户端收到后断开连接。

⚠️**客户端发送了一个目标IP地址存在但是端口不存在的UDP报文，UDP没有像TCP那样的RST报文，此时会发生什么**:

目标主机会**尝试向客户端发送一个ICMP目的端口不可达的错误消息，告诉客户端目标端口不存在**。客户端收到这个ICMP报文后，可以根据需要进行处理，例如重新发送UDP报文或者放弃发送。







怎么判断网络拥塞

1. 判断网络拥塞： 网络拥塞通常是指网络中的流量过大，导致网络性能下降，数据传输变慢或中断。判断网络拥塞可以采用以下几种方式：

- 丢包率增加：监测数据包的丢失情况，如果发现丢包率显著增加，可能表示网络拥塞。
- 延迟增加：监测数据传输的延迟，如果延迟明显增加，可能表示网络拥塞。
- 带宽利用率：监测网络带宽的利用率，如果带宽被充分利用，可能表示网络拥塞。

网络拥塞判断的方法可以根据具体的应用场景和需求来选择，通常是结合多种指标进行综合判断。

超时重传什么时候关闭

1. 超时重传的关闭时机： 超时重传是一种用于保证数据可靠传输的机制。当发送方发送数据后，如果在一定的时间内没有收到确认（ACK）信号，发送方会认为数据丢失，并进行超时重传。

关闭超时重传的时机通常是在以下情况下：

- 收到接收方的确认信号，表示数据已成功传输。
- 超过最大重传次数，表明数据传输失败。



文件上传漏洞是如何发生的

文件上传漏洞，指的是用户上传一个可执行的脚本文件，并通过此脚本文件获得了执行服务端命令的能力。 许多第三方框架、服务，都曾经被爆出文件上传漏洞，比如很早之前的Struts2，以及富文本编辑器等等，可被攻击者上传恶意代码，有可能服务端就被人黑了。



如何防范文件上传漏洞

文件上传的目录设置为不可执行。

1）判断文件类型。在判断文件类型的时候，可以结合使用MIME Type，后缀检查等方式。因为对于上传文件，不能简单地通过后缀名称来判断文件的类型，因为攻击者可以将可执行文件的后缀名称改为图片或其他后缀类型，诱导用户执行。

2）对上传的文件类型进行白名单校验，只允许上传可靠类型。

3）上传的文件需要进行重新命名，使攻击者无法猜想上传文件的访问路径，将极大地增加攻击成本，同时向shell.php.rar.ara这种文件，因为重命名而无法成功实施攻击。

4）限制上传文件的大小。

5）单独设置文件服务器的域名。



TCP中已有SO_KEEPALIVE选项，为什么还要在应用层加入心跳包机制?

SO_Keeplive 是实现在TCP协议栈（四层），应用层的心跳实现在第七层，本质没有任何区别，但应用层需要自己来定义心跳包格式。

在应用层实现的心跳机制实现更灵活，因为可以自定义配置比如消息类型，超时时间间隔，接收后的处理。超时时间间隔在 TCP 的保活机制中，默认是两个小时多一点，这个参数可以调节。

# IP篇

**MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。**比如说主机A连着路由器1再连着路由器2再连着主机B，IP就是负责主机A与主机B之间通信，MAC就是负责这些相互**直连**的设备之间通信

IP地址是用于在互联网上找到设备的地址，而MAC地址则是在局域网中进行设备识别和数据包传输的地址。

网络地址分类相关

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/7.jpg)

**A类0.0.0.0-127.255.255.255，最大主机数16777214；B类128.0.0.0-191.255.255.255，最大主机数65534；C类192.0.0.0-223.255.255.255，最大主机数254**

最大主机数看主机号的位数，2的主机号位数次方-2，减2是因为主机号全是0的指定某个网络，**主机号全是1的用于广播**，广播地址用于在**同一个链路中相互连接的主机之间发送数据包**。在本网络内广播的叫做本地广播，在不同网络之间的广播叫做直接广播。(路由器不转发广播包)

D类224.0.0.0-239.255.255.255多用于多播，多播用于**将包发送给特定组内的所有主机**。

**IP分类优缺点**：简单名了，选路(基于网络地址)简单；缺点：**同一网络下没有地址层次**，比如一个公司里用了 B 类地址，但是可能需要根据生产环境、测试环境、开发环境来划分地址层次，而这种 IP 分类是没有地址层次划分的功能，所以这就**缺少地址的灵活性**。A、B、C类有个尴尬处境，就是**不能很好的与现实网络匹配**。



IP 地址分类的优缺点

- **优点**

**快速找出网络地址和主机号**

不管是路由器还是主机解析到一个 IP 地址时候，我们判断其 IP 地址的首位是否为 0，为 0 则为 A 类地址，那么就能很快的找出网络地址和主机地址。

- **缺点**

1. **同一网络下没有地址层次**

   比如一个公司里用了 B 类地址，但是可能需要根据生产环境、测试环境、开发环境来划分地址层次，而这种 IP 分类是没有地址层次划分的功能，所以这就**缺少地址的灵活性**。

2. A、B、C类有个尴尬处境，就是**不能很好的与现实网络匹配**。

   - C 类地址能包含的最大主机数量实在太少了，只有 254 个，估计一个网吧都不够用。
   - 而 B 类地址能包含的最大主机数量又太多了，6 万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费。

   这两个缺点，都可以在 `CIDR` 无分类地址解决。





无分类地址CIDR

表示形式 `a.b.c.d/x`，其中 `/x` 表示前 x 位属于**网络号**， x 的范围是 `0 ~ 32`，这就使得 IP 地址更加具有灵活性。

**将子网掩码和IP地址按位计算AND，就可得到网络号**。 **子网划分实际上是将主机地址分为两个部分：子网网络地址和子网主机地址**。





IP 地址与路由控制

- IP地址的**网络地址**这一部分是用于进行路由控制。路由控制表中记录着网络地址与下一步应该发送至路由器的地址。在主机和路由器上都会有各自的路由器控制表。
- 在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有**相同网络地址**的记录，根据该记录将 IP 包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择相同位数最多的网络地址，也就是最长匹配。
- 环回地址是在同一台计算机上的程序之间进行网络通信时所使用的一个默认地址。计算机使用一个特殊的 IP 地址**127.0.0.1 作为环回地址**。与该地址具有相同意义的是一个叫做 `localhost` 的主机名。使用这个 IP 或主机名时，数据包不会流向网络

## 硬件相关

### 路由协议

路由协议是路由器之间实现路由信息共享的一种机制，它允许**路由器之间相互交换和维护各自的路由表**。当一台路由器的路由表由于某种原因发生变化时，它需要及时地将这一变化通知与之相连接的其他路由器，以保证数据的正确传递。路由协议不承担网络上终端用户之间的数据传输任务。主要有距离向量路由协议（RIP, IGRP, EIGRP）和链路状态路由协议（OSPF, IS-IS）两类。





### 交换机

- 交换机的设计是将网络包**原样**转发到目的地。交换机工作在 MAC 层，也称为**二层网络设备**。
- 信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。然后通过包末尾的 `FCS` 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，**交换机的端口不具有 MAC 地址**。
- 将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。交换机的 MAC 地址表主要包含两个信息：
  - 一个是设备的 MAC 地址，
  - 另一个是该设备连接在交换机的哪个端口上。
- **交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口**。
  - 地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。
  - 这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。



### 路由器的工作原理

- 路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。当转发包时，首先路由器端口会接收发给自己的以太网包，然后**路由表**查询转发目标，再由相应的端口作为发送方将以太网包发送出去。
- 电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 `FCS` 进行错误校验。如果没问题则检查 MAC 头部中的**接收方 MAC 地址**，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃
- 完成包接收操作之后，路由器就会**去掉**包开头的 MAC 头部。**MAC 头部的作用就是将包送达路由器**，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会**被丢弃**。
- 接下来，路由器会根据 MAC 头部后方的 `IP` 头部中的内容进行包的转发操作。
  - 转发操作分为几个阶段，首先是查询**路由表**判断转发目标。根据包的接收方 IP 地址查询路由表中的目标地址栏，以找到相匹配的记录。每个条目的子网掩码和 `192.168.1.100` IP 做 **& 与运算**后，得到的结果与对应条目的目标地址进行匹配，如果匹配就会作为候选转发目标，如果不匹配就继续与下个条目进行路由匹配。实在找不到匹配路由时，就会选择**默认路由**，路由表中子网掩码为 `0.0.0.0` 的记录表示「默认路由」
- **路由器的发送操作**：根据**路由表的网关列**判断对方的地址。
  - 如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，**还未抵达终点**，还需继续需要路由器转发。
  - 如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明**已抵达终点**。
- 知道对方的 IP 地址之后，接下来需要通过 `ARP` 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 `0800` （十六进制）表示 IP 协议。网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。
- 发送出去的网络包会通过**交换机**到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。
- **源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址**，因为需要 MAC 地址在以太网内进行**两个设备**之间的包传输





### 路由器和交换机的区别

- 网络包经过交换机之后，现在到达了**路由器**，并在此被转发到下一个路由器或目标设备。这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。不过在具体的操作过程上，路由器和交换机是有区别的。
  - 因为**路由器**是基于 IP 设计的，俗称**三层**网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；
  - 而**交换机**是基于以太网设计的，俗称**二层**网络设备，交换机的端口不具有 MAC 地址

网络层（IP）和数据链路层（MAC）的关系

MAC 的作用则是实现**「直连」**的两个设备之间通信，而 IP 则负责在**「没有直连」**的两个网络之间进行通信传输。

在网络中数据包传输中，**源IP地址和目标IP地址在传输过程中是不会变化的，只有源 MAC 地址和目标 MAC 一直在变化。**



### 网关作用

同一网段的主机如何通信

1. **网关的作用**：网关在**传输层**上以实现网络互连，是最复杂的网络互连设备，仅用于两个**高层协议不同的**网络互连。

2. **网内通信**，即通信双方都位处同一网段中，数据传输无需经过路由器(或三层交换机)，即可由本网段自主完成。

   假设发送主机的ARP表中并无目的主机对应的表项，则发送主机会以目的主机IP地址为内容，广播ARP请求以期获知目的主机MAC地址，并通过交换机(除到达端口之外的所有端口发送，即洪泛(Flooding)向全网段主机转发，而只有目的主机接收到此ARP请求后会将自己的MAC地址和IP地址装入ARP应答后将其回复给发送主机，发送主机接收到此ARP应答后，从中提取目的主机的MAC地址，并在其ARP表中建立目的主机的对应表项(IP地址到MAC地址的映射)，之后即可向目的主机发送数据，将待发送数据封装成帧，并通过二层设备(如交换机)转发至本网段内的目的主机，自此完成通信。





本机如何干预 DNS 解析

通过修改本机 host 来干预域名解析，例如：在 /etc/hosts 文件中添加一句话

```
192.168.188.1 www.baidu.com
```

保存文件后再ping一下 www.baidu.com 就会连接到192.168.188.1了

每一行为一条记录，分成两部分，第一部分是IP，第二部分是域名。

- 一个IP后面可以跟多个域名，可以是几十个甚至上百个
- 每一行只能有一个IP，也就是说一个域名不能对应多个IP
- 如果有多行中出现相同的域名（对应的ip不一样），会按最前面的记录来解析



什么是 DNS 劫持？

1. DNS劫持就是通过劫持了DNS服务器，通过某些手段取得某域名的解析记录控制权，进而修改此域名的解析结果，导致对该域名的访问由原IP地址转入到修改后的指定IP，其结果就是对特定的网址不能访问或访问的是假网址，从而实现窃取资料或者破坏原有正常服务的目的。DNS劫持通过篡改DNS服务器上的数据返回给用户一个错误的查询结果来实现的。
2. DNS劫持症状：在某些地区的用户在成功连接宽带后，首次打开任何页面都指向ISP提供的“电信互联星空”、“网通黄页广告”等内容页面。还有就是曾经出现过用户访问Google域名的时候出现了百度的网站。这些都属于DNS劫持。





什么是静态路由和动态路由

1. **静态路由**是系统管理员设计和构建的路由表所规定的路由。适用于网关数量有限的场合，且网络拓朴结构不经常变化的网络。其缺点是不能动态地适用网络状况的变化，当网络状况变化后必须由网络管理员修改路由表。
2. **动态路由**是由路由选择协议而动态构建的，路由协议之间通过交换各自所拥有的路由信息实时更新路由表的内容。动态路由可以自动学习网络的拓朴结构，并更新路由表。其缺点是路由广播更新信息将占据大量的网络带宽。



IP 分片与重组

- 每种数据链路的最大传输单元 `MTU` 都是不相同的，如 FDDI 数据链路 MTU 4352、以太网的 MTU 是 1500 字节等。每种数据链路的 MTU 之所以不同，是因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的 MTU 也就不同。其中，我们最常见数据链路是以太网，它的 MTU 是 `1500` 字节。
- 那么当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片;经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行，**路由器是不会进行重组的。**
- **在分片传输中，一旦某个分片丢失，则会造成整个 IP 数据报作废，所以 TCP 引入了 `MSS` 也就是在 TCP 层进行分片不由 IP 层分片，那么对于 UDP 我们尽量不要发送一个大于 `MTU` 的数据报文**

IPv6 基本认识

- IPv6 地址长度是 128 位，是以每 16 位作为一组，每组用冒号 「:」 隔开
  - 如果出现连续的 0 时还可以将这些 0 省略，并用两个冒号 「::」隔开。但是，一个 IP 地址中只允许出现一次两个连续的冒号

- IPv6 可自动配置，即使没有 DHCP 服务器也可以实现自动分配IP地址
- IPv6 包头包首部长度采用固定的值 `40` 字节，去掉了包头校验和，简化了首部结构，减轻了路由器负荷，大大**提高了传输的性能**
- IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大**提升了安全性**
- IPv6 的地址主要有以下类型地址：
  - 单播地址，用于一对一的通信,主要划分了三类单播地址，每类地址的有效范围都不同
    - 在同一链路单播通信，不经过路由器，可以使用**链路本地单播地址**，IPv4 没有此类型
    - 在内网里单播通信，可以使用**唯一本地地址**，相当于 IPv4 的私有 IP
    - 在互联网通信，可以使用**全局单播地址**，相当于 IPv4 的公有 IP
  - 组播地址，用于一对多的通信
  - 任播地址，用于通信最近的节点，最近的节点是由路由协议决定
  - 没有广播地址
- IPv6 相比 IPv4 的首部改进：
  - **取消了首部校验和字段。** 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。
  - **取消了分片/重新组装相关字段。** 分片与重组是耗时的过程，IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提高了路由器转发的速度。
  - **取消选项字段。** 选项字段不再是标准 IP 首部的一部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下一个首部」指出的位置上。删除该选项字段使的 IPv6 的首部成为固定长度的 `40` 字节

⚠️一开始以为16进制就是一个表示格式，例如（0x32，0xa3..)，今天才发现原来不管是0x123,还是0x1234都是表示16进制。发现自己是概念混淆，以后看到是0x开头的，就是16进制。0x12转换二进制为（0000 0000 0001 0020），0x123转换二进制为（0000 0001 0020 0011）,0x1234转换为二进制为（0001 0010 0011 0100）。0x只是表示一个16进制的标志位。

## DNS（域名解析）

- **DNS是应用层协议**
- **域名解析的工作流程：浏览器缓存 -> 系统本地缓存 -> host文件 -> 本地DNS -> 根DNS -> 顶级域名服务器(.com) -> 权威域名服务器**

### DNS原理、工作流程

- **DNS原理：**

  DNS的原理基于将容易记忆的域名（www.example.com`）转换为数字形式的IP地址（`192.0.2.1`），识别每个节点的方法。域名以层次结构组织，允许分布式处理。域名解析是通过一系列递归和迭代查询完成的，涉及不同级别的DNS服务器，包括根服务器、顶级域名服务器（TLD服务器）和权威名称服务器。

  **DNS工作流程：**

  1. **用户请求：** 用户输入一个域名（如`www.example.com`）进入浏览器。
  2. **本地系统查询：** 系统首先检查本地DNS缓存，看是否已经有该域名的解析记录；如果没有，则系统会向配置的DNS递归服务器发出请求。
  3. **递归服务器：** 递归DNS服务器查看它的缓存；如果缓存中没有找到，则递归服务器将请求发送到根服务器。
  4. **根服务器：** 根服务器回应顶级域（TLD）服务器的地址。对于`www.example.com`，它是`.com`的TLD服务器。
  5. **TLD服务器：** 递归服务器随后向`.com` TLD服务器查询`example.com`域的权威名称服务器地址。
  6. **权威名称服务器：** 一旦获得权威名称服务器的地址，递归服务器向权威服务器查询`www.example.com`的IP地址。
  7. **IP地址回应：** 权威名称服务器回应`www.example.com`的IP地址。
  8. **存储记录：** 递归服务器将IP地址存储在其缓存中以备后续查询，并将IP地址回应给用户的设备。
  9. **建立连接：** 用户的设备使用这个IP地址与目标服务器建立TCP连接，并开始HTTP会话，加载网站内容。
  10. **结果：** 用户的浏览器显示`www.example.com`的网页内容。







### DNS查询方式

- **递归解析**
- 当局部DNS服务器自己不能回答客户机的DNS查询时，它就需要向其他DNS服务器进行查询。此时有两种方式。**局部DNS服务器自己负责向其他DNS服务器进行查询，一般是先向该域名的根域服务器查询，再由根域名服务器一级级向下查询**。最后得到的查询结果返回给局部DNS服务器，再由局部DNS服务器返回给客户端。

- **迭代解析**
- 当局部DNS服务器自己不能回答客户机的DNS查询时，也可以通过迭代查询的方式进行解析。局部DNS服务器不是自己向其他DNS服务器进行查询，**而是把能解析该域名的其他DNS服务器的IP地址返回给客户端DNS程序**，客户端DNS程序再继续向这些DNS服务器进行查询，直到得到查询结果为止。也就是说，迭代解析只是帮你找到相关的服务器而已，而不会帮你去查。比如说：baidu.com的服务器ip地址在192.168.4.5这里，你自己去查吧，本人比较忙，只能帮你到这里了。




### 域名解析用UDP

1. **效率和速度**：UDP不需要像TCP那样进行连接的建立和终止，这意味着它的开销小，速度快。因为域名解析只是简单的查询和响应模式，所以UDP很适合这种快速交换信息的场景。
2. **简单的交互模式**：DNS查询通常只需要一个请求和一个响应，这种简单的一对一交互模式非常适合使用无连接的协议，即UDP。
3. **传输大小限制**：标准的DNS查询响应通常远小于512字节，适合UDP的数据包大小限制。如果DNS响应超过了UDP的大小限制，它会设置一个“截断”标志，告诉客户端需要通过TCP来重新执行查询。

### 区域传送用TCP

1. **可靠性**：TCP提供了可靠的数据传输服务，确保数据完整性和顺序，这对于区域传送是非常重要的，因为在区域传送中，我们需要确保所有的资源记录都被完整无误地复制过来。
2. **大数据量传输**：区域传送可能包含大量的数据，可能会超过UDP的数据大小限制。TCP没有这样的限制，可以处理大量数据的传输。
3. **流控制和拥塞控制**：TCP还提供了流控制和拥塞控制机制，这在传输大量数据时非常重要，可以根据网络条件动态调整数据发送速率，减少丢包和重传。



### DNS负载均衡

当一个网站有足够多的用户的时候，假如每次请求的资源都位于同一台机器上面，那么这台机器随时可能会崩掉。

处理办法就是用DNS负载均衡技术，它的原理是在**DNS服务器中为同一个主机名配置多个IP地址,在应答DNS查询时，DNS服务器对每个查询将以DNS文件中主机记录的IP地址按顺序返回不同的解析结果，将客户端的访问引导到不同的机器上去，使得不同的客户端访问不同的服务器**，从而达到负载均衡的目的。例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等。



怎么实现 DNS 劫持

**定义：**

DNS 劫持即域名劫持，是通过将原域名对应的 IP 地址进行替换从而使得用户访问到错误的网站或者使得用户无法正常访问网站的一种攻击方式。域名劫持往往只能在特定的网络范围内进行，范围外的 DNS 服务器能够返回正常的 IP 地址。攻击者可以冒充原域名所属机构，通过电子邮件的方式修改组织机构的域名注册信息，或者将域名转让给其它组织，并将新的域名信息保存在所指定的 DNS 服务器中，从而使得用户无法通过对原域名进行解析来访问目的网址。

**具体实现**：

① 获取要劫持的域名信息：攻击者首先会访问域名查询站点查询要劫持的域名信息。

② 控制域名相应的 E-MAIL 账号：在获取到域名信息后，攻击者通过暴力破解或者专门的方法破解公司注册域名时使用的 E-mail 账号所对应的密码。更高级的攻击者甚至能够直接对 E-mail 进行信息窃取。

③ 修改注册信息：当攻击者破解了 E-MAIL 后，会利用相关的更改功能修改该域名的注册信息，包括域名拥有者信息，DNS 服务器信息等。

④ 使用 E-MAIL 收发确认函：在修改完注册信息后，攻击者在 E-mail 真正拥有者之前收到修改域名注册信息的相关确认信息，并回复确认修改文件，待网络公司恢复已成功修改信件后，攻击者便成功完成 DNS 劫持。

用户端的一些预防手段：

直接通过 IP 地址访问网站，避开 DNS 劫持。
由于域名劫持往往只能在特定的网络范围内进行，因此一些高级用户可以通过网络设置让 DNS 指向正常的域名服务器以实现对目的网址的正常访问，例如将计算机首选 DNS 服务器的地址固定为 8.8.8.8。



DNS域名缓存

为了提高 DNS 查询效率，并减轻服务器的负荷和减少因特网上的 DNS 查询报文数量，在域名服务器中广泛使用了高速缓存，用来存放最近查询过的域名以及从何处获得域名映射信息的记录。

由于名字到地址的绑定并不经常改变，为保持高速缓存中的内容正确，域名服务器应为每项内容设置计时器并处理超过合理时间的项（例如：每个项目两天）。当域名服务器已从缓存中删去某项信息后又被请求查询该项信息，就必须重新到授权管理该项的域名服务器绑定信息。当权限服务器回答一个查询请求时，在响应中都指明绑定有效存在的时间值。增加此时间值可减少网络开销，而减少此时间值可提高域名解析的正确性。



## ARP、RARP、DHCP、ICMP、IGMP协议

### ARP 

**名字**：地址解析协议

**作用**：将网络层的IP地址映射到链路层的物理地址（MAC地址）。

**原理：**

- ARP 是借助 **ARP 请求与 ARP 响应**两种类型的包确定 MAC 地址的
- 主机会通过**广播发送 ARP 请求**，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。
- 当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 **ARP 响应包**返回给主机

**工作流程**：

1. 主机发出ARP请求广播（谁有这个IP地址?），包含目标IP地址和发送者的IP与MAC地址。
2. 网络上的所有主机接收此请求，但只有目标IP地址的主机会响应。
3. 目标主机发送ARP响应消息，包含其MAC地址，回给请求的主机。
4. 请求主机收到MAC地址后，存储在本地ARP缓存中，用于后续数据帧的发送。

### RARP

**名字**：逆地址解析协议

**作用**：将链路层的物理地址（MAC地址）映射到网络层的IP地址。

**工作流程**：

1. 主机发送RARP请求广播（我的MAC地址是这个，我的IP地址是什么？）。
2. RARP服务器接收请求，并查找对应的MAC地址所绑定的IP地址。
3. RARP服务器向请求的主机发送响应，提供其IP地址。
4. 主机收到自己的IP地址后开始网络活动。

### DHCP

**名字**：动态主机配置协议

**作用**：自动分配网络配置信息，如IP地址、子网掩码、默认网关、DNS服务器地址等。

**原理：** 

- 网络上的每台设备都会有一个独一无二的硬件地址，通常是由设备厂商分配的MAC地址。主机从网卡上读取MAC地址，然后在网络上发送一个RARP请求的广播数据包，请求RARP服务器回复该主机的IP地址。
- RARP服务器收到了RARP请求数据包，为其分配IP地址，并将RARP回应发送给主机。
- PC1收到RARP回应后，就使用得到的IP地址进行通讯。

**工作流程**：

1. 客户端发送DHCP发现消息，寻找DHCP服务器。
2. DHCP服务器响应发现消息，提供IP租约（DHCP提供消息）。
3. 客户端选择租约，并请求IP地址（DHCP请求消息）。
4. DHCP服务器确认分配的IP地址（DHCP ACK消息），完成配置。

### ICMP 

**名字**：互联网控制消息协议

**作用**：传输控制消息，例如报告路由器不能到达的错误、网络拥塞等。

**工作流程**：

1. 网络设备或主机遇到错误情况，如无法到达目的地。
2. 发送ICMP错误报文到原始数据包的源地址。
3. 源主机接收ICMP报文并采取相应的动作，如调整发送行为或通知用户。



#### ping 的工作原理

- `ping` 的**发送和接收过程**：

  - ping 命令执行的时候，源主机首先会构建一个 **ICMP 回送请求消息**数据包，最重要的是两个：第一个是**类型**，对于回送请求消息而言该字段为 `8`；另外一个是**序号**，主要用于区分连续 ping 的时候发出的多个数据包。每发出一个请求数据包，序号会自动加 `1`。为了能够计算往返时间 `RTT`，它会在报文的数据部分插入发送时间；由 ICMP 协议将这个数据包连同地址一起交给 IP 层，构建一个 `IP` 数据包
  - 接下来，需要加入 `MAC` 头；如果在本地 ARP 映射表中查找出 IP 地址的MAC地址则可以直接使用，否则发送 `ARP` 协议查询 MAC 地址，由数据链路层构建一个数据帧
  - 主机 `B` 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃；接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议
  - 主机 `B` 会构建一个 **ICMP 回送响应消息**数据包，回送响应数据包的**类型**字段为 `0`，**序号**为接收到的请求数据包中的序号，然后再发送出去给主机 A
  - 在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应消息，则说明目标主机可达。此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。

   ping 这个程序是**使用了 ICMP 里面的 ECHO REQUEST（类型为 8 ） 和 ECHO REPLY （类型为 0）**

什么是 ping

ping 是应用层命令，可以理解为它跟游戏或者聊天软件属于同一层。只不过聊天软件可以收发消息，还能点个赞什么的，有很多复杂的功能。而 ping 作为一个小软件，它的功能比较简单，就是**尝试**发送一个小小的消息到目标机器上，判断目的机器是否**可达**，其实也就是判断目标机器网络是否能连通。

ping应用的底层，用的是网络层的**ICMP协议**。

IP和ICMP和Ping所在分层,虽然ICMP协议和IP协议**都属于网络层协议**，但其实**ICMP也是利用了IP协议进行消息的传输**。

Ping命令基于什么协议？原理是什么？

ping是基于网络层的ICMP协议实现的。通过向对方发送一个**ICMP回送请求报文**，如果对方主机可达的话会收到该报文，并响应一个**ICMP回送回答报文**。

扩展：ICMP报文的介绍。ICMP报文分为两个种类：

1. ICMP差错报告报文，常见的有
   1. 终点不可达
   2. 时间超过
   3. 参数问题
   4. 改变路由
2. ICMP询问报文
   1. 回送请求和回答：向特定主机发出**回送请求报文**，收到回送请求报文的主机响应**回送回答报文**。
   2. 时间戳请求和回答：询问对方当前的时间，返回的是一个32位的时间戳。

TCP发数据和ping的区别

创建 `socket` 的时候用的是 `socket(AF_INET,SOCK_RAW,IPPROTO_ICMP)`，`SOCK_RAW` 是原始套接字 ，**工作在网络层**， 所以构建`ICMP`（网络层协议）的数据，是再合适不过了。ping 在进入内核态后最后也是调用的 `sock_sendmsg` 方法，进入到网络层后加上**ICMP和IP头**后，数据链路层加上**MAC头**，也是顺着网卡发出。因此 本质上ping 跟 普通应用发消息 在程序流程上没太大差别。

为什么断网了还能 ping 通 127.0.0.1

从应用层到传输层再到网络层。这段路径跟ping外网的时候是几乎是一样的。到了网络层，系统会根据目的IP，在路由表中获取对应的**路由信息**，而这其中就包含选择**哪个网卡**把消息发出。

当发现**目标IP是外网IP**时，会从"真网卡"发出。

当发现**目标IP是回环地址**时，就会选择**本地网卡**。

本地网卡，其实就是个**"假网卡"**，它不像"真网卡"那样有个`ring buffer`什么的，"假网卡"会把数据推到一个叫 `input_pkt_queue` 的 \**链表\** 中。这个链表，其实是所有网卡共享的，上面挂着发给本机的各种消息。消息被发送到这个链表后，会再触发一个**软中断**。

专门处理软中断的工具人**"ksoftirqd"** （这是个**内核线程**），它在收到软中断后就会立马去链表里把消息取出，然后顺着数据链路层、网络层等层层往上传递最后给到应用程序。

`127.0.0.1` 是**回环地址**。`localhost`是**域名**，但默认等于 `127.0.0.1`。

`ping` 回环地址和 `ping` 本机地址，是一样的，走的是**lo0 "假网卡"**，都会经过网络层和数据链路层等逻辑，最后在快要出网卡前**狠狠拐了个弯**， 将数据插入到一个**链表**后就**软中断**通知 **ksoftirqd** 来进行**收数据**的逻辑，**压根就不出网络**。所以断网了也能 `ping` 通回环地址。

如果服务器 `listen` 的是 `0.0.0.0`，那么此时用`127.0.0.1`和本机地址**都可以**访问到服务。



#### 网络ping不通是什么原因

- ping的原理是利用网络上机器IP地址的唯一性，给目标IP地址发送一个数据包，再要求对方返回一个同样大小的数据包来确定两台网络机器是否连接相通，时延是多少

- ping命令不通，主要有两种情况，一种是同网段内的ip地址ping不通，另一种是不同网段的ip地址ping不通

  - **同网段ping不通，结果是“无法访问目标主机”**，说明此时，ping的需求并没有成功发出，这时，要检查：

    1、对方是否开机？ip是否存在？

    2、有跨交换机vlan的话，检查对应的中间trunk链路是否导通？

    3、走直连路由是否正确？是否应该走默认路由，而走了直连路由。

    4、子网掩码是否错误。

    5、默认网关是否填写正确

  - **同网段ping不通，结果是“超时（time out)”**，这种情况是ping已经成功发出了，到达了主机，但时没有得到响应，要检查：

    1、检查下防火墙，防火墙禁止了对ping的回应。

    2、子网掩码的设置错误，导致不在同一个网段。

    3、设备硬件故障，导致设备没有对应的mac地址，无法生成路由表，而走默认路由。

    4、ip冲突，或ip地址与直联路由不在同一个网段。

    5、网关没有设置好



### IGMP 

**名字**：互联网组管理协议

**作用**：管理主机在多播组的成员资格，用于多播数据的有效传递。

**工作流程**：

1. 主机向其路由器发送IGMP报文，表示希望加入一个多播组。
2. 路由器接收报文，并更新自身的多播组成员列表。
3. 当路由器收到向该多播组地址的数据时，它会将数据转发给列表中的所有成员。
4. 如果主机需要离开多播组，它会发送IGMP离开组报文到路由器，路由器更新列表。

这些协议对于网络通信的稳定性和效率至关重要，它们确保数据能够在多样化的设备和网络架构之间准确地发送和接收。



ARP

- 在传输一个 IP 数据报的时候，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下一跳。然而，网络层的下一层是数据链路层，所以我们还要知道「下一跳」的 MAC 地址。由于主机的路由表中可以找到下一跳的 IP 地址，所以可以通过 **ARP 协议**，求得下一跳的 MAC 地址
- ARP 是借助 **ARP 请求与 ARP 响应**两种类型的包确定 MAC 地址的
  - 主机会通过**广播发送 ARP 请求**，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。
  - 当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 **ARP 响应包**返回给主机
- 操作系统通常会把第一次**通过 ARP 获取的 MAC 地址**缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC 地址。不过，MAC 地址的缓存是有一定期限的，超过这个期限，缓存的内容将被清除
- ARP 协议是已知 IP 地址求 MAC 地址，那 RARP 协议正好相反，它是**已知 MAC 地址求 IP 地址**。例如将打印机服务器等小型嵌入式设备接入到网络时就经常会用得到。

RARP

 反向地址转换协议，网络层协议，RARP与ARP工作方式相反。 RARP使**只知道自己硬件地址的主机能够知道其IP地址**。

原理： 

- 网络上的每台设备都会有一个独一无二的硬件地址，通常是由设备厂商分配的MAC地址。主机从网卡上读取MAC地址，然后在网络上发送一个RARP请求的广播数据包，请求RARP服务器回复该主机的IP地址。
- RARP服务器收到了RARP请求数据包，为其分配IP地址，并将RARP回应发送给主机。
- PC1收到RARP回应后，就使用得到的IP地址进行通讯。

DHCP

- 我们的电脑通常都是通过 DHCP 动态获取 IP 地址，大大省去了配 IP 信息繁琐的过程

- DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。

- 整体步骤：

  - 客户端首先发起 **DHCP 发现报文（DHCP DISCOVER）** 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP **广播**通信，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。
  - DHCP 服务器收到 DHCP 发现报文时，用 **DHCP 提供报文（DHCP OFFER）** 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 **IP 地址租用期**。
  - 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 **DHCP 请求报文（DHCP REQUEST**进行响应，回显配置的参数。
  - 最后，服务端用 **DHCP ACK 报文**对 DHCP 请求报文进行响应，应答所要求的参数

- 一旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。

- 如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：

  - 服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。
  - 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址

- DHCP 交互中，**全程都是使用 UDP 广播通信**。⚠️如果 DHCP 服务器和客户端不是在同一个局域网内，路由器又不会转发广播包，那不是每个网络都要配一个 DHCP 服务器？

  - 为了解决这一问题，就出现了 **DHCP 中继代理**。有了 DHCP 中继代理以后，**对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理。**
  - DHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以**单播**的形式发给 DHCP 服务器。
  - 服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包广播给 DHCP 客户端 

  因此，DHCP 服务器即使不在同一个链路上也可以实现统一分配和管理IP地址

NAT

- NAT的基本工作原理是，当私有网主机和公共网主机通信的IP包经过NAT网关时，将IP包中的源IP或目的IP在私有IP和NAT的公共IP之间进行转换。

- 普通的 NAT 转换没什么意义。由于绝大多数的网络应用都是使用传输层协议 TCP 或 UDP 来传输数据的。因此，可以把 IP 地址 + 端口号一起进行转换。这样，就用一个全球 IP 地址就可以了，这种转换技术就叫**网络地址与端口转换 NAPT。**
  - **两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端口号作为区分**
  - 生成一个 NAPT 路由器的转换表，就可以正确地转换地址跟端口的组合，令客户端 A、B 能同时与服务器之间进行通信。这种转换表在 NAT 路由器上自动生成。
  - 在 TCP 的情况下，建立 TCP 连接首次握手时的 SYN 包一经发出，就会生成这个表。而后又随着收到关闭连接时发出 FIN 包的确认应答从表中被删除。
  
- 由于 NAT/NAPT 都依赖于自己的转换表，因此会有以下的问题：
  - 外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。
  - 转换表的生成与转换操作都会产生性能开销。
  - 通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置
  
- 解决的方法主要有两种方法。
  - *第一种就是改用 IPv6*：IPv6 可用范围非常大，以至于每台设备都可以配置一个公有 IP 地址，就不搞那么多花里胡哨的地址转换了，但是 IPv6 普及速度还需要一些时间。
  - *第二种 NAT 穿透技术*：NAT 穿越技术拥有这样的功能，它能够让网络应用程序主动发现自己位于 NAT 设备之后，并且会主动获得 NAT 设备的公有 IP，并为自己建立端口映射条目，注意这些都是 NAT设备后的应用程序自动完成的。客户端主动从 NAT 设备获取公有 IP 地址，然后自己建立端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了
  
  

ICMP（ping相关）

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/5.jpg)

- ICMP 全称是**Internet Control Message Protocol**，也就是**互联网控制报文协议**，⚠️是**网络层协议**

- `ICMP` 主要的功能包括：**确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。**在 `IP` 通信中如果某个 `IP` 包因为某种原因未能达到目标地址，那么这个具体的原因将**由 ICMP 负责通知**。

  - ICMP 的这种通知消息会使用 `IP` 进行发送 。因此， 返回的 ICMP 包会按照往常的路由控制转发给主机 `A` 。收到该 ICMP 包的主机 `A` 则分解 ICMP 的首部和数据域以后得知具体发生问题的原因

- ICMP 大致可以分为两大类：

  - 一类是用于诊断的查询消息，也就是「**查询报文类型**」
  - 另一类是通知出错原因的错误消息，也就是「**差错报文类型**」

  ![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/6.jpg)

**查询报文类型**：回送消息 —— 类型 `0` 和 `8`

- 用于进行通信的主机或路由器之间，判断所发送的数据包是否已经成功到达对端的一种消息，**`ping` 命令就是利用这个消息实现的**；

- 可以向对端主机发送**回送请求**的消息（`ICMP Echo Request Message`，类型 `8`）也可以接收对端主机发回来的**回送应答**消息（`ICMP Echo Reply Message`，类型 `0`）

- 相比原生的 ICMP，这里多了两个字段：

  - **标识符**：用以区分是哪个应用程序发 ICMP 包，比如用进程 `PID` 作为标识符；

  - **序号**：序列号从 `0` 开始，每发送一次新的回送请求就会加 `1`， 可以用来确认网络包是否有丢失。


在**选项数据**中，`ping` 还会存放发送请求的时间值，来计算往返时间，说明路程的长短

**常用的 ICMP 差错报文的例子：**

- 目标不可达消息 —— 类型 为 `3`：IP 路由器无法将 IP 数据包发送给目标地址，在这个消息中显示不可达的具体原因，原因记录在 ICMP 包头的**代码**字段。
  - 网络不可达代码为 `0`，路由器中的路由器表匹配不到接收方 IP 的网络号
  - 主机不可达代码为 `1`，路由表中没有该主机的信息，或者该主机没有连接到网络
  - 协议不可达代码为 `2`，对端主机的防火墙已经禁止 TCP 协议访问
  - 端口不可达代码为 `3`，端主机没有进程监听 8080 端口
  - 需要进行分片但设置了不分片位代码为 `4`， IP 首部的**分片禁止标志位**设置为`1`。根据这个标志位，途中的路由器遇到超过 MTU 大小的数据包时，不会进行分片，而是直接抛弃
- 原点抑制消息 —— 类型 `4`：路由器向低速线路发送数据时，其发送队列的缓存变为零而无法发送出去时，可以向 IP 包的源地址发送一个 ICMP **原点抑制消息**
- 重定向消息 —— 类型 `5`，路由器发现发送端主机使用了「不是最优」的路径发送数据，会返回一个 ICMP **重定向消息**给这个主机，在这个消息中包含了**最合适的路由信息和源数据**。
- 超时消息 —— 类型 `11`，IP 包中有一个字段叫做 `TTL` （`Time To Live`，生存周期），它的**值随着每经过一次路由器就会减 1，直到减到 0 时该 IP 包会被丢弃。**

ping 的工作原理

- `ping` 的**发送和接收过程**：

  - ping 命令执行的时候，源主机首先会构建一个 **ICMP 回送请求消息**数据包，最重要的是两个：第一个是**类型**，对于回送请求消息而言该字段为 `8`；另外一个是**序号**，主要用于区分连续 ping 的时候发出的多个数据包。每发出一个请求数据包，序号会自动加 `1`。为了能够计算往返时间 `RTT`，它会在报文的数据部分插入发送时间；由 ICMP 协议将这个数据包连同地址一起交给 IP 层，构建一个 `IP` 数据包
  - 接下来，需要加入 `MAC` 头；如果在本地 ARP 映射表中查找出 IP 地址的MAC地址则可以直接使用，否则发送 `ARP` 协议查询 MAC 地址，由数据链路层构建一个数据帧
  - 主机 `B` 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃；接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议
  - 主机 `B` 会构建一个 **ICMP 回送响应消息**数据包，回送响应数据包的**类型**字段为 `0`，**序号**为接收到的请求数据包中的序号，然后再发送出去给主机 A
  - 在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应消息，则说明目标主机可达。此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。

   ping 这个程序是**使用了 ICMP 里面的 ECHO REQUEST（类型为 8 ） 和 ECHO REPLY （类型为 0）**

什么是 ping

ping 是应用层命令，可以理解为它跟游戏或者聊天软件属于同一层。只不过聊天软件可以收发消息，还能点个赞什么的，有很多复杂的功能。而 ping 作为一个小软件，它的功能比较简单，就是**尝试**发送一个小小的消息到目标机器上，判断目的机器是否**可达**，其实也就是判断目标机器网络是否能连通。

ping应用的底层，用的是网络层的**ICMP协议**。

IP和ICMP和Ping所在分层,虽然ICMP协议和IP协议**都属于网络层协议**，但其实**ICMP也是利用了IP协议进行消息的传输**。

Ping命令基于什么协议？原理是什么？

ping是基于网络层的ICMP协议实现的。通过向对方发送一个**ICMP回送请求报文**，如果对方主机可达的话会收到该报文，并响应一个**ICMP回送回答报文**。

扩展：ICMP报文的介绍。ICMP报文分为两个种类：

1. ICMP差错报告报文，常见的有
   1. 终点不可达
   2. 时间超过
   3. 参数问题
   4. 改变路由
2. ICMP询问报文
   1. 回送请求和回答：向特定主机发出**回送请求报文**，收到回送请求报文的主机响应**回送回答报文**。
   2. 时间戳请求和回答：询问对方当前的时间，返回的是一个32位的时间戳。

TCP发数据和ping的区别

创建 `socket` 的时候用的是 `socket(AF_INET,SOCK_RAW,IPPROTO_ICMP)`，`SOCK_RAW` 是原始套接字 ，**工作在网络层**， 所以构建`ICMP`（网络层协议）的数据，是再合适不过了。ping 在进入内核态后最后也是调用的 `sock_sendmsg` 方法，进入到网络层后加上**ICMP和IP头**后，数据链路层加上**MAC头**，也是顺着网卡发出。因此 本质上ping 跟 普通应用发消息 在程序流程上没太大差别。

为什么断网了还能 ping 通 127.0.0.1

从应用层到传输层再到网络层。这段路径跟ping外网的时候是几乎是一样的。到了网络层，系统会根据目的IP，在路由表中获取对应的**路由信息**，而这其中就包含选择**哪个网卡**把消息发出。

当发现**目标IP是外网IP**时，会从"真网卡"发出。

当发现**目标IP是回环地址**时，就会选择**本地网卡**。

本地网卡，其实就是个**"假网卡"**，它不像"真网卡"那样有个`ring buffer`什么的，"假网卡"会把数据推到一个叫 `input_pkt_queue` 的 \**链表\** 中。这个链表，其实是所有网卡共享的，上面挂着发给本机的各种消息。消息被发送到这个链表后，会再触发一个**软中断**。

专门处理软中断的工具人**"ksoftirqd"** （这是个**内核线程**），它在收到软中断后就会立马去链表里把消息取出，然后顺着数据链路层、网络层等层层往上传递最后给到应用程序。

`127.0.0.1` 是**回环地址**。`localhost`是**域名**，但默认等于 `127.0.0.1`。

`ping` 回环地址和 `ping` 本机地址，是一样的，走的是**lo0 "假网卡"**，都会经过网络层和数据链路层等逻辑，最后在快要出网卡前**狠狠拐了个弯**， 将数据插入到一个**链表**后就**软中断**通知 **ksoftirqd** 来进行**收数据**的逻辑，**压根就不出网络**。所以断网了也能 `ping` 通回环地址。

如果服务器 `listen` 的是 `0.0.0.0`，那么此时用`127.0.0.1`和本机地址**都可以**访问到服务。



网络ping不通是什么原因

- ping的原理是利用网络上机器IP地址的唯一性，给目标IP地址发送一个数据包，再要求对方返回一个同样大小的数据包来确定两台网络机器是否连接相通，时延是多少

- ping命令不通，主要有两种情况，一种是同网段内的ip地址ping不通，另一种是不同网段的ip地址ping不通

  - **同网段ping不通，结果是“无法访问目标主机”**，说明此时，ping的需求并没有成功发出，这时，要检查：

    1、对方是否开机？ip是否存在？

    2、有跨交换机vlan的话，检查对应的中间trunk链路是否导通？

    3、走直连路由是否正确？是否应该走默认路由，而走了直连路由。

    4、子网掩码是否错误。

    5、默认网关是否填写正确

  - **同网段ping不通，结果是“超时（time out)”**，这种情况是ping已经成功发出了，到达了主机，但时没有得到响应，要检查：

    1、检查下防火墙，防火墙禁止了对ping的回应。

    2、子网掩码的设置错误，导致不在同一个网段。

    3、设备硬件故障，导致设备没有对应的mac地址，无法生成路由表，而走默认路由。

    4、ip冲突，或ip地址与直联路由不在同一个网段。

    5、网关没有设置好



IGMP

- **IGMP 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间**
  - IGMP 报文向路由器申请加入和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除非主机通过 IGMP 加入到组播组，主机申请加入到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转发组播包到对应的主机了。
  - IGMP 报文采用 IP 封装，IP 头部的协议号为 2，而且 TTL 字段值通常为 1，因为 IGMP 是工作在主机与连接的路由器之间。
- *常规查询与响应工作机制*：
  - 路由器会周期性发送目的地址为 `224.0.0.1`（表示同一网段内所有主机和路由器） **IGMP 常规查询报文**。
  - 主机1 和 主机 3 收到这个查询，随后会启动「报告延迟计时器」，计时器的时间是随机的，通常是 0~10 秒，计时器超时后主机就会发送 **IGMP 成员关系报告报文**（源 IP 地址为自己主机的 IP 地址，目的 IP 地址为组播地址）。如果在定时器超时之前，收到同一个组内的其他主机发送的成员关系报告报文，则自己不再发送，这样可以减少网络中多余的 IGMP 报文数量。
  - 路由器收到主机的成员关系报文后，就会在 IGMP 路由表中加入该组播组，后续网络中一旦该组播地址的数据到达路由器，它会把数据包转发出去
- *离开组播组工作机制*
  - 网段中仍有该组播组：
    - 主机 1 要离开组 224.1.1.1，发送 IGMPv2 离组报文，报文的目的地址是 224.0.0.2（表示发向网段内的所有路由器）
    - 路由器 收到该报文后，以 1 秒为间隔连续发送 IGMP 特定组查询报文（共计发送 2 个），以便确认该网络是否还有 224.1.1.1 组的其他成员。
    - 主机 3 仍然是组 224.1.1.1 的成员，因此它立即响应这个特定组查询。路由器知道该网络中仍然存在该组播组的成员，于是继续向该网络转发 224.1.1.1 的组播数据包。
  - 网段中没有该组播组：
    - 主机 1 要离开组播组 224.1.1.1，发送 IGMP 离组报文。
    - 路由器收到该报文后，以 1 秒为间隔连续发送 IGMP 特定组查询报文（共计发送 2 个）。此时在该网段内，组 224.1.1.1 已经没有其他成员了，因此没有主机响应这个查询。
    - 一定时间后，路由器认为该网段中已经没有 224.1.1.1 组播组成员了，将不会再向这个网段转发该组播地址的数据包。



## 
